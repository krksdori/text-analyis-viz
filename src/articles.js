export default [
{
	title: "Aristocracy",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Copyright",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Colony",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Europe",
	eYear: 1756,
	wYear: 2017,
	eSource: "https://lololo.com",
	wSource: "https://en.wikipedia.org/wiki/Europe",
	eConn: ["atlantic","ocean","europe","world","world","only","western","ocean","west","ocean","vincent","ocean","south","ocean","south","north","smallest","world", "respect","peoples", "separated","ocean","sea","ocean","sister","like","portugese","ocean","ocean","miles","ocean","leagues","ocean","german","ocean","french","ocean","expanse","ocean","degree","ocean","arctic"],
	wConn: ["world","war","roman","empire","middle","ages","european","union","eastern","europe","central","europe","western","europe","states","europe","european","states","europe","asia","soviet","union","europe","population","europe","century","century","europe","central","eastern","languages","europe","european","economic","europe","western","europe","forest","united","states","million","people","map","europe","europe","world","europe","sea","countries","europe","world","europe","united","kingdom"],
	eArt: `
	<p> Europe large region of the inhabited world. What is perhaps the best etymology derives the word Europe from the Phoenician <i>urappa</i>, which in that language means white face. One might have applied this epithet to the daughter of Agenor and sister of Cadmus, but at the very least it is appropriate for Europeans, those who are neither brown like South Asians nor black like Africans.</p>

	<p> Europe has not always had the same name nor has it had the same divisions with respect to the principal peoples who lived there. As for subdivisions, they depend on impossible details in the absence of historians who can show us the correct path out of this labyrinth.</p>

	<p> This article will not consider Europe as it was known by ancient writers whose works have survived to this day. I merely want to say a word here on its boundaries.</p>

	<p> It extends in its greatest width from Cape St. Vincent in the Portugese Algarve on the Atlantic Ocean to the mouth of the Obi on the Arctic Ocean with an expanse of 1200 French leagues, 20 to the degree, or of 900 German miles. Its largest length, taken from Cape Matapan in the south of Morea to the North Cape in the most northern part of Norway is about 733 French leagues, also 20 to the degree, or 550 German miles. It is bordered on the east by Asia, to the south by Africa, from which it is separated by the Mediterranean Sea, to the west by the Atlantic or Western Ocean, and to the north by the Arctic Ocean.</p>

	<p> I do not know if we are right to divide the world into four parts, of which Europe is one. At the very least, this division does not appear accurate because it could not include the arctic or Antarctic lands, which although less known than the rest do not cease to exist and merit an empty space on globes and maps.</p>

	<p> In any case, Europe is still the smallest part of the world; however, as noted by the author of The Spirit of Laws , it has come to such a high degree of power that history has almost nothing on it, considering the immensity of its expenditures, the greatness of its engagements, the number of troops and their continued maintenance in standing armies, even when they are most useless and kept only for ostentation.</p>

		<p> Besides, it matters little that Europe is the smallest of the four parts of the world in terms of terrain because it is the largest of all with respect to its commerce, its navigation, its fertility, by the enlightenment and industry of its peoples, by the knowledge of Art, Science, Trades, and most importantly because of Christianity, the goodness of whose morals only leads to the well-being of society. We owe this religion a certain political right in government and a certain law of nations in war that human nature cannot acknowledge enough; in appearing to have as its only objective bliss in another life, it is also responsible for our happiness in this one.<p>

	<p> Europe was called Celtic in the earliest of times. Its location is between the 9 th and 93 rd degrees of longitude and between the 34 th and 73 rd degrees of north latitude. The geographers will teach the other details to the reader.</p>
	`,

	wArt: `

	<p> Europe is a continent that comprises the westernmost part of Eurasia. Europe is bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean Sea to the south. The eastern boundary with Asia is a historical and cultural construct, as there is no clear physical and geographical separation between them; Europe is generally considered as separated from Asia by the watershed divides of the Ural and Caucasus Mountains, the Ural River, the Caspian and Black Seas, and the waterways of the Turkish Straits. Yet the non-oceanic borders of Europe—a concept dating back to classical antiquity—are arbitrary. The primarily physiographic term "continent" as applied to Europe also incorporates cultural and political elements whose discontinuities are not always reflected by the continent's current overland boundaries.</p>
	<p> Europe covers about 10,180,000 square kilometres (3,930,000 sq mi), or 2% of the Earth's surface (6.8% of land area). Politically, Europe is divided into about fifty sovereign states of which the Russian Federation is the largest and most populous, spanning 39% of the continent and comprising 15% of its population. Europe had a total population of about 740 million (about 11% of world population) as of 2015.</p>
	<p> The European climate is largely affected by warm Atlantic currents that temper winters and summers on much of the continent, even at latitudes along which the climate in Asia and North America is severe. Further from the sea, seasonal differences are more noticeable than close to the coast.</p>
	<p> Europe, in particular ancient Greece, was the birthplace of Western civilization. The fall of the Western Roman Empire, during the migration period, marked the end of ancient history and the beginning of an era known as the Middle Ages. Renaissance humanism, exploration, art, and science led to the modern era. From the Age of Discovery onwards, Europe played a predominant role in global affairs. Between the 16th and 20th centuries, European powers controlled at various times the Americas, most of Africa, Oceania, and the majority of Asia.</p>
	<p> The Industrial Revolution, which began in Great Britain at the end of the 18th century, gave rise to radical economic, cultural, and social change in Western Europe, and eventually the wider world. Both world wars took place for the most part in Europe, contributing to a decline in Western European dominance in world affairs by the mid-20th century as the Soviet Union and the United States took prominence. During the Cold War, Europe was divided along the Iron Curtain between NATO in the west and the Warsaw Pact in the east, until the revolutions of 1989 and fall of the Berlin Wall.</p>
	<p> In 1955, the Council of Europe was formed following a speech by Sir Winston Churchill, with the idea of unifying Europe to achieve common goals. It includes all states except for Belarus, Kazakhstan and Vatican City. Further European integration by some states led to the formation of the European Union, a separate political entity that lies between a confederation and a federation. The EU originated in Western Europe but has been expanding eastward since the fall of the Soviet Union in 1991. The currency of most countries of the European Union, the euro, is the most commonly used among Europeans; and the EU's Schengen Area abolishes border and immigration controls among most of its member states. The European Anthem is "Ode to Joy" and states celebrate peace and unity on Europe Day.</p>
	<br>
	<br>

	<h4> Name</h4>
	<p> In classical Greek mythology, Europa (Ancient Greek: Εὐρώπη, Eurṓpē) is the name of either a Phoenician princess or of a queen of Crete. The name contains the elements εὐρύς (eurús), "wide, broad" and ὤψ (ōps, gen. ὠπός, ōpós) "eye, face, countenance", hence their composite Eurṓpē would mean "wide-gazing" or "broad of aspect". Broad has been an epithet of Earth herself in the reconstructed Proto-Indo-European religion and the poetry devoted to it. For the second part compare also the divine attributes of "grey-eyed" Athena (γλαυκῶπις, glaukōpis) or ox-eyed Hera (βοὠπις, boōpis).</p>
	<p> There have been attempts to connect Eurṓpē to a Semitic term for "west", this being either Akkadian erebu meaning "to go down, set" (said of the sun) or Phoenician 'ereb "evening, west", which is at the origin of Arabic Maghreb and Hebrew ma'arav. Michael A. Barry, professor in Princeton University's Near Eastern Studies Department, finds the mention of the word Ereb on an Assyrian stele with the meaning of "night, [the country of] sunset", in opposition to Asu "[the country of] sunrise", i.e. Asia. The same naming motive according to "cartographic convention" appears in Greek Ανατολή (Anatolḗ "[sun] rise", "east", hence Anatolia). Martin Litchfield West stated that "phonologically, the match between Europa's name and any form of the Semitic word is very poor." Next to these hypotheses there is also a Proto-Indo-European root *h1regʷos, meaning "darkness", which also produced Greek Erebus.</p>
	<p> Most major world languages use words derived from Eurṓpē or Europa to refer to the continent. Chinese, for example, uses the word Ōuzhōu (歐洲/欧洲); a similar Chinese-derived term Ōshū (欧州) is also sometimes used in Japanese such as in the Japanese name of the European Union, Ōshū Rengō (欧州連合?), despite the katakana Yōroppa (ヨーロッパ) being more commonly used. In some Turkic languages the originally Persian name Frangistan ("land of the Franks") is used casually in referring to much of Europe, besides official names such as Avrupa or Evropa.</p>
	<br>

	<h4> Definition</h4>
	<h2> Contemporary definition</h2>
	<p> The prevalent definition of Europe as a geographical term has been in use since the mid-19th century. Europe is taken to be bounded by large bodies of water to the north, west and south; Europe's limits to the far east are usually taken to be the Urals, the Ural River, and the Caspian Sea; to the southeast, including the Caucasus Mountains, the Black Sea and the waterways connecting the Black Sea to the Mediterranean Sea.</p>
	<p> Islands are generally grouped with the nearest continental landmass, hence Iceland is generally considered to be part of Europe, while the nearby island of Greenland is usually assigned to North America. Nevertheless, there are some exceptions based on sociopolitical and cultural differences. Cyprus is closest to Anatolia (or Asia Minor), but is usually considered part of Europe both culturally and politically and is a member state of the EU. Malta was considered an island of North Africa for centuries.</p>
	<p> "Europe" as used specifically in British English may also refer to Continental Europe exclusively.</p>
	<br>
	<h2> History of the concept</h2>
	<h1> Early history</h1>
	<p> The first recorded usage of Eurṓpē as a geographic term is in the Homeric Hymn to Delian Apollo, in reference to the western shore of the Aegean Sea. As a name for a part of the known world, it is first used in the 6th century BC by Anaximander and Hecataeus. Anaximander placed the boundary between Asia and Europe along the Phasis River (the modern Rioni River) in the Caucasus, a convention still followed by Herodotus in the 5th century BC. Herodotus mentioned that the world had been divided by unknown persons into three parts, Europe, Asia, and Libya (Africa), with the Nile and the Phasis forming their boundaries—though he also states that some considered the River Don, rather than the Phasis, as the boundary between Europe and Asia. Europe's eastern frontier was defined in the 1st century by geographer Strabo at the River Don. The Book of Jubilees described the continents as the lands given by Noah to his three sons; Europe was defined as stretching from the Pillars of Hercules at the Strait of Gibraltar, separating it from North Africa, to the Don, separating it from Asia.</p>
	<p> The convention received by the Middle Ages and surviving into modern usage is that of the Roman era used by Roman era authors such as Posidonius, Strabo and Ptolemy, who took the Tanais (the modern Don River) as the boundary.</p>
	<p> The term "Europe" is first used for a cultural sphere in the Carolingian Renaissance of the 9th century. From that time, the term designated the sphere of influence of the Western Church, as opposed to both the Eastern Orthodox churches and to the Islamic world.</p>
	<p> A cultural definition of Europe as the lands of Latin Christendom coalesced in the 8th century, signifying the new cultural condominium created through the confluence of Germanic traditions and Christian-Latin culture, defined partly in contrast with Byzantium and Islam, and limited to northern Iberia, the British Isles, France, Christianised western Germany, the Alpine regions and northern and central Italy. The concept is one of the lasting legacies of the Carolingian Renaissance: "Europa" often[dubious – discuss] figures in the letters of Charlemagne's court scholar, Alcuin.</p>
	<br>
	<h2> Modern definitions</h2>
	<p> The question of defining a precise eastern boundary of Europe arises in the Early Modern period, as the eastern extension of Muscovy began to include Northern Asia.</p>
	<p> Throughout the Middle Ages and into the 18th century, the traditional division of the landmass of Eurasia into two continents, Europe and Asia, followed Ptolemy, with the boundary following the Turkish Straits, the Black Sea, the Kerch Strait, the Sea of Azov and the Don (ancient Tanais). But maps produced during the 16th to 18th centuries tended to differ in how to continue the boundary beyond the Don bend at Kalach-na-Donu (where it is closest to the Volga, now joined with it by the Volga–Don Canal), into territory not described in any detail by the ancient geographers.</p>
	<p> Philip Johan von Strahlenberg in 1725 was the first to depart from the classical Don boundary by drawing the line along the Volga, following the Volga north until the Samara Bend, along Obshchy Syrt (the drainage divide between Volga and Ural) and then north along Ural Mountains. introducing the convention that would eventually become adopted as standard.</p>
	<p> The mapmakers continued to differ on the boundary between the lower Don and Samara well into the 19th century. The 1745 atlas published by the Russian Academy of Sciences has the boundary follow the Don beyond Kalach as far as Serafimovich before cutting north towards Arkhangelsk, while other 18th- to 19th-century mapmakers such as John Cary followed Strahlenberg's prescription. To the south, the Kuma–Manych Depression was identified circa 1773 by a German naturalist, Peter Simon Pallas, as a valley that, once upon a time, connected the Black Sea and the Caspian Sea, and subsequently was proposed as a natural boundary between continents.</p>
	<p> By the mid-19th century, there were three main conventions, one following the Don, the Volga–Don Canal and the Volga, the other following the Kuma–Manych Depression to the Caspian and then the Ural River, and the third abandoning the Don altogether, following the Greater Caucasus watershed to the Caspian. The question was still treated as a "controversy" in geographical literature of the 1860s, with Douglas Freshfield advocating the Caucasus crest boundary as the "best possible", citing support from various "modern geographers".</p>
	<p> In Russia and the Soviet Union, the boundary along the Kuma–Manych Depression was the most commonly used as early as 1906. In 1958, the Soviet Geographical Society formally recommended that the boundary between the Europe and Asia be drawn in textbooks from Baydaratskaya Bay, on the Kara Sea, along the eastern foot of Ural Mountains, then following the Ural River until the Mugodzhar Hills, and then the Emba River; and Kuma–Manych Depression, thus placing the Caucasus entirely in Asia and the Urals entirely in Europe. However, most geographers in the Soviet Union favoured the boundary along the Caucasus crest and this became the standard convention in the later 20th century, although the Kuma–Manych boundary remained in use in some 20th-century maps.</p>
	<br>
	<br>

	<h4> History</h4>
	<h3> Prehistory</h3>
	<p> Homo erectus georgicus, which lived roughly 1.8 million years ago in Georgia, is the earliest hominid to have been discovered in Europe. Other hominid remains, dating back roughly 1 million years, have been discovered in Atapuerca, Spain. Neanderthal man (named after the Neandertal valley in Germany) appeared in Europe 150,000 years ago and disappeared from the fossil record about 28,000 BC, with this extinction probably due to climate change, and their final refuge being present-day Portugal. The Neanderthals were supplanted by modern humans (Cro-Magnons), who appeared in Europe around 43 to 40 thousand years ago.</p>
	<p> The European Neolithic period—marked by the cultivation of crops and the raising of livestock, increased numbers of settlements and the widespread use of pottery—began around 7000 BC in Greece and the Balkans, probably influenced by earlier farming practices in Anatolia and the Near East. It spread from the Balkans along the valleys of the Danube and the Rhine (Linear Pottery culture) and along the Mediterranean coast (Cardial culture). Between 4500 and 3000 BC, these central European neolithic cultures developed further to the west and the north, transmitting newly acquired skills in producing copper artefacts. In Western Europe the Neolithic period was characterised not by large agricultural settlements but by field monuments, such as causewayed enclosures, burial mounds and megalithic tombs. The Corded Ware cultural horizon flourished at the transition from the Neolithic to the Chalcolithic. During this period giant megalithic monuments, such as the Megalithic Temples of Malta and Stonehenge, were constructed throughout Western and Southern Europe.</p>
	<p> The European Bronze Age began c. 3200 BC in Greece with the Minoan civilization on Crete, the first advanced civilization in Europe. The Minoans were followed by the Myceneans, who collapsed suddenly around 1200 BC, ushering the European Iron Age. Iron Age colonisation by the Greeks and Phoenicians gave rise to early Mediterranean cities. Early Iron Age Italy and Greece from around the 8th century BC gradually gave rise to historical Classical antiquity, whose beginning is sometimes dated to 776 BC, the year the first Olympic Games.</p>
	<br>
	<h3> Classical antiquity</h3>
	<p> Ancient Greece was the founding culture of Western civilisation. Western democratic and rationalist culture are often attributed to Ancient Greece.[50] The Greeks city-state, the polis, was the fundamental political unit of classical Greece.[50] In 508 BC, Cleisthenes instituted the world's first democratic system of government in Athens. The Greek political ideals were rediscovered in the late 18th century by European philosophers and idealists. Greece also generated many cultural contributions: in philosophy, humanism and rationalism under Aristotle, Socrates and Plato; in history with Herodotus and Thucydides; in dramatic and narrative verse, starting with the epic poems of Homer; in drama with Sophocles and Euripides, in medicine with Hippocrates and Galen; and in science with Pythagoras, Euclid and Archimedes. In the course of the 5th century BC, several of the Greek city states would ultimately check the Achaemenid Persian advance in Europe through the Greco-Persian Wars, considered a pivotal moment in world history, as the 50 years of peace that followed are known as Golden Age of Athens, the seminal period of ancient Greece that laid many of the foundations of Western civilization.</p>
	<p> Greece was followed by Rome, which left its mark on law, politics, language, engineering, architecture, government and many more key aspects in western civilisation. Expanding from their base in Italy beginning in the 3rd century BC, the Romans gradually expanded to eventually rule the entire Mediterranean basin and western Europe by the turn of the millennium. The Roman Republic ended in 27 BC, when Augustus proclaimed the Roman Empire. The two centuries that followed are known as the pax romana, a period of unprecedented peace, prosperity, and political stability in most of Europe.</p>
	<p> The empire continued to expand under emperors such as Antoninus Pius and Marcus Aurelius, who spent time on the Empire's northern border fighting Germanic, Pictish and Scottish tribes. The Empire began to decline in the 3rd century, particularly in the west. Christianity was legalised by Constantine I in 313 AD after three centuries of imperial persecution. Constantine also permanently moved the capital of the empire from Rome to the city of Byzantium, which was renamed Constantinople in his honour (modern-day Istanbul) in 330 AD. Christianity became the sole official religion of the empire in 380 AD, and in 391-392 AD, the emperor Theodosius outlawed pagan religions. This is sometimes considered to mark the end of antiquity; alternatively antiquity is considered to end with the fall of the Western Roman Empire in 476 AD; the closure of the pagan Platonic Academy of Athens in 529 AD; or the rise of Islam in the early 7th century AD.</p>
	<br>
	<h3> Early Middle Ages</h3>
	<p> During the decline of the Roman Empire, Europe entered a long period of change arising from what historians call the "Age of Migrations". There were numerous invasions and migrations amongst the Ostrogoths, Visigoths, Goths, Vandals, Huns, Franks, Angles, Saxons, Slavs, Avars, Bulgars and, later on, the Vikings, Pechenegs, Cumans and Magyars. Renaissance thinkers such as Petrarch would later refer to this as the "Dark Ages". Isolated monastic communities were the only places to safeguard and compile written knowledge accumulated previously; apart from this very few written records survive and much literature, philosophy, mathematics, and other thinking from the classical period disappeared from Western Europe though they were preserved in the east, in the Byzantine Empire.</p>
	<p> While the Roman empire in the west continued to decline, Roman traditions and the Roman state remained strong in the predominantly Greek-speaking Eastern Roman Empire, also known as the Byzantine Empire. During most of its existence, the Byzantine Empire was the most powerful economic, cultural, and military force in Europe. Emperor Justinian I presided over Constantinople's first golden age: he established a legal code that forms the basis of many modern legal systems, funded the construction of the Hagia Sophia, and brought the Christian church under state control.</p>
	<p> From the 7th century onwards, as the Byzantines and neighbouring Sasanid Persians were severely weakened due the protracted, centuries-lasting and frequent Byzantine–Sasanian wars, the Muslim Arabs began to make inroads into historically Roman territory, taking the Levant and North Africa and making inroads into Asia Minor. In the mid 7th century AD, following the Muslim conquest of Persia, Islam penetrated into the Caucasus region. Over the next centuries Muslim forces took Cyprus, Malta, Crete, Sicily and parts of southern Italy. Between 711 and 720, most of the Iberian Peninsula was brought under Muslim rule — save for small areas in the northwest (Asturias) and largely Basque regions in the Pyrenees. This territory, under the Arabic name Al-Andalus, became part of the expanding Umayyad Caliphate. The unsuccessful second siege of Constantinople (717) weakened the Umayyad dynasty and reduced their prestige. The Umayyads were then defeated by the Frankish leader Charles Martel at the Battle of Poitiers in 732, which ended their northward advance.</p>
	<p> During the Dark Ages, the Western Roman Empire fell under the control of various tribes. The Germanic and Slav tribes established their domains over Western and Eastern Europe respectively. Eventually the Frankish tribes were united under Clovis I. Charlemagne, a Frankish king of the Carolingian dynasty who had conquered most of Western Europe, was anointed "Holy Roman Emperor" by the Pope in 800. This led in 962 to the founding of the Holy Roman Empire, which eventually became centred in the German principalities of central Europe.</p>
	<p> East Central Europe saw the creation of the first Slavic states and the adoption of Christianity (circa 1000 AD). The powerful West Slavic state of Great Moravia spread its territory all the way south to the Balkans, reaching its largest territorial extent under Svatopluk I and causing a series of armed conflicts with East Francia. Further south, the first South Slavic states emerged in the late 7th and 8th century and adopted Christianity: the First Bulgarian Empire, the Serbian Principality (later Kingdom and Empire), and the Duchy of Croatia (later Kingdom of Croatia). To the East, the Kievan Rus expanded from its capital in Kiev to become the largest state in Europe by the 10th century. In 988, Vladimir the Great adopted Orthodox Christianity as the religion of state. Further East, Volga Bulgaria became an Islamic state in the 10th century, but was eventually absorbed into Russia several centuries later.</p>
	<br>
	<h3> High and Late Middle Ages</h3>
	<p>The period between the year 1000 and 1300 is known as the High Middle Ages, during which the population of Europe experienced significant growth, culminating in the Renaissance of the 12th century. Economic growth, together with the lack of safety on the mainland trading routes, made possible the development of major commercial routes along the coast of the Mediterranean and Baltic Seas. The growing wealth and independence acquired by some coastal cities gave the Maritime Republics a leading role in the European scene.</p>
	<p> The Middle Ages on the mainland were dominated by the two upper echelons of the social structure: the nobility and the clergy. Feudalism developed in France in the Early Middle Ages and soon spread throughout Europe. A struggle for influence between the nobility and the monarchy in England led to the writing of the Magna Carta and the establishment of a parliament. The primary source of culture in this period came from the Roman Catholic Church. Through monasteries and cathedral schools, the Church was responsible for education in much of Europe.</p>
	<p> The Papacy reached the height of its power during the High Middle Ages. An East-West Schism in 1054 split the former Roman Empire religiously, with the Eastern Orthodox Church in the Byzantine Empire and the Roman Catholic Church in the former Western Roman Empire. In 1095 Pope Urban II called for a crusade against Muslims occupying Jerusalem and the Holy Land. In Europe itself, the Church organised the Inquisition against heretics. In Spain, the Reconquista concluded with the fall of Granada in 1492, ending over seven centuries of Islamic rule in the Iberian Peninsula.</p>
	<p> In the east a resurgent Byzantine Empire recaptured Crete and Cyprus from the Muslims and reconquered the Balkans. Constantinople was the largest and wealthiest city in Europe from the 9th to the 12th centuries, with a population of approximately 400,000. The Empire was weakened following the defeat at Manzikert and was weakened considerably by the sack of Constantinople in 1204, during the Fourth Crusade. Although it would recover Constantinople in 1261, Byzantium fell in 1453 when Constantinople was taken by the Ottoman Empire.</p>
	<p> In the 11th and 12th centuries, constant incursions by nomadic Turkic tribes, such as the Pechenegs and the Cuman-Kipchaks, caused a massive migration of Slavic populations to the safer, heavily forested regions of the north and temporarily halted the expansion of the Rus' state to the south and east.[90] Like many other parts of Eurasia, these territories were overrun by the Mongols.[91] The invaders, who became known as Tatars, were mostly Turkic-speaking peoples under Mongol suzerainty. They established the state of the Golden Horde with headquarters in Crimea, which later adopted Islam as a religion and ruled over modern-day southern and central Russia for more than three centuries.[92][93] After the collapse of Mongol dominions, the first Romanian states (principalities) emerged in the 14th century: Moldova and Walachia. Previously, these territories were under the successive control of Pechenegs and Cumans.[94] From the 12th to the 15th centuries, the Grand Duchy of Moscow grew from a small principality under Mongol rule to the largest state in Europe, overthrowing the Mongols in 1480 and eventually becoming the Tsardom of Russia. The state was consolidated under Ivan III the Great and Ivan the Terrible, steadily expanding to the east and south over the next centuries.</p>
	<p> The Great Famine of 1315–1317 was the first crisis that would strike Europe in the late Middle Ages. The period between 1348 and 1420 witnessed the heaviest loss. The population of France was reduced by half. Medieval Britain was afflicted by 95 famines, and France suffered the effects of 75 or more in the same period. Europe was devastated in the mid-14th century by the Black Death, one of the most deadly pandemics in human history which killed an estimated 25 million people in Europe alone—a third of the European population at the time.</p>
	<p> The plague had a devastating effect on Europe's social structure; it induced people to live for the moment as illustrated by Giovanni Boccaccio in The Decameron (1353). It was a serious blow to the Roman Catholic Church and led to increased persecution of Jews, foreigners, beggars and lepers. The plague is thought to have returned every generation with varying virulence and mortalities until the 18th century. During this period, more than 100 plague epidemics swept across Europe.</p>
	<br>
	<h3> Early modern period</h3>
	<p> The Renaissance was a period of cultural change originating in Florence and later spreading to the rest of Europe. The rise of a new humanism was accompanied by the recovery of forgotten classical Greek and Arabic knowledge from monastic libraries, often translated from Arabic into Latin. The Renaissance spread across Europe between the 14th and 16th centuries: it saw the flowering of art, philosophy, music, and the sciences, under the joint patronage of royalty, the nobility, the Roman Catholic Church, and an emerging merchant class. Patrons in Italy, including the Medici family of Florentine bankers and the Popes in Rome, funded prolific quattrocento and cinquecento artists such as Raphael, Michelangelo, and Leonardo da Vinci.</p>
	<p> Political intrigue within the Church in the mid-14th century caused the Western Schism. During this forty-year period, two popes—one in Avignon and one in Rome—claimed rulership over the Church. Although the schism was eventually healed in 1417, the papacy's spiritual authority had suffered greatly.</p>
	<p> The Church's power was further weakened by the Protestant Reformation (1517–1648), initially sparked by the works of German theologian Martin Luther, an attempt to start a reform within the Church. The Reformation also damaged the Holy Roman Emperor's influence, as German princes became divided between Protestant and Roman Catholic faiths.[113] This eventually led to the Thirty Years War (1618–1648), which crippled the Holy Roman Empire and devastated much of Germany, killing between 25 and 40 percent of its population.[114] In the aftermath of the Peace of Westphalia, France rose to predominance within Europe.</p>
	<p> The 17th century in southern, central and eastern Europe was a period of general decline.[ Central and Eastern Europe experienced more than 150 famines in a 200-year period between 1501 and 1700. From the Union of Krewo (1385) central and eastern Europe was dominated by Kingdom of Poland and Grand Duchy of Lithuania. Between 1648 and 1655 in the central and eastern Europe ended hegemony of the Polish–Lithuanian Commonwealth. From the 15th to 18th centuries, when the disintegrating khanates of the Golden Horde were conquered by Russia, Tatars from the Crimean Khanate frequently raided Eastern Slavic lands to capture slaves. Further east, the Nogai Horde and Kazakh Khanate frequently raided the Slavic-speaking areas of Russia, Ukraine and Poland for hundreds of years, until the Russian expansion and conquest of most of northern Eurasia (i.e. Eastern Europe, Central Asia and Siberia). Meanwhile, in the south, the Ottomans had conquered the Balkans by the 15th century, laying siege to Vienna in 1529. In the Battle of Lepanto in 1571, the Holy League checked Ottoman power in the Mediterranean. The Ottomans again laid siege to Vienna in 1683, but the Battle of Vienna permanently ended their advance into Europe, and marked the political hegemony of the Habsburg dynasty in central Europe.</p>
	<p> The Renaissance and the New Monarchs marked the start of an Age of Discovery, a period of exploration, invention, and scientific development. Among the great figures of the Western scientific revolution of the 16th and 17th centuries were Copernicus, Kepler, Galileo, and Isaac Newton. According to Peter Barrett, "It is widely accepted that 'modern science' arose in the Europe of the 17th century (towards the end of the Renaissance), introducing a new understanding of the natural world."[104] In the 15th century, Portugal and Spain, two of the greatest naval powers of the time, took the lead in exploring the world. Christopher Columbus reached the New World in 1492 and Vasco da Gama opened the ocean route to the East in 1498, and soon after the Spanish and Portuguese began establishing colonial empires in the Americas and Asia.[123] France, the Netherlands and England soon followed in building large colonial empires with vast holdings in Africa, the Americas, and Asia.</p>
	<br>
	<h3> 18th and 19th centuries</h3>
	<p>wo world wars and an economic depression dominated the first half of the 20th century. World War I was fought between 1914 and 1918. It started when Archduke Franz Ferdinand of Austria was assassinated by the Yugoslav nationalist Gavrilo Princip. Most European nations were drawn into the war, which was fought between the Entente Powers (France, Belgium, Serbia, Portugal, Russia, the United Kingdom, and later Italy, Greece, Romania, and the United States) and the Central Powers (Austria-Hungary, Germany, Bulgaria, and the Ottoman Empire). The war left more than 16 million civilians and military dead. Over 60 million European soldiers were mobilised from 1914 to 1918.</p>
	<p> Russia was plunged into the Russian Revolution, which threw down the Tsarist monarchy and replaced it with the communist Soviet Union. Austria-Hungary and the Ottoman Empire collapsed and broke up into separate nations, and many other nations had their borders redrawn. The Treaty of Versailles, which officially ended World War I in 1919, was harsh towards Germany, upon whom it placed full responsibility for the war and imposed heavy sanctions.</p>
	<p> Excess deaths in Russia over the course of World War I and the Russian Civil War (including the postwar famine) amounted to a combined total of 18 million. In 1932–1933, under Stalin's leadership, confiscations of grain by the Soviet authorities contributed to the second Soviet famine which caused millions of deaths; surviving kulaks were persecuted and many sent to Gulags to do forced labour. Stalin was also responsible for the Great Purge of 1937–38 in which the NKVD executed 681,692 people; millions of people were deported and exiled to remote areas of the Soviet Union.</p>
	<p> The social revolutions sweeping through Russia also affected other European nations following The Great War: in 1919, with the Weimar Republic in Germany, and the First Austrian Republic; in 1922, with Mussolini's one party fascist government in the Kingdom of Italy, and in Ataturk's Turkish Republic, adopting the Western alphabet, and state secularism. Economic instability, caused in part by debts incurred in the First World War and 'loans' to Germany played havoc in Europe in the late 1920s and 1930s. This and the Wall Street Crash of 1929 brought about the worldwide Great Depression. Helped by the economic crisis, social instability and the threat of communism, fascist movements developed throughout Europe placing Adolf Hitler in power of what became Nazi Germany.</p>
	<p> In 1933, Hitler became the leader of Germany and began to work towards his goal of building Greater Germany. Germany re-expanded and took back the Saarland and Rhineland in 1935 and 1936. In 1938, Austria became a part of Germany following the Anschluss. Later that year, following the Munich Agreement signed by Germany, France, the United Kingdom and Italy, Germany annexed the Sudetenland, which was a part of Czechoslovakia inhabited by ethnic Germans, and in early 1939, the remainder of Czechoslovakia was split into the Protectorate of Bohemia and Moravia, controlled by Germany, and the Slovak Republic. At the time, Britain and France preferred a policy of appeasement.</p>
	<p>With tensions mounting between Germany and Poland over the future of Danzig, the Germans turned to the Soviets, and signed the Molotov–Ribbentrop Pact, which allowed the Soviets to invade the Baltic states and parts of Poland and Romania. Germany invaded Poland on 1 September 1939, prompting France and the United Kingdom to declare war on Germany on 3 September, opening the European Theatre of World War II. The Soviet invasion of Poland started on 17 September and Poland fell soon thereafter. On 24 September, the Soviet Union attacked the Baltic countries and later, Finland. The British hoped to land at Narvik and send troops to aid Finland, but their primary objective in the landing was to encircle Germany and cut the Germans off from Scandinavian resources. Around the same time, Germany moved troops into Denmark. The Phoney War continued.</p>
	<p> In May 1940, Germany attacked France through the Low Countries. France capitulated in June 1940. By August Germany began a bombing offensive on Britain, but failed to convince the Britons to give up. In 1941, Germany invaded the Soviet Union in the Operation Barbarossa. On 7 December 1941 Japan's attack on Pearl Harbor drew the United States into the conflict as allies of the British Empire and other allied forces.</p>
	<p>After the staggering Battle of Stalingrad in 1943, the German offensive in the Soviet Union turned into a continual fallback. The Battle of Kursk, which involved the largest tank battle in history, was the last major German offensive on the Eastern Front. In 1944, British and American forces invaded France in the D-Day landings, opening a new front against Germany. Berlin finally fell in 1945, ending World War II in Europe. The war was the largest and most destructive in human history, with 60 million dead across the world.[168] More than 40 million people in Europe had died as a result of World War II, including between 11 and 17 million people who perished during the Holocaust. The Soviet Union lost around 27 million people (mostly civilians) during the war, about half of all World War II casualties. By the end of World War II, Europe had more than 40 million refugees. Several post-war expulsions in Central and Eastern Europe displaced a total of about 20 million people.</p>
	<p> World War I and especially World War II diminished the eminence of Western Europe in world affairs. After World War II the map of Europe was redrawn at the Yalta Conference and divided into two blocs, the Western countries and the communist Eastern bloc, separated by what was later called by Winston Churchill an "Iron Curtain". The United States and Western Europe established the NATO alliance and later the Soviet Union and Central Europe established the Warsaw Pact.</p>
	<p> The two new superpowers, the United States and the Soviet Union, became locked in a fifty-year-long Cold War, centred on nuclear proliferation. At the same time decolonisation, which had already started after World War I, gradually resulted in the independence of most of the European colonies in Asia and Africa. In the 1980s the reforms of Mikhail Gorbachev and the Solidarity movement in Poland accelerated the collapse of the Eastern bloc and the end of the Cold War. Germany was reunited, after the symbolic fall of the Berlin Wall in 1989, and the maps of Central and Eastern Europe were redrawn once more.</p>
	<p> European integration also grew after World War II. The Treaty of Rome in 1957 established the European Economic Community between six Western European states with the goal of a unified economic policy and common market. In 1967 the EEC, European Coal and Steel Community and Euratom formed the European Community, which in 1993 became the European Union. The EU established a parliament, court and central bank and introduced the euro as a unified currency. In 2004 and 2007, more Central and Eastern European countries began joining, expanding the EU to its current size of 28 European countries, and once more making Europe a major economical and political centre of power.</p>
	<br>
	<br>
	<h4> Geography</h4>
	<p> Europe makes up the western fifth of the Eurasian landmass. It has a higher ratio of coast to landmass than any other continent or subcontinent. Its maritime borders consist of the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean, Black, and Caspian Seas to the south. Land relief in Europe shows great variation within relatively small areas. The southern regions are more mountainous, while moving north the terrain descends from the high Alps, Pyrenees, and Carpathians, through hilly uplands, into broad, low northern plains, which are vast in the east. This extended lowland is known as the Great European Plain, and at its heart lies the North German Plain. An arc of uplands also exists along the north-western seaboard, which begins in the western parts of the islands of Britain and Ireland, and then continues along the mountainous, fjord-cut spine of Norway.</p>
	<p> This description is simplified. Sub-regions such as the Iberian Peninsula and the Italian Peninsula contain their own complex features, as does mainland Central Europe itself, where the relief contains many plateaus, river valleys and basins that complicate the general trend. Sub-regions like Iceland, Britain, and Ireland are special cases. The former is a land unto itself in the northern ocean which is counted as part of Europe, while the latter are upland areas that were once joined to the mainland until rising sea levels cut them off.</p>
	<br>
	<h3> Climate</h3>
	<p> Europe lies mainly in the temperate climate zones, being subjected to prevailing westerlies. The climate is milder in comparison to other areas of the same latitude around the globe due to the influence of the Gulf Stream. The Gulf Stream is nicknamed "Europe's central heating", because it makes Europe's climate warmer and wetter than it would otherwise be. The Gulf Stream not only carries warm water to Europe's coast but also warms up the prevailing westerly winds that blow across the continent from the Atlantic Ocean.</p>
	<p> Therefore, the average temperature throughout the year of Naples is 16 °C (61 °F), while it is only 12 °C (54 °F) in New York City which is almost on the same latitude. Berlin, Germany; Calgary, Canada; and Irkutsk, in the Asian part of Russia, lie on around the same latitude; January temperatures in Berlin average around 8 °C (14 °F) higher than those in Calgary, and they are almost 22 °C (40 °F) higher than average temperatures in Irkutsk. Similarly, northern parts of Scotland have a tempertate marine climate. The yearly average temperature in city of Inverness is 9.05 °C (48.29 °F). However, Churchill, Manitoba, Canada, is on roughly the same latitude and has an average temperature of −6.5 °C (20.3 °F), giving it a nearly subarctic climate.</p>
	<br>
	<h3> Geology</h3>
	<p> The geological history of Europe traces back to the formation of the Baltic Shield (Fennoscandia) and the Sarmatian craton, both around 2.25 billion years ago, followed by the Volgo–Uralia shield, the three together leading to the East European craton (≈ Baltica) which became a part of the supercontinent Columbia. Around 1.1 billion years ago, Baltica and Arctica (as part of the Laurentia block) became joined to Rodinia, later resplitting around 550 million years ago to reform as Baltica. Around 440 million years ago Euramerica was formed from Baltica and Laurentia; a further joining with Gondwana then leading to the formation of Pangea. Around 190 million years ago, Gondwana and Laurasia split apart due to the widening of the Atlantic Ocean. Finally, and very soon afterwards, Laurasia itself split up again, into Laurentia (North America) and the Eurasian continent. The land connection between the two persisted for a considerable time, via Greenland, leading to interchange of animal species. From around 50 million years ago, rising and falling sea levels have determined the actual shape of Europe, and its connections with continents such as Asia. Europe's present shape dates to the late Tertiary period about five million years ago.</p>
	<p> The geology of Europe is hugely varied and complex, and gives rise to the wide variety of landscapes found across the continent, from the Scottish Highlands to the rolling plains of Hungary. Europe's most significant feature is the dichotomy between highland and mountainous Southern Europe and a vast, partially underwater, northern plain ranging from Ireland in the west to the Ural Mountains in the east. These two halves are separated by the mountain chains of the Pyrenees and Alps/Carpathians. The northern plains are delimited in the west by the Scandinavian Mountains and the mountainous parts of the British Isles. Major shallow water bodies submerging parts of the northern plains are the Celtic Sea, the North Sea, the Baltic Sea complex and Barents Sea.</p>
	<p> The northern plain contains the old geological continent of Baltica, and so may be regarded geologically as the "main continent", while peripheral highlands and mountainous regions in the south and west constitute fragments from various other geological continents. Most of the older geology of western Europe existed as part of the ancient microcontinent Avalonia.</p>
	<br>
	<h3> Flora</h3>
	<p> Having lived side-by-side with agricultural peoples for millennia, Europe's animals and plants have been profoundly affected by the presence and activities of man. With the exception of Fennoscandia and northern Russia, few areas of untouched wilderness are currently found in Europe, except for various national parks.</p>
	<p> The main natural vegetation cover in Europe is mixed forest. The conditions for growth are very favourable. In the north, the Gulf Stream and North Atlantic Drift warm the continent. Southern Europe could be described as having a warm, but mild climate. There are frequent summer droughts in this region. Mountain ridges also affect the conditions. Some of these (Alps, Pyrenees) are oriented east-west and allow the wind to carry large masses of water from the ocean in the interior. Others are oriented south-north (Scandinavian Mountains, Dinarides, Carpathians, Apennines) and because the rain falls primarily on the side of mountains that is oriented towards the sea, forests grow well on this side, while on the other side, the conditions are much less favourable. Few corners of mainland Europe have not been grazed by livestock at some point in time, and the cutting down of the pre-agricultural forest habitat caused disruption to the original plant and animal ecosystems.</p>
	<p> Probably 80 to 90 percent of Europe was once covered by forest. It stretched from the Mediterranean Sea to the Arctic Ocean. Though over half of Europe's original forests disappeared through the centuries of deforestation, Europe still has over one quarter of its land area as forest, such as the broadleaf and mixed forests, taiga of Scandinavia and Russia, mixed rainforests of the Caucasus and the Cork oak forests in the western Mediterranean. During recent times, deforestation has been slowed and many trees have been planted. However, in many cases monoculture plantations of conifers have replaced the original mixed natural forest, because these grow quicker. The plantations now cover vast areas of land, but offer poorer habitats for many European forest dwelling species which require a mixture of tree species and diverse forest structure. The amount of natural forest in Western Europe is just 2–3% or less, in European Russia 5–10%. The country with the smallest percentage of forested area is Iceland (1%), while the most forested country is Finland (77%).[</p>
	<p> In temperate Europe, mixed forest with both broadleaf and coniferous trees dominate. The most important species in central and western Europe are beech and oak. In the north, the taiga is a mixed spruce–pine–birch forest; further north within Russia and extreme northern Scandinavia, the taiga gives way to tundra as the Arctic is approached. In the Mediterranean, many olive trees have been planted, which are very well adapted to its arid climate; Mediterranean Cypress is also widely planted in southern Europe. The semi-arid Mediterranean region hosts much scrub forest. A narrow east-west tongue of Eurasian grassland (the steppe) extends eastwards from Ukraine and southern Russia and ends in Hungary and traverses into taiga to the north.</p>
	<br>
	<h3> Fauna</h3>
	<p> Glaciation during the most recent ice age and the presence of man affected the distribution of European fauna. As for the animals, in many parts of Europe most large animals and top predator species have been hunted to extinction. The woolly mammoth was extinct before the end of the Neolithic period. Today wolves (carnivores) and bears (omnivores) are endangered. Once they were found in most parts of Europe. However, deforestation and hunting caused these animals to withdraw further and further. By the Middle Ages the bears' habitats were limited to more or less inaccessible mountains with sufficient forest cover. Today, the brown bear lives primarily in the Balkan peninsula, Scandinavia, and Russia; a small number also persist in other countries across Europe (Austria, Pyrenees etc.), but in these areas brown bear populations are fragmented and marginalised because of the destruction of their habitat. In addition, polar bears may be found on Svalbard, a Norwegian archipelago far north of Scandinavia. The wolf, the second largest predator in Europe after the brown bear, can be found primarily in Central and Eastern Europe and in the Balkans, with a handful of packs in pockets of Western Europe (Scandinavia, Spain, etc.).</p>
	<p> European wild cat, foxes (especially the red fox), jackal and different species of martens, hedgehogs, different species of reptiles (like snakes such as vipers and grass snakes) and amphibians, different birds (owls, hawks and other birds of prey).</p>
	<p> Important European herbivores are snails, larvae, fish, different birds, and mammals, like rodents, deer and roe deer, boars, and living in the mountains, marmots, steinbocks, chamois among others. A number of insects, such as the small tortoiseshell butterfly, add to the biodiversity.</p>
	<p> The extinction of the dwarf hippos and dwarf elephants has been linked to the earliest arrival of humans on the islands of the Mediterranean.</p>
	<p> Sea creatures are also an important part of European flora and fauna. The sea flora is mainly phytoplankton. Important animals that live in European seas are zooplankton, molluscs, echinoderms, different crustaceans, squids and octopuses, fish, dolphins, and whales.</p>
	<p> Biodiversity is protected in Europe through the Council of Europe's Bern Convention, which has also been signed by the European Community as well as non-European states.</p>
	<br>
	<br>
	<h4> Politics</h4>
	<p> The political map of Europe is substantially derived from the re-organisation of Europe following the Napoleonic Wars in 1815. The prevalent form of government in Europe is parliamentary democracy, in most cases in the form of Republic; in 1815, the prevalent form of government was still the Monarchy. Europe's remaining eleven monarchies are constitutional.</p>
	<p> European integration is the process of political, legal, economic (and in some cases social and cultural) integration of European states as it has been pursued by the powers sponsoring the Council of Europe since the end of World War II The European Union has been the focus of economic integration on the continent since its foundation in 1993. More recently, the Eurasian Economic Union has been established as a counterpart comprising former Soviet states.</p>
	<p> 28 European states are members of the politico-economic European Union, 26 of the border-free Schengen Area and 19 of the monetary union Eurozone. Among the smaller European organizations are the Nordic Council, the Benelux, the Baltic Assembly and the Visegrád Group.</p>
	<br>
	<br>
	<h4> Economy</h4>
	<p> As a continent, the economy of Europe is currently the largest on Earth and it is the richest region as measured by assets under management with over $32.7 trillion compared to North America's $27.1 trillion in 2008. In 2009 Europe remained the wealthiest region. Its $37.1 trillion in assets under management represented one-third of the world's wealth. It was one of several regions where wealth surpassed its precrisis year-end peak. As with other continents, Europe has a large variation of wealth among its countries. The richer states tend to be in the West; some of the Central and Eastern European economies are still emerging from the collapse of the Soviet Union and the breakup of Yugoslavia.</p>
	<p> The European Union, a political entity composed of 28 European states, comprises the largest single economic area in the world. 18 EU countries share the euro as a common currency. Five European countries rank in the top ten of the world's largest national economies in GDP (PPP). This includes (ranks according to the CIA): Germany (5), the UK (6), Russia (7), France (8), and Italy (10).There is huge disparity between many European countries in terms of their income. The richest in terms of GDP per capita is Monaco with its US$172,676 per capita (2009) and the poorest is Moldova with its GDP per capita of US$1,631 (2010). Monaco is the richest country in terms of GDP per capita in the world according to the World Bank report.</p>
	<br>
	<h3> Economic history</h3>
	<h2> Industrial growth (1760–1945)</h2>
	<p> Capitalism has been dominant in the Western world since the end of feudalism. From Britain, it gradually spread throughout Europe.[197] The Industrial Revolution started in Europe, specifically the United Kingdom in the late 18th century, and the 19th century saw Western Europe industrialise. Economies were disrupted by World War I but by the beginning of World War II they had recovered and were having to compete with the growing economic strength of the United States. World War II, again, damaged much of Europe's industries.</p>
	<h2> Cold War (1945–1991)</h2>
	<p> After World War II the economy of the UK was in a state of ruin, and continued to suffer relative economic decline in the following decades.[200] Italy was also in a poor economic condition but regained a high level of growth by the 1950s. West Germany recovered quickly and had doubled production from pre-war levels by the 1950s. France also staged a remarkable comeback enjoying rapid growth and modernisation; later on Spain, under the leadership of Franco, also recovered, and the nation recorded huge unprecedented economic growth beginning in the 1960s in what is called the Spanish miracle. The majority of Central and Eastern European states came under the control of the Soviet Union and thus were members of the Council for Mutual Economic Assistance (COMECON).[</p>
	<p> The states which retained a free-market system were given a large amount of aid by the United States under the Marshall Plan. The western states moved to link their economies together, providing the basis for the EU and increasing cross border trade. This helped them to enjoy rapidly improving economies, while those states in COMECON were struggling in a large part due to the cost of the Cold War. Until 1990, the European Community was expanded from 6 founding members to 12. The emphasis placed on resurrecting the West German economy led to it overtaking the UK as Europe's largest economy.</p>
	<h2> Reunification (1991–present)</h2>
	<p> With the fall of communism in Central and Eastern Europe in 1991, the post-socialist states began free market reforms: Poland, Hungary, and Slovenia adopted them reasonably quickly, while Ukraine and Russia are still in the process of doing so.</p>
	<p> After East and West Germany were reunited in 1990, the economy of West Germany struggled as it had to support and largely rebuild the infrastructure of East Germany.</p>
	<p> By the millennium change, the EU dominated the economy of Europe comprising the five largest European economies of the time namely Germany, the United Kingdom, France, Italy, and Spain. In 1999, 12 of the 15 members of the EU joined the Eurozone replacing their former national currencies by the common euro. The three who chose to remain outside the Eurozone were: the United Kingdom, Denmark, and Sweden. The European Union is now the largest economy in the world.[</p>
	<p> Figures released by Eurostat in 2009 confirmed that the Eurozone had gone into recession in 2008. It impacted much of the region. In 2010, fears of a sovereign debt crisis developed concerning some countries in Europe, especially Greece, Ireland, Spain, and Portugal. As a result, measures were taken, especially for Greece, by the leading countries of the Eurozone. The EU-27 unemployment rate was 10.3% in 2012. For those aged 15–24 it was 22.4%.</p>
	<br>
	<br>
	<h4> Demographics</h4>
	<p> In 2016, the population of Europe was estimated to be 738 million according to the United Nations, which is slightly more than one-ninth of the world's population. A century ago, Europe had nearly a quarter of the world's population. The population of Europe has grown in the past century, but in other areas of the world (in particular Africa and Asia) the population has grown far more quickly. Among the continents, Europe has a relatively high population density, second only to Asia. The most densely populated country in Europe (and in the world) is the microstate of Monaco.</p>
	<br>
	<h3> Ethnic groups</h3>
	<p> Pan and Pfeil (2004) count 87 distinct "peoples of Europe", of which 33 form the majority population in at least one sovereign state, while the remaining 54 constitute ethnic minorities. According to UN population projection, Europe's population may fall to about 7% of world population by 2050, or 653 million people (medium variant, 556 to 777 million in low and high variants, respectively). Within this context, significant disparities exist between regions in relation to fertility rates. The average number of children per female of child bearing age is 1.52. According to some sources, this rate is higher among Muslims in Europe. The UN predicts a steady population decline in Central and Eastern Europe as a result of emigration and low birth rates.</p>
	<br>
	<h3> Migration</h3>
	<p> Europe is home to the highest number of migrants of all global regions at 70.6 million people, the IOM's report said. In 2005, the EU had an overall net gain from immigration of 1.8 million people. This accounted for almost 85% of Europe's total population growth. The European Union plans to open the job centres for legal migrant workers from Africa. In 2008, 696,000 persons were given citizenship of an EU27 member state, a decrease from 707,000 the previous year.</p>
	<p> Emigration from Europe began with Spanish and Portuguese settlers in the 16th century, and French and English settlers in the 17th century. But numbers remained relatively small until waves of mass emigration in the 19th century, when millions of poor families left Europe.</p>
	<p> Today, large populations of European descent are found on every continent. European ancestry predominates in North America, and to a lesser degree in South America (particularly in Uruguay, Argentina, Chile and Brazil, while most of the other Latin American countries also have a considerable population of European origins). Australia and New Zealand have large European derived populations. Africa has no countries with European-derived majorities (or with the exception of Cape Verde and probably São Tomé and Príncipe, depending on context), but there are significant minorities, such as the White South Africans. In Asia, European-derived populations predominate in Northern Asia (specifically Russians), some parts of Northern Kazakhstan and Israel.</p>
	<br>
	<h3> Languages</h3>
	<p> European languages mostly fall within three Indo-European language groups: the Romance languages, derived from the Latin of the Roman Empire; the Germanic languages, whose ancestor language came from southern Scandinavia; and the Slavic languages.</p>
	<p> Slavic languages are most spoken by the number of native speakers in Europe, they are spoken in Central, Eastern, and Southeastern Europe. Romance languages are spoken primarily in south-western Europe as well as in Romania and Moldova, in Eastern Europe. Germanic languages are spoken in Northern Europe, the British Isles and some parts of Central Europe.</p>
	<p> Many other languages outside the three main groups exist in Europe. Other Indo-European languages include the Baltic group (that is, Latvian and Lithuanian), the Celtic group (that is, Irish, Scottish Gaelic, Manx, Welsh, Cornish, and Breton[182]), Greek, Armenian, and Albanian. In addition, a distinct non-Indo-European family of Uralic languages (Estonian, Finnish, and Hungarian) is spoken mainly in Estonia, Finland, and Hungary, while Kartvelian languages (Georgian, Mingrelian, and Svan), are spoken primarily in Georgia, and two other language families reside in the North Caucasus (termed Northeast Caucasian, most notably including Chechen, Avar and Lezgin and Northwest Caucasian, notably including Adyghe). Maltese is the only Semitic language that is official within the EU, while Basque is the only European language isolate. Turkic languages include Azerbaijani and Turkish, in addition to the languages of minority nations in Russia.</p>
	<p> Multilingualism and the protection of regional and minority languages are recognised political goals in Europe today. The Council of Europe Framework Convention for the Protection of National Minorities and the Council of Europe's European Charter for Regional or Minority Languages set up a legal framework for language rights in Europe.</p>
	<br>
	<br>
	<h4> Demographics</h4>
	<p> "Europe" as a cultural concept is substantially derived from the shared heritage of the Roman Empire and its culture. The boundaries of Europe were historically understood as those of Christendom (or more specifically Latin Christendom), as established or defended throughout the medieval and early modern history of Europe, especially against Islam, as in the Reconquista and the Ottoman wars in Europe.</p>
	<p> This shared cultural heritage is combined by overlapping indigenous national cultures and folklores, roughly divided into Slavic, Latin (Romance) and Germanic, but with several components not part of either of these group (notably Greek and Celtic). Cultural contact and mixtures characterise much of European regional cultures; Kaplan (2014) describes Europe as "embracing maximum cultural diversity at minimal geographical distances".</p>
	<p> Europe is also the birthplace of the Western civilisation and culture. Although differencies exist from south to north and from east to west, have the different European people learned to know about each other through thousands of years. Not always peacefully however. But this can for instance be seen in the translation of names of other people, other countries, provinces and as well in towns and cities. Vienna is called "Wien" in German, Rome is called "Roma" in Italian, Brittany is called "Bretagne" in French, Poland is called "Polska" in Polish and (most of) the Spaniards are calling themselves "Españoles" etc. Translations of such names (by Europeans) in other civilisations are very rare. (And those who appear to be translated are instead usually invented or changed by Europeans, like for instance Johannesburg) Music, classical as well as hymns, and art have crossed language borders for centuries. Europeans traditionally eat with a knife in their right hand and a fork in the left - which can be compared with how east Asians eat with chopsticks. Most Europeans consider Football as the most popular sport in their respective countries. Much of European culture can also be found in America and at other places which the Europeans have populated. Europeans have though also imported importaint matters, like the figures, from the Arabs. (And the Arabs had got them from the Persians, who had got them from Sanskrit) But almost all languages spoken in Europe gives credit to the Arabs for the figures. Also the use of inventions and science have spread across the continent from the "Old Greeks" like Archimedes and Pythagoras to Isaac Newton, Carl von Linneus, Niels Bohr and Wilhelm Röntgen, just to mention a few. And most of the exploration of the world must also be counted as a European invention which indeed has affected European culture.</p>
	<br>
	<h3> Religion</h3>
	<p> Historically, religion in Europe has been a major influence on European art, culture, philosophy and law.</p>
	<p> The largest religion in Europe is Christianity, with 76.2% of Europeans considering themselves Christians, including Catholic, Eastern Orthodox and various Protestant denominations. Among Protestants, the most popular are historically state-supported European denominations such as Lutheranism, Anglicanism and the Reformed faith. Other Protestant denominations such as historically significant ones like Anabaptists were never supported by any state and thus are not so widespread, as well as these newly arriving from the United States such as Pentecostalism, Adventism, Methodism, Baptists and various Evangelical Protestants; although Methodism and Baptists both have European origins. The notion of "Europe" and the "Western World" has been intimately connected with the concept of "Christianity and Christendom"; many even attribute Christianity for being the link that created a unified European identity.</p>
	<p> Christianity, including the Roman Catholic Church, has played a prominent role in the shaping of Western civilization since at least the 4th century, and for at least a millennium and a half, Europe has been nearly equivalent to Christian culture, even though the religion was inherited from the Middle East. Christian culture was the predominant force in western civilization, guiding the course of philosophy, art, and science.</p>
	<p> The second most popular religion is Islam (6%) concentrated mainly in the Balkans and eastern Europe (Bosnia and Herzegovina, Albania, Kosovo, Kazakhstan, North Cyprus, Turkey, Azerbaijan, North Caucasus, and the Volga-Ural region). Other religions, including Judaism, Hinduism, and Buddhism are minority religions (though Tibetan Buddhism is the majority religion of Russia's Republic of Kalmykia). The 20th century saw the revival of Neopaganism through movements such as Wicca and Druidry.</p>
	<p> Europe has become a relatively secular continent, with an increasing number and proportion of irreligious, atheist and agnostic people, who make up about 18.2% of Europe's population, actually the largest secular population in the Western world. There are a particularly high number of self-described non-religious people in the Czech Republic, Estonia, Sweden, former East Germany, and France.</p>
	`
},{
	title: "History",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Man",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Monarchy",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Money",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 10 (1765), pp. 644–648",
	wSource: "https://en.wikipedia.org/wiki/Money",
	eConn: ["money","value","silver","value","supply","demand","wheat","wine","value","goods","silver","worth","imaginary","value","ounces","worth","money","silver","gold","silver","weight","value","value","imaginary","silver","money"],
	wConn: ["commodity","money","paper","money","money","supply","gold","silver","money","value","money","financial","fiat","money","medium","exchange","legal","tender","central","bank","store","value","gold","coins"],
	eArt: `Money is a sign that represents the value, the measure of all useful goods, and that is given as the price of all things. We use a metal so that the sign, the measure, the price will be stable, so that it will be little consumed by use, and so that it may be greatly divided without being destroyed.
	<p> We seek earnestly to know: 1) whence money derives its value, 2) whether this value is variable and imaginary, 3) whether the sovereign should make alterations to the money , and set the ratio of the metals. In this essay we propose to resolve all these interesting questions by drawing on the wisdom of the author of the Considérations sur les finances .<p>
	<p> To avoid disputes about words, let us distinguish between the denomination or numerical value of money , which is arbitrary; its intrinsic value, which depends on its weight and degree of purity; and its accidental value, which depends on the commercial circumstances of the transaction by which one trades goods for money . Thus money can be defined as a piece of metal to which the prince gives a form, a name and a stamp, in order to certify its weight and standard in any exchange that might occur for all goods that men wish to place in trade.<p>
	<p> Mr. Boizard gives us a different idea of money , for he defines it as a piece of matter to which the public authority has given a weight and a fixed value, in order to serve as the price of all things in trade.<p>
	<p> Money does not receive its value from the public authority, as Mr. Boizard claims. Its stamp indicates its weight and standard. It demonstrates that the coin is composed of a certain amount of metal of a certain purity, but it does not give value. Rather the matter gives it its value.<p>
	<p> The prince may decide to call a coin of twenty sous [i.e., one livre] an écu, and require that it be accepted as four livres. This is a way to tax his subjects, who are obliged to accept it at this rate. Nevertheless he does not augment the value of the twenty-sou coin. It does indeed circulate as four livres, but then the livre is worth only what five sous [i.e., one-fourth livre] was worth before the revaluation.<p>
	<p> If the prince gave value to money , he could give the value of an écu to pewter, to lead or to other metals minted into one-ounce coins, and make them serve in trade as silver money currently does. But when the prince had given the form and name of an écu to an ounce of pewter, his subject would not give the value of an écu in merchandise for a pewter écu, because the matter from which it is made is not worth it. <p>
	<p> Money is not a fixed value, as Mr. Boizard also says, for even if the prince makes no alteration, and if the coins maintain the same weight and standard and are subject to the same price, still the value of money is variable.<p>
	<p> To prove this I will show whence goods derive their value, how this value is perceived, and how it changes.<p>
	<p> Goods derive their value from the uses to which they are employed. If they had no use they would have no value.<p>
	<p> The value of goods is higher or lower depending on their supply in proportion to demand. Water is not sold but given away because the supply is greater than the demand. Wine is sold because the demand for wine is greater than the supply.<p>
	<p> The value of goods changes when the supply or the demand changes. If the supply of wine is great, or if the demand for wine diminishes, then the price falls. If wine is scarce, or if the demand increases, then the price rises.<p>
	<p> The good or poor quality of goods, and the greater or lesser use to which they are employed, are assumed. When I say that their value is higher or lower depending on their supply in proportion to demand, the better or worse quality does not increase or reduce the price except to the extent that the difference in quality increases or reduces the demand.<p>
	<p> Example: If this year’s wine is not as good as it was last year, then the demand for wine will not be as great and the price will fall. But if wine is also less abundant, and if the decline in supply matches the decline in demand, then it will continue to be sold at the same price even though it is not as good. The decline in supply will increase the price just as the difference in quality will reduce it, and the supply thus has the same proportion to demand as it did the previous year.<p>
	<p> Water is more useful and necessary than wine. Thus neither the quality of goods nor the uses to which they are employed alter their price, except to the extent that the proportion of quality [ sic , for supply ( quantité )] to demand is altered. It follows that their value is greater or less depending on how the supply is proportioned to the demand. Their value changes when the supply or the demand changes. In the same way gold and silver, like other goods, derive their value from the uses to which they are employed.<p>
	<p> As money derives its value from the matters from which it is made, and as the value of these matters is variable, money is of variable value even if it maintains the same weight and standard and is subject to the same price. If the supply of the matters suffers any change of value, then the écu will have the same weight and standard and will circulate as the same number of livres or sous, but the supply of the sliver matter having increased, or the demand having decreased, the écu will not have the same value.<p>
	<p> If a unit of wheat is sold for twice as much money as it was fifty years ago, one imagines that wheat has become more expensive. Yet this difference in price may be the result of changes to the supply of or demand for money . In that case it is the money that has become cheaper.<p>
	<p> As long as coins maintain the same weight and standard, and are subject to the same prices, we take little note of changes to the value of money , or of the matter of gold and silver, but that does not mean that their value does not change. Neither the écu nor an ounce of silver is worth what it was a century ago. The value of all things changes, and the value of money has changed more than that of other goods. The increase in its supply since the discovery of the Indies has so diminished its value that ten ounces in matter or in coin is worth less than what one ounce was once worth.<p>
	<p> To convince oneself that what I am arguing is true, one may examine the prices of land, houses, wheat, wine and other goods before the discovery of the Indies. At that time a thousand ounces of silver, whether unminted or minted, purchased more of these goods than ten thousand would purchase today. The goods are not more expensive or have changed little. Since their supply is in nearly the same proportion to demand as it was, silver must be cheaper.<p>
	<p> Those who use silver plate think that they lose only the interest they forego on the quantity employed, and the cost of the tax and the manufacture, but they also lose the amount that the matter declines in value, and its value declines to the extent that its supply increases, so long as the demand does not increase accordingly. A family that has used ten thousand ounces of silver plate for two hundred years has lost on the value of its silver more than nine thousand ounces, besides the manufacture, the tax and the interest, because ten thousand ounces are worth less than what one thousand were worth at that time.<p>
	<p> The Indies Companies of England and Holland have exported a large amount of unminted and minted silver to the East Indies, and Europe also consumes it, which to some extent has supported its value. But despite this exportation and consumption, the great quantity imported has reduced its value by ninety percent.<p>
	<p> The supply of gold has increased more than its demand, and gold has fallen in value. But because its supply has not risen in the same proportion as silver, its value has not fallen as much. Two hundred years ago the ounce of gold in France was worth sixteen livres, five sous, four deniers, and the ounce of silver was worth one livre, twelve sous. An ounce of unminted or minted gold was thus worth ten ounces of silver. Today it is worth more than fifteen. Thus these metals are no longer worth what they were with respect to other goods, nor with respect to each other. Gold, though fallen in value, is worth half again as much in silver as it once was.<p>
	<p> On the basis of what I have just said, it is clear that the prince does not give value to money , as Mr. Boizard claims, for its value consists in the matter of which it is made. It is therefore clear that its value is not fixed, because experience shows that it has diminished since the discovery of the Indies by more than ninety percent.<p>
	<p> By these diminutions I am not referring to the weakenings of the coinage that princes have carried out. I am speaking only of the diminution of the [value of the] matter caused by the increase in their supply.<p>
	<p> When we come to examine these weakenings, we will discover that less than one part remains in fifty. That is to say, there was once as much silver in twenty sous [i.e., one livre] as there is now in fifty livres. This is proven by the ordinances concerning the manufacture of French sous in the year 755. At that time there was the same quantity of pure silver in one sou as there is now in the half-écu, which is worth fifty sous. But without going back so far, over the last two hundred years the silver coins have been weakened in France by about two-thirds of their value.<p>
	<p> Those whose income is payable in money have also suffered by the decline in interest. Before the discovery of the Indies, annuities were constituted at one-tenth [i.e., ten percent per annum]. Today they are at one-twentieth [i.e., five percent per annum]. A donation made two hundred years ago, intended for the upkeep of fifty people, today can barely support one. Suppose that the donation was mortgaged for a sum of ten thousand livres. Because money was scarce, annuities were constituted at one-tenth. At that time one thousand livres in interest could support fifty people. Due to its scarcity money was of greater value, but as it became more abundant due to the quantity of matter imported into Europe, interest fell to five percent. The interest on the mortgage has thus fallen from a thousand to five hundred livres. As a result of the weakenings that princes have carried out, there remains only the standard of silver in the money [but two-thirds less weight], which reduces the value of five hundred livres to 166 livres 13 s. 4 d., and since the matter itself fell in value by ninety percent, five hundred livres [in] weak currency are worth no more than what sixteen livres were worth two hundred years ago, and will purchase no more necessities than sixteen livres would have purchased. Based on these assumptions, a sum intended for the upkeep of fifty people can no longer support one person.<p>
	<p> The quantity of matter imported into Europe since the discovery of the Indies has not only disturbed the wealth and income of individuals, but has also disturbed states, which are no longer in the same proportion of force. Those that have profited most from trade with Spain abound in specie, while the others can barely sustain their previous condition.<p>
	<p> It is not surprising that Mr. Boizard, a Frenchman, erred in his ideas on money , but Mr. Locke, an Englishman and a profound thinker who made himself famous by his beautiful works on this subject, should not have fallen into a misconception similar to that [of] Mr. Boizard. He thinks that men by common consent have given an imaginary value to money.<p>
	<p> I cannot conceive how men of different nations, or even those of the same province, could agree to put an imaginary value upon anything, especially upon money , by which the value of all other goods is measured, and that is given as the price of all things, or that any one country would want to receive a value in exchange or payment for more than it was worth, or how that imaginary value could have been kept up.<p>
	<p> Suppose that in England money were received at an imaginary value, and that other nations had consented to receive it at that value, then the écu passing in England for sixty pence, should pass in Holland for sixty stivers, the penny and the stiver being nothing but numbers that one uses to count. But we see just the opposite: money is valued and received according to the quantity and quality of matters of which it is composed.<p>
	<p> Before silver was used as money , its value depended on the uses to which it was employed. It was received as money on the basis of what it was as matter. If silver had had no value before it was used as money , it would never have been so used. Who would have wanted to receive a matter of no value as the price of his goods? A pound of lead as money would be worth something, since lead has several uses when it is reduced to matter, but a pound of silver would be worthless if, reduced to matter, silver had no use as metal. So before it was employed as money , silver had a value that depended on the uses to which it was employed, and was received as money on the basis of its value as matter.<p>
	<p> Being used to make money it increases its value, but this additional value does not derive from the manufacture or minting, for unminted silver is worth as much as minted silver, and this value is no more imaginary than the value that it possessed before it was used to make money.<p>
	<p> Its first value, as metal, derived from the fact that silver had qualities that rendered it suitable for several uses to which it was employed. The additional value derived from the fact that this metal had qualities that rendered it appropriate to make money. These values are greater or less to the extent that the demand for this silver is proportioned to its supply.<p>
	<p> If either of these values is imaginary, than all value is imaginary, for goods have no value except from the uses to which they are employed, and according to their supply in proportion to demand.<p>
	<p> Let us see how and why silver has been used to make money .<p>
	<p> Before the use of money was known, goods were exchanged. This exchange was often very cumbersome. At that time there was no measure with which to determine the value that goods had proportionally to each other. For example, A wished to barter fifty bushels of wheat for wine. One could not easily determine the quantity of wine that A should receive for his fifty bushels of wheat. For though the proportion of wine to wheat might be known for the previous year, if the wheat and wine were no longer of the same quality, or if as the result of a good or bad harvest they were more or less abundant, then the supply of wheat and wine being no longer in the same proportion to demand, their proportional value had changed, and fifty bushels of wheat might be worth twice the quantity of wine that it was worth the year before.<p>
	<p> Since silver is capable of a certain standard, or in other words to be reduced to a certain degree of purity, being then little subject to changes in supply or demand, and as a result less variable in value, it was used as the middle term with which to determine the proportional value of goods. If fifty bushels of wheat were worth two hundred ounces of silver of a certain standard, and if two hundred ounces of silver of the same purity were worth thirty barrels of wine of the quality that A required in exchange, then thirty barrels of wine would be the equivalent of fifty bushels of wheat.<p>
	<p> The proportional value of goods delivered to different places was even more difficult to determine. For example, a hundred pieces of Dutch canvas were delivered at Amsterdam to the order of a London merchant. If the Amsterdam merchant wrote that one should deliver at London, to his order, the value of these hundred pieces of canvas in English woolens, then the value of these hundred pieces of canvas could be determined neither by the supply of English woolens nor by their value at Amsterdam, because these woolens were more valuable at Amsterdam than at London, where they were to be delivered. Reciprocally, the value of the English woolens could be determined neither by the supply of Dutch canvases nor by the value of these woolens [ sic , for canvases] at London, because the canvases were more valuable at London than at Amsterdam, where they were to be delivered.<p>
	<p> Silver being highly portable, and thus of nearly the same value in different places, was used as the measure with which to determine the proportion of goods delivered to different places. If at Amsterdam the hundred pieces of canvas were worth a thousand ounces of pure silver, and if at London a thousand ounces of pure silver were worth twenty pieces of woolen of the quality that the Dutch merchant required in exchange, then twenty of these pieces of woolen delivered at London were the equivalent of these hundred pieces of canvas delivered at Amsterdam.<p>
	<p> Contracts, promises, etc. , being payable in goods, gave rise to disputes because goods of the same sort differ greatly in value. Example: A lent fifty bushels of wheat to B, and B promised to return them a year later. A claimed that the wheat that B returned was not of the same quality as that which he had lent, and since wheat cannot be standardized there was no way to judge the loss suffered by A in receiving wheat of an inferior quality. But silver, which can be standardized, was used as the value for which one contracted. Thus the person who made a loan received a contract payable in so many ounces of silver at such a standard, thereby avoiding all dispute.<p>
	<p> It was difficult to find the goods that were required in exchange. Example: A had more wheat than he could consume and sought to barter it for wine, but since the region did not produce wine, in order to barter the wheat he was obliged to transport it to a place that had wine.<p>
	<p> Silver, being more portable, was used as the middle term by which goods could be more easily exchanged. Thus A bartered his wheat for silver and carried the silver to the place where he bought the wine he needed.<p>
	<p> Silver, along with its other qualities, being divisible without the loss of its value, as well as being portable, was better suited to these uses, and those who possessed goods that they did not immediately need converted them into silver. It was less cumbersome to store than other goods, its value was less subject to variation, and since it was more durable and divisible without loss of value, one could use all or part of it as the need arose. Thus unminted silver, having the necessary qualities, was employed to serve those uses that money serves today. Since it was capable of being stamped, princes established offices that purified it to a given standard and manufactured it. In this way the standard and the weight were known, and the inconvenience of weighing and refining it was spared.<p>
	<p> But the manufacture does not give value to money , and its value is not imaginary. Money receives its value from the matters of which it is composed, and its value is greater or less depending on the proportion of supply to demand. Its value is therefore real, like the value of wheat, wine and other goods. Admittedly, if men found some other metal more suitable than silver to make money , and to serve the other uses to which unminted silver is employed, such as making plate, and if this metal were cheap, then silver would lose much of its value and would no longer be worth the expense of extracting it from mines. In the same way if men found some beverage that was more agreeable, healthier and cheaper than wine, then grapevines would cease to be valued, and would not be worth the expense of cultivation. The land would then be used to cultivate that which supplanted the consumption of wine.<p>
	<p> It is not difficult to answer the third question, whether the sovereign should alter the money by weakening it, raising it or fixing the proportion between gold and silver. Experience shows that the first operation is harmful, the second and third are useless. All weakening of the kingdom’s money , far from attracting the coins and bullion of foreign countries, causes the transportation of the country’s coins, however weakened, as well as its bullion to foreign countries. By weakening I mean the minting fees, the taxes that princes levy on money [i.e., seigniorage duties], the raising of the coins and the reduction of their weight or standard.<p>
	<p> The raising of money does not increase its price. We have long been misled by this error, that the same quantity of specie, when raised, had the same effect it would have if its quantity were increased. If, by making the écu of three livres pass for four livres, we could actually increase the value of the écu, and if this raised écu produced the same effect that four livres produced when the écu was at three livres, then there would be nothing to say. But this idea is as if a man who had three hundred yards of cloth to cover the walls of his apartment imagined that by simply measuring these three hundred yards with a three-quarter yardstick he would have four hundred yards of cloth, yet his apartment would not be covered any more completely. Raising the coins causes them to be worth more livres, but only by making the livres less valuable.<p>
	<p> I assume that the ministers are aware that raising the coins does not make them more valuable, and that they alter the money only to save or raise funds for the prince, but they probably do not understand all the harmful consequences of these alterations.<p>
	<p> The ancients considered money sacred . It was minted in the temples. The Romans minted money at state expense. The same weight of matter and of coin of the same standard had the same value.<p>
	<p> The public authority, by minting money , is supposed to guarantee that the coins will be of a constant weight and standard, and receivable for the same number of livres, sous and deniers. Justice and honor oblige the prince, both toward his subjects and toward foreigners who trade with them, not to alter the money . It is the quantity and the quality of the matter that give value to the money , and not the price set by the prince. The matters that are suited to be used as money need to be minted, but the price of coins made of different matters should not be regulated by the prince.<p>
	<p> Nor should he fix the ratio between gold and silver, because it varies constantly, and in the meantime this alteration causes unprofitable shipments, or harms certain trades. It suffices that the mark of silver should be fixed, and the market, depending on its needs, will determine the price of the mark of gold. In England the price of the gold in a guinea is twenty shillings sterling, yet it passes in trade for twenty-one shillings sterling. Admittedly this is only possible where coin is minted at public expense, and this is the true means to attract gold and silver. But a general rule for states that would fix the [bimetallic] ratio is to avoid both the lowest and the highest.<p>
	<p> Some policy makers have claimed that, as a lower [bimetallic] ratio pays less for gold, and consequently attracts silver by preference, it is better suited for countries that trade with the East Indies. But one should also note that these countries have less advantage in their trade with nations who pay in gold. Today all [European] nations trade with the East Indies, and the re-exportation of these products is very limited. Thus this trade will become more and more unprofitable. In order to recoup its costs, it is essential to favor useful trade more and more.<p>
	<p> What constitutes the real value of a coin of money is the number of grains of pure gold or pure silver that it contains. A gold coin at 24 karats [ sic , for 23 karats] weighing one ounce contains [five] hundred fifty-two grains of pure gold and twenty-four grains of alloy. A gold coin of 22 karats weighing one ounce, one dram and two grains will have the same intrinsic value as the first coin, the only difference being the twenty-six grains of alloy that it contains more than the first coin, which count for nothing. Not that a goldsmith who needs 23-karat gold for his work will not pay more in the market for the 23-karat gold coin than for the other, due to the cost that it would require to refine the 22-karat coin, as well as the greater expense of minting the 23-karat coin as a result of the same cost. Mines do not ordinarily produce gold finer than 22 karats, besides which the use of very fine gold is rare in trade. We should also note that if one needed 24-karat gold, a 24-karat gold coin would cost as much because of its refinement as the 22-karat gold coin [would cost to refine].<p>
	<p> 1. John Locke, Some Considerations of the Consequences of the Lowering of Interest, and Raising the Value of Money (London: Churchil, 1692); Further Considerations Concerning Raising the Value of Money (London: Churchil, 1695).<p>
	<p> 2. Jean Boizard, Traité des monoyes, de leurs circonstances & dépendances (Paris: Coignard, 1692). For the passage here cited, see the article “Monoye” in the glossary (pages unnumbered) that Boizard includes with the front matter to the 3 rd edition, 2 vols (Paris: Le Febvre, 1711), vol. 1, and the 4 th edition, 2 vols (Paris: Coustelier, 1714), vol. 1.<p>
	<p> 3. Like most monetary economists of the eighteenth century, Jaucourt fails to anticipate the rise of modern fiat currencies, which (so long as they are not over-issued) can exhibit stable purchasing power despite their lack of intrinsic value.<p>
	<p> 4. To be precise, according to Jaucourt’s figures the bimetallic ratio in sixteenth-century France was 244/24, or roughly 10.17. At the time he was writing the official bimetallic ratio in Britain was 15.19, but in France it was only 14.58, as can be calculated from tables showing the silver and gold content of European coins in the article “Monnoies” in Encyclopédie méthodique: Commerce, 3 vols (Paris: Pankoucke, 1783-1784) vol. 17, pp. 270-271.<p>
	<p> 5. That is, the market (and legal) rate of interest having fallen to one-half its former level, the silver content of the coinage having been reduced to one-third its former weight, and the purchasing power of silver having fallen to one-tenth its former value, the purchasing power of the annual coupon earned from the annuity was now only one-sixtieth its former value, thus reducing a coupon of 1,000 livres to the equivalent value of 16 ⅔ livres. Like Locke, Jaucourt here asserts what John Maynard Keynes has called “twin quantity theories,” arguing that the money supply is inversely related to the interest rate as well as to the purchasing power of money, each of which he understands as a “price” of money. Keynes, The General Theory of Employment, Interest, and Money (NY: Harcourt Brace, 1936), p. 343. This quantity theory of interest was characteristic of mercantilist writings, but came to be rejected by many of the liberal economists of the eighteenth century, including David Hume, Adam Smith and Anne-Robert-Jacques Turgot.<p>
	<p> 6. Jaucourt’s critique of Locke depends in part on a misquotation, since Locke actually states that “Mankind [has] consented to put an imaginary Value upon Gold and Silver,” not upon money, the value of which derives (as for Jaucourt) from its intrinsic gold and silver content. Locke, Some Considerations, 2nd edn (London: Churchil, 1696), p. 31. (The same words do not appear in the comparable passage of Locke’s first edition of Some Considerations, p. 30.) See also Locke, Further Considerations, p. 1: “The intrinsic value of Silver, consider’d as Money, is that estimate which common consent has placed on it.”<p>
	<p> 7. This and the following five paragraphs are based heavily on a passage in John Law, Money and Trade Considered, with a Proposal for Supplying the Nation with Money (Edinburgh: Anderson, 1705), pp. 9-10. Jaucourt nowhere credits this source, perhaps because Law had such a poor reputation in France following the collapse of his financial “System” in the Mississippi Bubble of 1720.<p>
	<p> 8. In fact unminted silver was not worth as much as minted silver. Jaucourt here ignores the seigniorage duties that European states imposed on the minting of coin.<p>
	<p> 9. The mine (here translated “bushel”) was equivalent to about 79 liters, or more than two modern bushels. The muid (here translated “barrel”) varied in size from province to province. Jaucourt was probably thinking of the Paris muid, equivalent to about 268 liters. According to his figures, two liters of wine were thus worth about one liter of wheat. Emile Littré, Dictionnaire de la langue française, 4 vols (Paris: Hachette, 1873-1874), vol. 3, pp. 565, 664.<p>
	<p> 10. For the source of the first two sentences of this paragraph, see Claude Bouteroue, Recherches curieuses des monoyes de France depuis le commencement de la monarchie (Paris: Cramoisy, 1666), p. 10.<p>
	<p> 11. This confusingly worded paragraph alludes to the fact that Britain had at that time the highest bimetallic ratio in Europe, which created an incentive to transport the gold coins of other European countries to Britain and sell them to the mint. Of course it also created an incentive to export silver coins from Britain.<p>
	<p> 12. That is, a 22-karat coin weighing 602.18 grains contains as much pure gold as a 23-karat coin weighing 576 grains. There were 24 grains to the dram (denier) and 24 drams to the ounce.<p>`,
	wArt:`Money is any item or verifiable record that is generally accepted as payment for goods and services and repayment of debts in a particular country or socio-economic context, or is easily converted to such a form.[citation needed] The main functions of money are distinguished as: a medium of exchange; a unit of account; a store of value; and, sometimes, a standard of deferred payment. Any item or verifiable record that fulfills these functions can be considered as money.
	<p> Money is historically an emergent market phenomenon establishing a commodity money, but nearly all contemporary money systems are based on fiat money. Fiat money, like any check or note of debt, is without use value as a physical commodity. It derives its value by being declared by a government to be legal tender; that is, it must be accepted as a form of payment within the boundaries of the country, for "all debts, public and private".</p>
	<p> The money supply of a country consists of currency (banknotes and coins) and, depending on the particular definition used, one or more types of bank money (the balances held in checking accounts, savings accounts, and other types of bank accounts). Bank money, which consists only of records (mostly computerized in modern banking), forms by far the largest part of broad money in developed countries.</p>
	<h2> Etymology</h2>
	<p> The word "money" is believed to originate from a temple of Juno, on Capitoline, one of Rome's seven hills. In the ancient world Juno was often associated with money. The temple of Juno Moneta at Rome was the place where the mint of Ancient Rome was located. The name "Juno" may derive from the Etruscan goddess Uni (which means "the one", "unique", "unit", "union", "united") and "Moneta" either from the Latin word "monere" (remind, warn, or instruct) or the Greek word "moneres" (alone, unique).</p>
	<p> In the Western world, a prevalent term for coin-money has been specie, stemming from Latin in specie, meaning 'in kind'.</p>
	<p> History</p>
	<p> A 640 BC one-third stater electrum coin from Lydia</p>
	<p> Main article: History of money</p>
	<p> The use of barter-like methods may date back to at least 100,000 years ago, though there is no evidence of a society or economy that relied primarily on barter. Instead, non-monetary societies operated largely along the principles of gift economy and debt. When barter did in fact occur, it was usually between either complete strangers or potential enemies.</p>
	<p> Many cultures around the world eventually developed the use of commodity money. The Mesopotamian shekel was a unit of weight, and relied on the mass of something like 160 grains of barley. The first usage of the term came from Mesopotamia circa 3000 BC. Societies in the Americas, Asia, Africa and Australia used shell money – often, the shells of the cowry (Cypraea moneta L. or C. annulus L.). According to Herodotus, the Lydians were the first people to introduce the use of gold and silver coins. It is thought by modern scholars that these first stamped coins were minted around 650–600 BC.</p>
	<p> Song Dynasty Jiaozi, the world's earliest paper money</p>
	<p> The system of commodity money eventually evolved into a system of representative money.[citation needed] This occurred because gold and silver merchants or banks would issue receipts to their depositors – redeemable for the commodity money deposited. Eventually, these receipts became generally accepted as a means of payment and were used as money. Paper money or banknotes were first used in China during the Song Dynasty. These banknotes, known as "jiaozi", evolved from promissory notes that had been used since the 7th century. However, they did not displace commodity money, and were used alongside coins. In the 13th century, paper money became known in Europe through the accounts of travelers, such as Marco Polo and William of Rubruck. Marco Polo's account of paper money during the Yuan Dynasty is the subject of a chapter of his book, The Travels of Marco Polo, titled "How the Great Kaan Causeth the Bark of Trees, Made Into Something Like Paper, to Pass for Money All Over his Country." Banknotes were first issued in Europe by Stockholms Banco in 1661, and were again also used alongside coins. The gold standard, a monetary system where the medium of exchange are paper notes that are convertible into pre-set, fixed quantities of gold, replaced the use of gold coins as currency in the 17th-19th centuries in Europe. These gold standard notes were made legal tender, and redemption into gold coins was discouraged. By the beginning of the 20th century almost all countries had adopted the gold standard, backing their legal tender notes with fixed amounts of gold.</p>
	<p> After World War II and the Bretton Woods Conference, most countries adopted fiat currencies that were fixed to the U.S. dollar. The U.S. dollar was in turn fixed to gold. In 1971 the U.S. government suspended the convertibility of the U.S. dollar to gold. After this many countries de-pegged their currencies from the U.S. dollar, and most of the world's currencies became unbacked by anything except the governments' fiat of legal tender and the ability to convert the money into goods via payment. According to proponents of modern money theory, fiat money is also backed by taxes. By imposing taxes, states create demand for the currency they issue.</p>
	<p> In Money and the Mechanism of Exchange (1875), William Stanley Jevons famously analyzed money in terms of four functions: a medium of exchange, a common measure of value (or unit of account), a standard of value (or standard of deferred payment), and a store of value. By 1919, Jevons's four functions of money were summarized in the couplet:</p>
	<p> Money's a matter of functions four,</p>
	<p> A Medium, a Measure, a Standard, a Store.</p>
	<p> This couplet would later become widely popular in macroeconomics textbooks. Most modern textbooks now list only three functions, that of medium of exchange, unit of account, and store of value, not considering a standard of deferred payment as it is a distinguished function, but rather subsuming it in the others.</p>
	<p> There have been many historical disputes regarding the combination of money's functions, some arguing that they need more separation and that a single unit is insufficient to deal with them all. One of these arguments is that the role of money as a medium of exchange is in conflict with its role as a store of value: its role as a store of value requires holding it without spending, whereas its role as a medium of exchange requires it to circulate. Others argue that storing of value is just deferral of the exchange, but does not diminish the fact that money is a medium of exchange that can be transported both across space and time. The term "financial capital" is a more general and inclusive term for all liquid instruments, whether or not they are a uniformly recognized tender.</p>
	<p> Medium of exchange</p>
	<p> Main article: Medium of exchange</p>
	<p> When money is used to intermediate the exchange of goods and services, it is performing a function as a medium of exchange. It thereby avoids the inefficiencies of a barter system, such as the "coincidence of wants" problem. Money's most important usage is as a method for comparing the values of dissimilar objects.</p>
	<p> Measure of value</p>
	<p> Main article: Unit of account</p>
	<p> A unit of account (in economics) is a standard numerical monetary unit of measurement of the market value of goods, services, and other transactions. Also known as a "measure" or "standard" of relative worth and deferred payment, a unit of account is a necessary prerequisite for the formulation of commercial agreements that involve debt.</p>
	<p> Money acts as a standard measure and common denomination of trade. It is thus a basis for quoting and bargaining of prices. It is necessary for developing efficient accounting systems.</p>
	<p> Standard of deferred payment</p>
	<p> Main article: Standard of deferred payment</p>
	<p> While standard of deferred payment is distinguished by some texts, particularly older ones, other texts subsume this under other functions. A "standard of deferred payment" is an accepted way to settle a debt – a unit in which debts are denominated, and the status of money as legal tender, in those jurisdictions which have this concept, states that it may function for the discharge of debts. When debts are denominated in money, the real value of debts may change due to inflation and deflation, and for sovereign and international debts via debasement and devaluation.</p>
	<p> Store of value</p>
	<p> Main article: Store of value</p>
	<p> To act as a store of value, a money must be able to be reliably saved, stored, and retrieved – and be predictably usable as a medium of exchange when it is retrieved. The value of the money must also remain stable over time. Some have argued that inflation, by reducing the value of money, diminishes the ability of the money to function as a store of value.</p>
	<p> Money supply</p>
	<p> Main article: Money supply</p>
	<p> Money Base, M1 and M2 in the U.S. from 1981 to 2012</p>
	<p> Printing paper money at a printing press in Perm</p>
	<p> In economics, money is a broad term that refers to any financial instrument that can fulfill the functions of money (detailed above). These financial instruments together are collectively referred to as the money supply of an economy. In other words, the money supply is the number of financial instruments within a specific economy available for purchasing goods or services. Since the money supply consists of various financial instruments (usually currency, demand deposits and various other types of deposits), the amount of money in an economy is measured by adding together these financial instruments creating a monetary aggregate.</p>
	<p> Modern monetary theory distinguishes among different ways to measure the money supply, reflected in different types of monetary aggregates, using a categorization system that focuses on the liquidity of the financial instrument used as money. The most commonly used monetary aggregates (or types of money) are conventionally designated M1, M2 and M3. These are successively larger aggregate categories: M1 is currency (coins and bills) plus demand deposits (such as checking accounts); M2 is M1 plus savings accounts and time deposits under $100,000; and M3 is M2 plus larger time deposits and similar institutional accounts. M1 includes only the most liquid financial instruments, and M3 relatively illiquid instruments. The precise definition of M1, M2 etc. may be different in different countries.</p>
	<p> Another measure of money, M0, is also used; unlike the other measures, it does not represent actual purchasing power by firms and households in the economy. M0 is base money, or the amount of money actually issued by the central bank of a country. It is measured as currency plus deposits of banks and other institutions at the central bank. M0 is also the only money that can satisfy the reserve requirements of commercial banks.</p>
	<p> Market liquidity</p>
	<p> Main article: Market liquidity</p>
	<p> "Market liquidity" describes how easily an item can be traded for another item, or into the common currency within an economy. Money is the most liquid asset because it is universally recognised and accepted as the common currency. In this way, money gives consumers the freedom to trade goods and services easily without having to barter.</p>
	<p> Liquid financial instruments are easily tradable and have low transaction costs. There should be no (or minimal) spread between the prices to buy and sell the instrument being used as money.</p>
	<p> Types</p>
	<p> Currently, most modern monetary systems are based on fiat money. However, for most of history, almost all money was commodity money, such as gold and silver coins. As economies developed, commodity money was eventually replaced by representative money, such as the gold standard, as traders found the physical transportation of gold and silver burdensome. Fiat currencies gradually took over in the last hundred years, especially since the breakup of the Bretton Woods system in the early 1970s.</p>
	<p> Commodity</p>
	<p> Main article: Commodity money</p>
	<p> A 1914 British gold sovereign</p>
	<p> Many items have been used as commodity money such as naturally scarce precious metals, conch shells, barley, beads etc., as well as many other things that are thought of as having value. Commodity money value comes from the commodity out of which it is made. The commodity itself constitutes the money, and the money is the commodity. Examples of commodities that have been used as mediums of exchange include gold, silver, copper, rice, Wampum, salt, peppercorns, large stones, decorated belts, shells, alcohol, cigarettes, cannabis, candy, etc. These items were sometimes used in a metric of perceived value in conjunction to one another, in various commodity valuation or price system economies. Use of commodity money is similar to barter, but a commodity money provides a simple and automatic unit of account for the commodity which is being used as money. Although some gold coins such as the Krugerrand are considered legal tender, there is no record of their face value on either side of the coin. The rationale for this is that emphasis is laid on their direct link to the prevailing value of their fine gold content. American Eagles are imprinted with their gold content and legal tender face value.</p>
	<p> Representative</p>
	<p> Main article: Representative money</p>
	<p> In 1875, the British economist William Stanley Jevons described the money used at the time as "representative money". Representative money is money that consists of token coins, paper money or other physical tokens such as certificates, that can be reliably exchanged for a fixed quantity of a commodity such as gold or silver. The value of representative money stands in direct and fixed relation to the commodity that backs it, while not itself being composed of that commodity.</p>
	<p> Fiat</p>
	<p> Main article: Fiat money</p>
	<p> Gold coins are an example of legal tender that are traded for their intrinsic value, rather than their face value.</p>
	<p> Fiat money or fiat currency is money whose value is not derived from any intrinsic value or guarantee that it can be converted into a valuable commodity (such as gold). Instead, it has value only by government order (fiat). Usually, the government declares the fiat currency (typically notes and coins from a central bank, such as the Federal Reserve System in the U.S.) to be legal tender, making it unlawful not to accept the fiat currency as a means of repayment for all debts, public and private.</p>
	<p> Some bullion coins such as the Australian Gold Nugget and American Eagle are legal tender, however, they trade based on the market price of the metal content as a commodity, rather than their legal tender face value (which is usually only a small fraction of their bullion value).</p>
	<p> Fiat money, if physically represented in the form of currency (paper or coins) can be accidentally damaged or destroyed. However, fiat money has an advantage over representative or commodity money, in that the same laws that created the money can also define rules for its replacement in case of damage or destruction. For example, the U.S. government will replace mutilated Federal Reserve Notes (U.S. fiat money) if at least half of the physical note can be reconstructed, or if it can be otherwise proven to have been destroyed. By contrast, commodity money which has been lost or destroyed cannot be recovered.</p>
	<p> Coinage</p>
	<p> Main article: Coin</p>
	<p> These factors led to the shift of the store of value being the metal itself: at first silver, then both silver and gold, and at one point there was bronze as well. Now we have copper coins and other non-precious metals as coins. Metals were mined, weighed, and stamped into coins. This was to assure the individual taking the coin that he was getting a certain known weight of precious metal. Coins could be counterfeited, but they also created a new unit of account, which helped lead to banking. Archimedes' principle provided the next link: coins could now be easily tested for their fine weight of metal, and thus the value of a coin could be determined, even if it had been shaved, debased or otherwise tampered with (see Numismatics).</p>
	<p> In most major economies using coinage, copper, silver and gold formed three tiers of coins. Gold coins were used for large purchases, payment of the military and backing of state activities. Silver coins were used for midsized transactions, and as a unit of account for taxes, dues, contracts and fealty, while copper coins represented the coinage of common transaction. This system had been used in ancient India since the time of the Mahajanapadas. In Europe, this system worked through the medieval period because there was virtually no new gold, silver or copper introduced through mining or conquest. Thus the overall ratios of the three coinages remained roughly equivalent.</p>
	<p> Paper</p>
	<p> Main article: Banknote</p>
	<p> Huizi currency, issued in 1160</p>
	<p> In premodern China, the need for credit and for circulating a medium that was less of a burden than exchanging thousands of copper coins led to the introduction of paper money, commonly known today as banknotes. This economic phenomenon was a slow and gradual process that took place from the late Tang Dynasty (618–907) into the Song Dynasty (960–1279). It began as a means for merchants to exchange heavy coinage for receipts of deposit issued as promissory notes from shops of wholesalers, notes that were valid for temporary use in a small regional territory. In the 10th century, the Song Dynasty government began circulating these notes amongst the traders in their monopolized salt industry. The Song government granted several shops the sole right to issue banknotes, and in the early 12th century the government finally took over these shops to produce state-issued currency. Yet the banknotes issued were still regionally valid and temporary; it was not until the mid 13th century that a standard and uniform government issue of paper money was made into an acceptable nationwide currency. The already widespread methods of woodblock printing and then Pi Sheng's movable type printing by the 11th century was the impetus for the massive production of paper money in premodern China.</p>
	<p> Paper money from different countries</p>
	<p> At around the same time in the medieval Islamic world, a vigorous monetary economy was created during the 7th–12th centuries on the basis of the expanding levels of circulation of a stable high-value currency (the dinar). Innovations introduced by Muslim economists, traders and merchants include the earliest uses of credit, cheques, promissory notes, savings accounts, transactional accounts, loaning, trusts, exchange rates, the transfer of credit and debt, and banking institutions for loans and deposits.</p>
	<p> In Europe, paper money was first introduced in Sweden in 1661. Sweden was rich in copper, thus, because of copper's low value, extraordinarily big coins (often weighing several kilograms) had to be made. The advantages of paper currency were numerous: it reduced transport of gold and silver, and thus lowered the risks; it made loaning gold or silver at interest easier, since the specie (gold or silver) never left the possession of the lender until someone else redeemed the note; and it allowed for a division of currency into credit and specie backed forms. It enabled the sale of stock in joint stock companies, and the redemption of those shares in paper.</p>
	<p> However, these advantages held within them disadvantages. First, since a note has no intrinsic value, there was nothing to stop issuing authorities from printing more of it than they had specie to back it with. Second, because it increased the money supply, it increased inflationary pressures, a fact observed by David Hume in the 18th century. The result is that paper money would often lead to an inflationary bubble, which could collapse if people began demanding hard money, causing the demand for paper notes to fall to zero. The printing of paper money was also associated with wars, and financing of wars, and therefore regarded as part of maintaining a standing army. For these reasons, paper currency was held in suspicion and hostility in Europe and America. It was also addictive, since the speculative profits of trade and capital creation were quite large. Major nations established mints to print money and mint coins, and branches of their treasury to collect taxes and hold gold and silver stock.</p>
	<p> At this time both silver and gold were considered legal tender, and accepted by governments for taxes. However, the instability in the ratio between the two grew over the course of the 19th century, with the increase both in supply of these metals, particularly silver, and of trade. This is called bimetallism and the attempt to create a bimetallic standard where both gold and silver backed currency remained in circulation occupied the efforts of inflationists. Governments at this point could use currency as an instrument of policy, printing paper currency such as the United States Greenback, to pay for military expenditures. They could also set the terms at which they would redeem notes for specie, by limiting the amount of purchase, or the minimum amount that could be redeemed.</p>
	<p> Banknotes with a face value of 5000 of different currencies</p>
	<p> By 1900, most of the industrializing nations were on some form of gold standard, with paper notes and silver coins constituting the circulating medium. Private banks and governments across the world followed Gresham's Law: keeping gold and silver paid, but paying out in notes. This did not happen all around the world at the same time, but occurred sporadically, generally in times of war or financial crisis, beginning in the early part of the 20th century and continuing across the world until the late 20th century, when the regime of floating fiat currencies came into force. One of the last countries to break away from the gold standard was the United States in 1971.</p>
	<p> No country anywhere in the world today has an enforceable gold standard or silver standard currency system.</p>
	<p> Commercial bank</p>
	<p> Main article: Demand deposit</p>
	<p> A check, used as a means of converting funds in a demand deposit to cash</p>
	<p> Commercial bank money or demand deposits are claims against financial institutions that can be used for the purchase of goods and services. A demand deposit account is an account from which funds can be withdrawn at any time by check or cash withdrawal without giving the bank or financial institution any prior notice. Banks have the legal obligation to return funds held in demand deposits immediately upon demand (or 'at call'). Demand deposit withdrawals can be performed in person, via checks or bank drafts, using automatic teller machines (ATMs), or through online banking.</p>
	<p> Commercial bank money is created through fractional-reserve banking, the banking practice where banks keep only a fraction of their deposits in reserve (as cash and other highly liquid assets) and lend out the remainder, while maintaining the simultaneous obligation to redeem all these deposits upon demand. Commercial bank money differs from commodity and fiat money in two ways: firstly it is non-physical, as its existence is only reflected in the account ledgers of banks and other financial institutions, and secondly, there is some element of risk that the claim will not be fulfilled if the financial institution becomes insolvent. The process of fractional-reserve banking has a cumulative effect of money creation by commercial banks, as it expands money supply (cash and demand deposits) beyond what it would otherwise be. Because of the prevalence of fractional reserve banking, the broad money supply of most countries is a multiple larger than the amount of base money created by the country's central bank. That multiple (called the money multiplier) is determined by the reserve requirement or other financial ratio requirements imposed by financial regulators.</p>
	<p> The money supply of a country is usually held to be the total amount of currency in circulation plus the total value of checking and savings deposits in the commercial banks in the country. In modern economies, relatively little of the money supply is in physical currency. For example, in December 2010 in the U.S., of the $8853.4 billion in broad money supply (M2), only $915.7 billion (about 10%) consisted of physical coins and paper money.</p>
	<p> Electronic or digital</p>
	<p> Main article: Electronic money</p>
	<p> Many digital currencies, in particular Flooz and Beenz, had gained momentum before the Dot-com bubble of the early 2000s. Not much innovation occurred until the conception of Bitcoin in 2009, which introduced the concept of a cryptocurrency.</p>
	<p> Monetary policy</p>
	<p> Main article: Monetary policy</p>
	<p> US dollar banknotes</p>
	<p> When gold and silver are used as money, the money supply can grow only if the supply of these metals is increased by mining. This rate of increase will accelerate during periods of gold rushes and discoveries, such as when Columbus discovered the New World and brought back gold and silver to Spain, or when gold was discovered in California in 1848. This causes inflation, as the value of gold goes down. However, if the rate of gold mining cannot keep up with the growth of the economy, gold becomes relatively more valuable, and prices (denominated in gold) will drop, causing deflation. Deflation was the more typical situation for over a century when gold and paper money backed by gold were used as money in the 18th and 19th centuries.</p>
	<p> Modern day monetary systems are based on fiat money and are no longer tied to the value of gold. The control of the amount of money in the economy is known as monetary policy. Monetary policy is the process by which a government, central bank, or monetary authority manages the money supply to achieve specific goals. Usually the goal of monetary policy is to accommodate economic growth in an environment of stable prices. For example, it is clearly stated in the Federal Reserve Act that the Board of Governors and the Federal Open Market Committee should seek "to promote effectively the goals of maximum employment, stable prices, and moderate long-term interest rates."</p>
	<p> A failed monetary policy can have significant detrimental effects on an economy and the society that depends on it. These include hyperinflation, stagflation, recession, high unemployment, shortages of imported goods, inability to export goods, and even total monetary collapse and the adoption of a much less efficient barter economy. This happened in Russia, for instance, after the fall of the Soviet Union.</p>
	<p> Governments and central banks have taken both regulatory and free market approaches to monetary policy. Some of the tools used to control the money supply include:</p>
	<p> changing the interest rate at which the central bank loans money to (or borrows money from) the commercial banks</p>
	<p> •currency purchases or sales</p>
	<p> •increasing or lowering government borrowing</p>
	<p> •increasing or lowering government spending</p>
	<p> •manipulation of exchange rates</p>
	<p> •raising or lowering bank reserve requirements</p>
	<p> •regulation or prohibition of private currencies</p>
	<p> •taxation or tax breaks on imports or exports of capital into a country</p>
	<p> In the US, the Federal Reserve is responsible for controlling the money supply, while in the Euro area the respective institution is the European Central Bank. Other central banks with significant impact on global finances are the Bank of Japan, People's Bank of China and the Bank of England.</p>
	<p> For many years much of monetary policy was influenced by an economic theory known as monetarism. Monetarism is an economic theory which argues that management of the money supply should be the primary means of regulating economic activity. The stability of the demand for money prior to the 1980s was a key finding of Milton Friedman and Anna Schwartz supported by the work of David Laidler, and many others. The nature of the demand for money changed during the 1980s owing to technical, institutional, and legal factors[clarification needed] and the influence of monetarism has since decreased.</p>
	<p> Counterfeit</p>
	<p> Main article: Counterfeit money</p>
	<p> Counterfeit money is imitation currency produced without the legal sanction of the state or government. Producing or using counterfeit money is a form of fraud or forgery. Counterfeiting is almost as old as money itself. Plated copies (known as Fourrées) have been found of Lydian coins which are thought to be among the first western coins.[45] Before the introduction of paper money, the most prevalent method of counterfeiting involved mixing base metals with pure gold or silver. A form of counterfeiting is the production of documents by legitimate printers in response to fraudulent instructions. During World War II, the Nazis forged British pounds and American dollars. Today some of the finest counterfeit banknotes are called Superdollars because of their high quality and likeness to the real U.S. dollar. There has been significant counterfeiting of Euro banknotes and coins since the launch of the currency in 2002, but considerably less than for the U.S. dollar.</p>
	<p> Laundering</p>
	<p> Main article: Money laundering</p>
	<p> Money laundering is the process in which the proceeds of crime are transformed into ostensibly legitimate money or other assets. However, in a number of legal and regulatory systems the term money laundering has become conflated with other forms of financial crime, and sometimes used more generally to include misuse of the financial system (involving things such as securities, digital currencies, credit cards, and traditional currency), including terrorism financing, tax evasion and evading of international sanctions.</p>`
},{
	title: "Morals",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 10 (1765), p. 611",
	wSource: "https://en.wikipedia.org/wiki/Morality",
	eConn: ["monarchy","will","will","sight","will","privileges","will","politics","will","morals","government","morals","good","will","women","morals","women","idleness","vanity","morals","subjects","morals","subjects","idleness"],
	wConn: ["right","wrong","moral","development","moral","judgments","ethics","morality","intentional","harms","ethics","considerations","development","moral","theories","moral","conduct","western","religion","morality","psychology","development","principles","conduct"],
	eArt: `Morals, free actions of men, natural or acquired, good or bad, amenable by rule and direction.

	<p> Their variety with regard to many people of the world depends on the climate, religion, laws, government, needs, education, manners and examples. In each nation where one of these factors acts with more force, the others succumb to it.</p>

	<p> In order to verify all these truths, we will enter in the level of detail that this work will permit; but looking only at the different forms of government in temperate climates, we can deduce this consideration quite clearly through the morals of its citizens. Thus, in a republic that can only subsist through economic commerce, the simplicity of the morals , religious tolerance, love of frugality, thrift, self-interest and of avarice, should definitely dominate. In a limited monarchy, where each citizen takes part in the administration of the state, liberty will be regarded as a very great good, for which all wars will be undertaken and will not even be considered a bad thing; the people of this monarchy will be proud, generous, knowledgeable in the sciences and in politics, never losing sight of their privileges, even those of leisure and debauchery. In a rich absolute monarchy, where the women prescribe the tenor, honor, ambition, gallantry, taste for pleasures, vanity, softness, will be the distinctive characteristics of the subjects; and as this government produces idleness, this idleness corrupts the morals , giving birth in their place to the politeness of morals.</p>`,
	wArt:`Morality (from the Latin moralis "manner, character, proper behavior") is the differentiation of intentions, decisions and actions between those that are distinguished as proper and those that are improper.[1] Morality can be a body of standards or principles derived from a code of conduct from a particular philosophy, religion or culture, or it can derive from a standard that a person believes should be universal.[2] Morality may also be specifically synonymous with "goodness" or "rightness".
	<p> Moral philosophy includes moral ontology, or the origin of morals, as well as moral epistemology, or knowledge of morals. Different systems of expressing morality have been proposed, including deontological ethical systems which adhere to a set of established rules, and normative ethical systems which consider the merits of actions themselves. An example of normative ethical philosophy is the Golden Rule, which states that: "One should treat others as one would like others to treat oneself."[3]</p>
	<p> Immorality is the active opposition to morality (i.e. opposition to that which is good or right), while amorality is variously defined as an unawareness of, indifference toward, or disbelief in any set of moral standards or principles.[4][5][6]</p>
	<p> Immanuel Kant introduced the categorical imperative: "Act only according to that maxim whereby you can, at the same time, will that it should become a universal law".</p>
	<p> Main article: Ethics</p>
	<p> See also: Sittlichkeit</p>
	<p> Ethics (also known as moral philosophy) is the branch of philosophy which addresses questions of morality. The word "ethics" is "commonly used interchangeably with 'morality,' and sometimes it is used more narrowly to mean the moral principles of a particular tradition, group, or individual."[7] Likewise, certain types of ethical theories, especially deontological ethics, sometimes distinguish between ethics and morals: "Although the morality of people and their ethics amounts to the same thing, there is a usage that restricts morality to systems such as that of Immanuel Kant, based on notions such as duty, obligation, and principles of conduct, reserving ethics for the more Aristotelian approach to practical reasoning, based on the notion of a virtue, and generally avoiding the separation of 'moral' considerations from other practical considerations."[8]</p>
	<p> Descriptive and normative[edit]</p>
	<p> This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (January 2015) (Learn how and when to remove this template message)</p>
	<p> In its descriptive sense, "morality" refers to personal or cultural values, codes of conduct or social mores from a society that provides these codes of conduct in which it applies and is accepted by an individual. It does not connote objective claims of right or wrong, but only refers to that which is considered right or wrong. Descriptive ethics is the branch of philosophy which studies morality in this sense.[9]</p>
	<p> In its normative sense, "morality" refers to whatever (if anything) is actually right or wrong, which may be independent of the values or mores held by any particular peoples or cultures. Normative ethics is the branch of philosophy which studies morality in this sense.[9]</p>
	<p> Realism and anti-realism[edit]</p>
	<p> Philosophical theories on the nature and origins of morality (that is, theories of meta-ethics) are broadly divided into two classes:</p>
	<p> Moral realism is the class of theories which hold that there are true moral statements that report objective moral facts. For example, while they might concede that forces of social conformity significantly shape individuals' "moral" decisions, they deny that those cultural norms and customs define morally right behavior. This may be the philosophical view propounded by ethical naturalists, however not all moral realists accept that position (e.g. ethical non-naturalists).[10]</p>
	<p> Moral anti-realism, on the other hand, holds that moral statements either fail or do not even attempt to report objective moral facts. Instead, they hold that moral sentences are either categorically false claims of objective moral facts (error theory); claims about subjective attitudes rather than objective facts (ethical subjectivism); or else not attempts to describe the world at all but rather something else, like an expression of an emotion or the issuance of a command (non-cognitivism).</p>
	<p> Some forms of non-cognitivism and ethical subjectivism, while considered anti-realist in the robust sense used here, are considered realist in the sense synonymous with moral universalism. For example, universal prescriptivism is a universalist form of non-cognitivism which claims that morality is derived from reasoning about implied imperatives, and divine command theory and ideal observer theory are universalist forms of ethical subjectivism which claim that morality is derived from the edicts of a god or the hypothetical decrees of a perfectly rational being, respectively.</p>
	<p> Anthropology[edit]</p>
	<p> Tribal and territorial[edit]</p>
	<p> Celia Green made a distinction between tribal and territorial morality.[11] She characterizes the latter as predominantly negative and proscriptive: it defines a person's territory, including his or her property and dependents, which is not to be damaged or interfered with. Apart from these proscriptions, territorial morality is permissive, allowing the individual whatever behaviour does not interfere with the territory of another. By contrast, tribal morality is prescriptive, imposing the norms of the collective on the individual. These norms will be arbitrary, culturally dependent and 'flexible', whereas territorial morality aims at rules which are universal and absolute, such as Kant's 'categorical imperative' and Geisler's graded absolutism. Green relates the development of territorial morality to the rise of the concept of private property, and the ascendancy of contract over status.</p>
	<p> In-group and out-group[edit]</p>
	<p> Main article: Ingroups and outgroups</p>
	<p> Some observers hold that individuals apply distinct sets of moral rules to people depending on their membership of an "in-group" (the individual and those they believe to be of the same culture or race) or an "out-group" (people not entitled to be treated according to the same rules). Some biologists, anthropologists and evolutionary psychologists believe this in-group/out-group discrimination has evolved because it enhances group survival. This belief has been confirmed by simple computational models of evolution.[12] In simulations this discrimination can result in both unexpected cooperation towards the in-group and irrational hostility towards the out-group.[13] Gary R. Johnson and V.S. Falger have argued that nationalism and patriotism are forms of this in-group/out-group boundary. Jonathan Haidt has noted[14] that experimental observation indicating an in-group criterion provides one moral foundation substantially used by conservatives, but far less so by liberals.</p>
	<p> Comparing cultures[edit]</p>
	<p> Peterson and Seligman[15] approach the anthropological view looking across cultures, geo-cultural areas and across millennia. They conclude that certain virtues have prevailed in all cultures they examined. The major virtues they identified include wisdom / knowledge; courage; humanity; justice; temperance; and transcendence. Each of these includes several divisions. For instance humanity includes love, kindness, and social intelligence.</p>
	<p> Fons Trompenaars, author of Did the Pedestrian Die?, tested members of different cultures with various moral dilemmas. One of these was whether the driver of a car would have his friend, a passenger riding in the car, lie in order to protect the driver from the consequences of driving too fast and hitting a pedestrian. Trompenaars found that different cultures had quite different expectations, from none to definite.[16]</p>
	<p> John Newton, author of Complete Conduct Principles for the 21st Century[17] compared the Eastern and the Western cultures about morality. As stated in Complete Conduct Principles for the 21st Century, "One of the important objectives of this book is to blend harmoniously the fine souls regarding conduct in the Eastern and the Western cultures, to take the result as the source and then to create newer and better conduct principles to suit the human society of the new century, and to introduce a lot of Chinese fine conduct spirits to the Western world. It is hoped that this helps solve lots of problems the human society of the 21st century faces, including (but not limited to the Eastern and the Western cultures) what a single culture cannot."</p>
	<p> Evolution[edit]</p>
	<p> See also: Altruism § Evolutionary explanations, Evolution of morality, and Evolutionary ethics</p>
	<p> The development of modern morality is a process closely tied to sociocultural evolution. Some evolutionary biologists, particularly sociobiologists, believe that morality is a product of evolutionary forces acting at an individual level and also at the group level through group selection (although to what degree this actually occurs is a controversial topic in evolutionary theory). Some sociobiologists contend that the set of behaviors that constitute morality evolved largely because they provided possible survival and/or reproductive benefits (i.e. increased evolutionary success). Humans consequently evolved "pro-social" emotions, such as feelings of empathy or guilt, in response to these moral behaviors.</p>
	<p> On this understanding, moralities are sets of self-perpetuating and biologically-driven behaviors which encourage human cooperation. Biologists contend that all social animals, from ants to elephants, have modified their behaviors, by restraining immediate selfishness in order to improve their evolutionary fitness. Human morality, although sophisticated and complex relative to the moralities of other animals, is essentially a natural phenomenon that evolved to restrict excessive individualism that could undermine a group's cohesion and thereby reducing the individuals' fitness.[18]</p>
	<p> On this view, moral codes are ultimately founded on emotional instincts and intuitions that were selected for in the past because they aided survival and reproduction (inclusive fitness). Examples: the maternal bond is selected for because it improves the survival of offspring; the Westermarck effect, where close proximity during early years reduces mutual sexual attraction, underpins taboos against incest because it decreases the likelihood of genetically risky behaviour such as inbreeding.</p>
	<p> The phenomenon of reciprocity in nature is seen by evolutionary biologists as one way to begin to understand human morality. Its function is typically to ensure a reliable supply of essential resources, especially for animals living in a habitat where food quantity or quality fluctuates unpredictably. For example, some vampire bats fail to feed on prey some nights while others manage to consume a surplus. Bats that did eat will then regurgitate part of their blood meal to save a conspecific from starvation. Since these animals live in close-knit groups over many years, an individual can count on other group members to return the favor on nights when it goes hungry (Wilkinson, 1984)</p>
	<p> Marc Bekoff and Jessica Pierce (2009) have argued that morality is a suite of behavioral capacities likely shared by all mammals living in complex social groups (e.g., wolves, coyotes, elephants, dolphins, rats, chimpanzees). They define morality as "a suite of interrelated other-regarding behaviors that cultivate and regulate complex interactions within social groups." This suite of behaviors includes empathy, reciprocity, altruism, cooperation, and a sense of fairness.[19] In related work, it has been convincingly demonstrated that chimpanzees show empathy for each other in a wide variety of contexts.[20] They also possess the ability to engage in deception, and a level of social politics[21] prototypical of our own tendencies for gossip and reputation management.</p>
	<p> Christopher Boehm (1982)[22] has hypothesized that the incremental development of moral complexity throughout hominid evolution was due to the increasing need to avoid disputes and injuries in moving to open savanna and developing stone weapons. Other theories are that increasing complexity was simply a correlate of increasing group size and brain size, and in particular the development of theory of mind abilities.</p>
	<p> Neuroscience[edit]</p>
	<p> See also: Science of morality</p>
	<p> The brain areas that are consistently involved when humans reason about moral issues have been investigated by a quantitative large-scale meta-analysis of the brain activity changes reported in the moral neuroscience literature.[23] In fact, the neural network underlying moral decisions overlapped with the network pertaining to representing others' intentions (i.e., theory of mind) and the network pertaining to representing others' (vicariously experienced) emotional states (i.e., empathy). This supports the notion that moral reasoning is related to both seeing things from other persons' points of view and to grasping others' feelings. These results provide evidence that the neural network underlying moral decisions is probably domain-global (i.e., there might be no such things as a "moral module" in the human brain) and might be dissociable into cognitive and affective sub-systems.[23]</p>
	<p> Brain areas[edit]</p>
	<p> The explicit making of moral right and wrong judgments coincides with activation in the ventromedial prefrontal cortex (VMPC) while intuitive reactions to situations containing implicit moral issues activates the temporoparietal junction area.[24]</p>
	<p> Stimulation of the VMPC by transcranial magnetic stimulation, has been shown to inhibit the ability of human subjects to take into account intent when forming a moral judgment. According to this investigation, TMS did not disrupt participants' ability to make any moral judgment. On the contrary, moral judgments of intentional harms and non-harms were unaffected by TMS to either the RTPJ or the control site; presumably, however, people typically make moral judgments of intentional harms by considering not only the action's harmful outcome but the agent's intentions and beliefs. So why were moral judgments of intentional harms not affected by TMS to the RTPJ? One possibility is that moral judgments typically reflect a weighted function of any morally relevant information that is available at the time. On the basis of this view, when information concerning the agent's belief is unavailable or degraded, the resulting moral judgment simply reflects a higher weighting of other morally relevant factors (e.g., outcome). Alternatively, following TMS to the RTPJ, moral judgments might be made via an abnormal processing route that does not take belief into account. On either account, when belief information is degraded or unavailable, moral judgments are shifted toward other morally relevant factors (e.g., outcome). For intentional harms and non-harms, however, the outcome suggests the same moral judgment as the intention. Thus, the researchers suggest that TMS to the RTPJ disrupted the processing of negative beliefs for both intentional harms and attempted harms, but the current design allowed the investigators to detect this effect only in the case of attempted harms, in which the neutral outcomes did not afford harsh moral judgments on their own.[25]</p>
	<p> Similarly VMPC-impaired persons will judge an action purely on its outcome and are unable to take into account the intent of that action.[26]</p>
	<p> Mirror neurons[edit]</p>
	<p> Main article: Mirror neurons</p>
	<p> Mirror neurons are neurons in the brain that fire when another person is observed doing a certain action. The neurons fire in imitation of the action being observed, causing the same muscles to act minutely in the observer as are acting grossly in the person actually performing the action. Research on mirror neurons, since their discovery in 1996,[27] suggests that they may have a role to play not only in action understanding, but also in emotion sharing empathy. Cognitive neuro-scientist Jean Decety thinks that the ability to recognize and vicariously experience what another individual is undergoing was a key step forward in the evolution of social behavior, and ultimately, morality.[28] The inability to feel empathy is one of the defining characteristics of psychopathy, and this would appear to lend support to Decety's view.[29][30]</p>
	<p> Psychology[edit]</p>
	<p> See also: Kohlberg's stages of moral development and Jean Piaget § Education and development of morality</p>
	<p> Kohlberg Model of Moral Development</p>
	<p> In modern moral psychology, morality is considered to change through personal development. A number of psychologists have produced theories on the development of morals, usually going through stages of different morals. Lawrence Kohlberg, Jean Piaget, and Elliot Turiel have cognitive-developmental approaches to moral development; to these theorists morality forms in a series of constructive stages or domains. Social psychologists such as Martin Hoffman and Jonathan Haidt emphasize social and emotional development based on biology, such as empathy. Moral identity theorists, such as William Damon and Mordechai Nisan, see moral commitment as arising from the development of a self-identity that is defined by moral purposes: this moral self-identity leads to a sense of responsibility to pursue such purposes. Of historical interest in psychology are the theories of psychoanalysts such as Sigmund Freud, who believe that moral development is the product of aspects of the super-ego as guilt-shame avoidance.</p>
	<p> Because we are naturally prone to be empathic and moral, we have a sense of responsibility to pursue moral purposes,[31][32] we still, at least occasionally, engage in immoral behavior. Such behaviors jeopardize our moral self-image; however, when we engage in immoral behaviors we still feel as though we are moral individuals. Moral self-licensing attempts to explain this phenomenon and proposes that self-image security increases our likelihood to engage in immoral behavior. When our moral self-image is threatened, we can gain confidence from our past moral behavior. The more confident we are, the less we will worry about our future behavior which actually increases the likelihood that we will engage in immoral behaviors.[33][34]Monin and Miller (2001)[33] examined the moral self-licensing effect and found that when participants established credentials as non-prejudiced persons, they were more willing to express politically incorrect opinions despite the fact that the audience was unaware of their credentials.</p>
	<p> Morality and politics[edit]</p>
	<p> If morality is the answer to the question 'how ought we to live' at the individual level, politics can be seen as addressing the same question at the social level, though the political sphere raises additional problems and challenges.[35] It is therefore unsurprising that evidence has been found of a relationship between attitudes in morality and politics. Jonathan Haidt and Jesse Graham have studied the differences between liberals and conservatives, in this regard.[36][37][38] Haidt found that Americans who identified as liberals tended to value care and fairness higher than loyalty, respect and purity. Self-identified conservative Americans valued care and fairness less and the remaining three values more. Both groups gave care the highest over-all weighting, but conservatives valued fairness the lowest, whereas liberals valued purity the lowest. Haidt also hypothesizes that the origin of this division in the United States can be traced to geo-historical factors, with conservatism strongest in closely knit, ethnically homogenous communities, in contrast to port-cities, where the cultural mix is greater, thus requiring more liberalism.</p>
	<p> Group morality develops from shared concepts and beliefs and is often codified to regulate behavior within a culture or community. Various defined actions come to be called moral or immoral. Individuals who choose moral action are popularly held to possess "moral fiber", whereas those who indulge in immoral behavior may be labeled as socially degenerate[disambiguation needed]. The continued existence of a group may depend on widespread conformity to codes of morality; an inability to adjust moral codes in response to new challenges is sometimes credited with the demise of a community (a positive example would be the function of Cistercian reform in reviving monasticism; a negative example would be the role of the Dowager Empress in the subjugation of China to European interests). Within nationalist movements, there has been some tendency to feel that a nation will not survive or prosper without acknowledging one common morality, regardless of its content. Political Morality is also relevant to the behavior internationally of national governments, and to the support they receive from their host population. Noam Chomsky states that[39][40]</p>
	<p> ... if we adopt the principle of universality : if an action is right (or wrong) for others, it is right (or wrong) for us. Those who do not rise to the minimal moral level of applying to themselves the standards they apply to others—more stringent ones, in fact—plainly cannot be taken seriously when they speak of appropriateness of response; or of right and wrong, good and evil. In fact, one of the, maybe the most, elementary of moral principles is that of universality, that is, If something's right for me, it's right for you; if it's wrong for you, it's wrong for me. Any moral code that is even worth looking at has that at its core somehow.</p>
	<p> Morality and religion[edit]</p>
	<p> Main article: Morality and religion</p>
	<p> See also: Divine command theory, Morality without religion, and Secular ethics</p>
	<p> Religion and morality are not synonymous. Morality does not depend upon religion although for some this is "an almost automatic assumption".[41] According to The Westminster Dictionary of Christian Ethics, religion and morality "are to be defined differently and have no definitional connections with each other. Conceptually and in principle, morality and a religious value system are two distinct kinds of value systems or action guides."[42]</p>
	<p> Positions[edit]</p>
	<p> Within the wide range of moral traditions, religious value systems co-exist with contemporary secular frameworks such as consequentialism, freethought, humanism, utilitarianism, and others. There are many types of religious value systems. Modern monotheistic religions, such as Islam, Judaism, Christianity, and to a certain degree others such as Sikhism and Zoroastrianism, define right and wrong by the laws and rules set forth by their respective scriptures and as interpreted by religious leaders within the respective faith. Other religions spanning pantheistic to nontheistic tend to be less absolute. For example, within Buddhism, the intention of the individual and the circumstances should be accounted for to determine if an action is right or wrong.[43] A further disparity between the values of religious traditions is pointed out by Barbara Stoler Miller, who states that, in Hinduism, "practically, right and wrong are decided according to the categories of social rank, kinship, and stages of life. For modern Westerners, who have been raised on ideals of universality and egalitarianism, this relativity of values and obligations is the aspect of Hinduism most difficult to understand".[44]</p>
	<p> Religions provide different ways of dealing with moral dilemmas. For example, there is no absolute prohibition on killing in Hinduism, which recognizes that it "may be inevitable and indeed necessary" in certain circumstances.[45] In monotheistic traditions, certain acts are viewed in more absolute terms, such as abortion or divorce.[a] Religion is not always positively associated with morality. Philosopher David Hume stated that, "the greatest crimes have been found, in many instances, to be compatible with a superstitious piety and devotion; Hence it is justly regarded as unsafe to draw any inference in favor of a man's morals, from the fervor or strictness of his religious exercises, even though he himself believe them sincere."[46]</p>
	<p> Religious value systems can diverge from commonly-held contemporary moral positions, such as those on murder, mass atrocities, and slavery. For example, Simon Blackburn states that "apologists for Hinduism defend or explain away its involvement with the caste system, and apologists for Islam defend or explain away its harsh penal code or its attitude to women and infidels".[47] In regard to Christianity, he states that the "Bible can be read as giving us a carte blanche for harsh attitudes to children, the mentally handicapped, animals, the environment, the divorced, unbelievers, people with various sexual habits, and elderly women",[48] and notes morally suspect themes in the Bible's New Testament as well.[49][e] Christian apologists address Blackburn's viewpoints[50] and construe that Jewish laws in the Jewish Bible showed the evolution of moral standards towards protecting the vulnerable, imposing a death penalty on those pursuing slavery and treating slaves as persons and not property.[51] Elizabeth Anderson holds that "the Bible contains both good and evil teachings", and it is "morally inconsistent".[52] Humanists like Paul Kurtz believe that we can identify moral values across cultures, even if we do not appeal to a supernatural or universalist understanding of principles - values including integrity, trustworthiness, benevolence, and fairness. These values can be resources for finding common ground between believers and nonbelievers.[53]</p>
	<p> Empirical analyses[edit]</p>
	<p> A number of studies have been conducted on the empirics of morality in various countries, and the overall relationship between faith and crime is unclear.[b] A 2001 review of studies on this topic found "The existing evidence surrounding the effect of religion on crime is varied, contested, and inconclusive, and currently no persuasive answer exists as to the empirical relationship between religion and crime."[54] Phil Zuckerman's 2008 book, Society without God, notes that Denmark and Sweden, "which are probably the least religious countries in the world, and possibly in the history of the world", enjoy "among the lowest violent crime rates in the world [and] the lowest levels of corruption in the world".[55][c]</p>
	<p> Dozens of studies have been conducted on this topic since the twentieth century. A 2005 study by Gregory S. Paul published in the Journal of Religion and Society stated that, "In general, higher rates of belief in and worship of a creator correlate with higher rates of homicide, juvenile and early adult mortality, STD infection rates, teen pregnancy, and abortion in the prosperous democracies," and "In all secular developing democracies a centuries long-term trend has seen homicide rates drop to historical lows" with the exceptions being the United States (with a high religiosity level) and "theistic" Portugal.[56][d] In a response, Gary Jensen builds on and refines Paul's study.[57] His conclusion is that a "complex relationship" exists between religiosity and homicide "with some dimensions of religiosity encouraging homicide and other dimensions discouraging it". On April 26, 2012, the results of a study which tested their subjects' pro-social sentiments were published in the Social Psychological and Personality Science journal in which non-religious people had higher scores showing that they were more inclined to show generosity in random acts of kindness, such as lending their possessions and offering a seat on a crowded bus or train. Religious people also had lower scores when it came to seeing how much compassion motivated participants to be charitable in other ways, such as in giving money or food to a homeless person and to non-believers.</p>`
},{
	title: "Nobility",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 11 (1765), pp. 166–167",
	wSource: "https://en.wikipedia.org/wiki/Nobility",
	eConn: ["nobles","decide","nobility","time","nobility","people","monarchy","nobility","state","nobility","nobles","equal","nobility","state","nobility","prince","nobility","alone","monarchical","state","virtue","nobles","virtue","equal"],
	wConn: ["titles","nobility","countries","nobility","nobility","class","lower","rank","nobles","population","nobility","social","were","imperial","upper","class","official","descendant","noble","descent","nobility","republic","married","rank"],
	eArt: `Nobility. One might consider nobility , as does Chancellor Bacon, in two different ways, either as constituting part of a state, or as constituting the condition of individuals.</p>
	<p> As part of a state, all monarchy that does not possess nobility is pure tyranny: nobility enters in some manner into the essence of monarchy, the fundamental maxim of which is, no nobility , no monarch ; but one has a despot, as in Turkey.
	<p> Nobility tempers sovereignty, and by its own splendor accustoms the people to fix their eyes on and withstand the brilliance of royalty without being afraid. A great and powerful nobility adds to a prince's splendor, although it diminishes his power when it is itself too powerful. It is good for the prince and for justice that nobility not be too strong, and that it conserve at the same time enough estimable grandeur to repress popular insolence and to prevent it from attacking the majesty of the throne. In a monarchical state, the most natural subordinate intermediary power, is that of the nobility ; abolish its prerogatives, and you will soon have a popular state, or a despotic state.</p>
	<p> Honor governs nobility , by prescribing to it obedience to the will of the prince; but this honor dictates at the same time that the prince never command it to commit a dishonorable act. Nothing is prescribed more strongly to the nobility than serving the prince during wartime: that is the distinguished profession fitting to the nobility , for its hazards, its successes and even its misfortunes lead to greatness.</p>
	<p> It is thus necessary that in a monarchy laws work to support the nobility and to make it hereditary, not in order to be the line between the prince and the people, but to be the link between the two. The prerogatives accorded to nobility will belong to it alone under a monarchy, and will not pass to the people, if one does not wish to violate the principle of government, if one does not wish to diminish the power of the nobility and that of the people. However a too-numerous nobility ordinarily weakens a monarchical state; for in addition to being overly costly, it happens that most of the nobles will become poor over time, creating a kind of disproportion between honors and means.</p>
	<p> The nobles in an aristocracy tend to enjoy limitless authority; that is why if nobles exist in great number, one needs a senate to regulate those affairs that the body of nobles is unable to decide, and to prepare those that it will decide. It is as easy for a body of nobles to control other aristocrats as it is difficult for this body to curb its own self: such is the nature of this constitution, that it seems to place the same people under the governance of laws and then to remove them. Now such a body can restrict itself only in two ways, either by great virtue, which makes the nobles in a sense equal to their people, and may result in a sort of republic; or by a lesser virtue, that is a certain moderation that renders nobles at least equal to themselves, that preserves them.</p>
	<p> Both the extreme poverty of nobles and their exorbitant wealth are pernicious to aristocracy. To prevent their poverty, one must above all require them early on to pay their debts. To moderate their wealth requires wise and painless regulations, not confiscations, nor agrarian laws, nor abolition of debt, which create infinite evils.</p>
	<p> In an aristocracy, the law must remove primogeniture from among nobles , as established in Venice, so that by the continual division of inheritances, fortunes may always remain equal. There must be consequently no substitutions, no replacements, no transmissions, no adoptions: in a word, all the methods invented to support the nobility in monarchical states, tend to establish tyranny within the aristocracy.</p>
	<p> When laws have equalized families, they will still need to maintain union among them. Disputes among nobles must be promptly settled, or altercations between individuals become altercations between families. Arbiters could put an end to trials or prevent them from developing.</p>
	<p> Finally laws must not favor the distinctions that vanity places between families, on the vain pretext that they are more noble and older; that should left to the pettiness of individuals.</p>
	<p> Democracies have no need for nobility , they are even more peaceful when there are no noble families; for then one considers the thing proposed and not the individual proposing it; or when it happens that the individual is taken into account, it is only to the extent that he might be useful to the business at hand, and not because of his coat of arms and genealogy. The Swiss republic, for example, maintains itself very well despite the diversity of its religions and cantons, because utility and not respect hold it together. The government of the United Provinces possesses the advantage that equality among persons produces equality in the counsels, and thus taxes and contributions are paid with a better will.</p>
	<p> With regard to the nobility of individuals, one has a sort of respect for an old castle or for a building that has stood the test of time, or even for a tall and beautiful tree that is fresh and whole in spite of its age. How much more respect should one have for a noble and ancient family that has sustained itself despite the ravages of time? New nobility is the work of princely power, but ancient nobility is the work of time alone: the first inspires more talent, the second more transcendent grandeur.</p>
	<p> Those who are first raised to nobility ordinarily have more genius but less innocence than their descendants. The route to honor is crossed by torturous paths that one often follows rather than taking the straight road.</p>
	<p> Noble birth commonly stifles industry and emulation. Nobles do not have as far to go as do others in order to reach the highest levels; and he who is stopped while others rise ordinarily experiences feelings of envy. But since the nobility alone possesses the right to receive honors, this possession stifles the envy that would be felt if these honors were newly bestowed. Kings able to choose prudent and capable individuals from among their nobility find that doing so advantageously facilitates the task: the people obey them naturally, as men who are born to command. See Birth.</p>`,
	wArt:`Nobility is a social class, normally ranked immediately under royalty, that possesses more acknowledged privileges and higher social status than most other classes in a society, membership thereof typically being hereditary. The privileges associated with nobility may constitute substantial advantages over or relative to non-nobles, or may be largely honorary (e.g., precedence), and vary from country to country and era to era.
	<p> Historically, membership in the nobility and the prerogatives thereof have been regulated or acknowledged by the monarch or government, thereby distinguishing it from other sectors of a nation's upper class wherein wealth, lifestyle or affiliation may be the salient markers of membership. Nonetheless, nobility per se has rarely constituted a closed caste; acquisition of sufficient power, wealth, military prowess or royal favour has, with varying frequency, enabled commoners to ascend into the nobility.</p>
	<p> There is often a variety of ranks within the noble class. Legal recognition of nobility has been more common in monarchies, but nobility also existed in such regimes as the Dutch Republic (1581–1795), the Republic of Genoa (1005–1815) and the Republic of Venice (697–1797), and remains part of the legal social structure of some non-hereditary regimes, e.g., San Marino and the Vatican City in Europe. Hereditary titles often distinguish nobles from non-nobles, although in many nations most of the nobility have been un-titled, and a hereditary title need not ipso facto indicate nobility (e.g., vidame). Some countries have had non-hereditary nobility, such as the Empire of Brazil.</p>
	<p> History</p>
	<p> This section includes a list of references, related reading or external links, but its sources remain unclear because it lacks inline citations. Please help to improve this section by introducing more precise citations. (July 2013) (Learn how and when to remove this template message)</p>
	<p> Nobility offered protection in exchange for service</p>
	<p> The term derives from Latin nobilitas, the abstract noun of the adjective nobilis ("well-known, famous, notable"). In ancient Roman society, nobiles originated as an informal designation for the political governing class who had allied interests, including both patricians and plebeian families (gentes) with an ancestor who had risen to the consulship through his own merit (see novus homo, "new man").</p>
	<p> In modern usage, "nobility" is applied to the highest social class in pre-modern societies, excepting the ruling dynasty. In the feudal system (in Europe and elsewhere), the nobility were generally those who held a fief, often land or office, under vassalage, i.e., in exchange for allegiance and various, mainly military, services to a suzerain, who might be a higher-ranking nobleman or a monarch. It rapidly came to be seen as a hereditary caste, sometimes associated with a right to bear a hereditary title and, for example in pre-revolutionary France, enjoying fiscal and other privileges.</p>
	<p> While noble status formerly conferred significant privileges in most jurisdictions, by the 21st century it had become a largely honorary dignity in most societies, although a few, residual privileges may still be preserved legally (e.g., Netherlands, Spain, UK) and some Asian, Pacific and African cultures continue to attach considerable significance to formal hereditary rank or titles. (Compare the entrenched position and leadership expectations of the nobility of the Kingdom of Tonga.)</p>
	<p> Nobility is a historical, social and often legal notion, differing from high socio-economic status in that the latter is mainly based on income, possessions and/or lifestyle. Being wealthy or influential cannot, ipso facto, make one noble, nor are all nobles wealthy or influential (aristocratic families have lost their fortunes in various ways, and the concept of the 'poor nobleman' is almost as old as nobility itself).</p>
	<p> Various republics, including former Iron Curtain countries, Greece, Mexico, and Austria have expressly abolished the conferral and use of titles of nobility for their citizens. This is distinct from countries which have not abolished the right to inherit titles, but which do not grant legal recognition or protection to them, such as Germany and Italy, although Germany recognizes their use as part of the legal surname. Still other countries and authorities allow their use, but forbid attachment of any privilege thereto, e.g., Finland, Norway and the European Union, while French law also protects lawful titles against usurpation.</p>
	<p> Although many societies have a privileged upper class with substantial wealth and power, the status is not necessarily hereditary and does not entail a distinct legal status, nor differentiated forms of address.</p>
	<p> French aristocrats, c. 1774</p>
	<p> Noble privileges[edit]</p>
	<p> A French political cartoon of the three orders of feudal society (1789). The rural third estate carries the clergy and the nobility.</p>
	<p> Not all of the benefits of nobility derived from noble status per se. Usually privileges were granted or recognised by the monarch in association with possession of a specific title, office or estate. Most nobles' wealth derived from one or more estates, large or small, that might include fields, pasture, orchards, timberland, hunting grounds, streams, etc. It also included infrastructure such as castle, well and mill to which local peasants were allowed some access, although often at a price. Nobles were expected to live "nobly", that is, from the proceeds of these possessions. Work involving manual labour or subordination to those of lower rank (with specific exceptions, such as in military or ecclesiastic service) was either forbidden (as derogation from noble status) or frowned upon socially. On the other hand, membership in the nobility was usually a prerequisite for holding offices of trust in the realm and for career promotion, especially in the military, at court and often the higher functions in the government, judiciary and church.</p>
	<p> Prior to the French Revolution, European nobles typically commanded tribute in the form of entitlement to cash rents or usage taxes, labour and/or a portion of the annual crop yield from commoners or nobles of lower rank who lived or worked on the noble's manor or within his seigneurial domain. In some countries, the local lord could impose restrictions on such a commoner's movements, religion or legal undertakings. Nobles exclusively enjoyed the privilege of hunting. In France, nobles were exempt from paying the taille, the major direct tax. Peasants were not only bound to the nobility by dues and services, but the exercise of their rights was often also subject to the jurisdiction of courts and police from whose authority the actions of nobles were entirely or partially exempt. In some parts of Europe the right of private war long remained the privilege of every noble.[1]</p>
	<p> During the early Renaissance, duelling established the status of a respectable gentleman, and was an accepted manner of resolving disputes.[2] According to Ariel Roth, during the reign of Henry IV, over 4,000 French aristocrats were killed in duels "in an eighteen-year period" whilst a twenty-year period of Louis XIII's reign saw some eight thousand pardons for "murders associated with duels".[3]</p>
	<p> Since the end of World War I the hereditary nobility entitled to special rights has largely been abolished in the Western World as intrinsically discriminatory, and discredited as inferior in efficiency to individual meritocracy in the allocation of societal resources.[4] Nobility came to be associated with social rather than legal privilege, expressed in a general expectation of deference from those of lower rank. By the 21st century even that deference had become increasingly minimised.</p>
	<p> Ennoblement[edit]</p>
	<p> Hungarian hussar troops set up by the Hungarian nobility, during the Austro–Turkish War of 1787–1791.</p>
	<p> In France, a seigneurie (lordship) might include one or more manors surrounded by land and villages subject to a noble's prerogatives and disposition. Seigneuries could be bought, sold or mortgaged. If erected by the crown into, e.g., a barony or countship, it became legally entailed for a specific family, which could use it as their title. Yet most French nobles were untitled ("seigneur of Montagne" simply meant ownership of that lordship but not, if one was not otherwise noble, the right to use a title of nobility, as commoners often purchased lordships). Only a member of the nobility who owned a countship was allowed, ipso facto, to style himself as its comte, although this restriction came to be increasingly ignored as the ancien régime drew to its close.</p>
	<p> In other parts of Europe, sovereign rulers arrogated to themselves the exclusive prerogative to act as fons honorum within their realms. For example, in the United Kingdom royal letters patent are necessary to obtain a title of the peerage, which also carries nobility and formerly a seat in the House of Lords, but never came with automatic entail of land nor rights to the local peasants' output.</p>
	<p> Rank within the nobility[edit]</p>
	<p> Polish magnates 1576–1586</p>
	<p> Polish magnates 1697–1795</p>
	<p> Main article: Royal and noble ranks</p>
	<p> Nobility might be either inherited or conferred by a fons honorum. It is usually an acknowledged preeminence that is hereditary, i.e. the status descends exclusively to some or all of the legitimate, and usually male-line, descendants of a nobleman. In this respect, the nobility as a class has always been much more extensive than the primogeniture-based titled nobility, which included peerages in France and in the United Kingdom, grandezas in Portugal and Spain, and some noble titles in Belgium, Italy, the Netherlands, Prussia and Scandinavia. In Russia, Scandinavia and non-Prussian Germany, titles usually descended to all male-line descendants of the original titleholder, including females. In Spain, noble titles are now equally heritable by females and males. Noble estates, on the other hand, gradually came to descend by primogeniture in much of western Europe aside from Germany. In Eastern Europe, by contrast, with the exception of a few Hungarian estates, they usually descended to all sons or even all children[5]</p>
	<p> In France, some wealthy bourgeois, most particularly the members of the various parlements, were ennobled by the king, constituting the noblesse de robe. The old nobility of landed or knightly origin, the noblesse d'épée, increasingly resented the influence and pretensions of this parvenu nobility. In the last years of the ancien régime the old nobility pushed for restrictions of certain offices and orders of chivalry to noblemen who could demonstrate that their lineage had extended "quarterings", i.e. several generations of noble ancestry, to be eligible for offices and favors at court along with nobles of medieval descent, although historians such as William Doyle have disputed this so-called "Aristocratic Reaction".[6] Various court and military positions were reserved by tradition for nobles who could "prove" an ancestry of at least seize quartiers (16 quarterings), indicating exclusively noble descent (as displayed, ideally, in the family's coat of arms) extending back five generations (all 16 great-great grandparents).</p>
	<p> Hungarian count Nicholaus Eszterházy of Galántha (1583–1645)</p>
	<p> Italian Nobleman of the Fifteenth Century. Engraving from the so-called Mantegna Tarocchi, about 1465.</p>
	<p> This illustrates the traditional link in many countries between heraldry and nobility; in those countries where heraldry is used, nobles have almost always been armigerous, and have used heraldry to demonstrate their ancestry and family history. However, heraldry has never been restricted to the noble classes in most countries, and being armigerous does not necessarily demonstrate nobility. Scotland, however, is an exception.[7] In a number of recent cases in Scotland the Lord Lyon King of Arms has controversially (vis-à-vis Scotland's Salic law) granted the arms and allocated the chiefships of medieval noble families to female-line descendants of lords, even when they were not of noble lineage in the male line, while persons of legitimate male-line descent may still survive (e.g. the modern Chiefs of Clan MacLeod).</p>
	<p> In some nations, hereditary titles, as distinct from noble rank, were not always recognised in law, e.g., Poland's Szlachta. European ranks of nobility lower than baron or its equivalent, are commonly referred to as the petty nobility, although baronets of the British Isles are deemed titled gentry. Most nations traditionally had an untitled lower nobility in addition to titled nobles. An example is the landed gentry of the British Isles.[8][9] Unlike England's gentry, the Junkers of Germany, the noblesse de robe of France, the hidalgos of Spain and the nobili of Italy were explicitly acknowledged by the monarchs of those countries as members of the nobility, although untitled. In Scandinavia, the Benelux nations and Spain there are still untitled as well as titled families recognised in law as noble.</p>
	<p> In Hungary members of the nobility always theoretically enjoyed the same rights. In practice, however, a noble family's financial assets largely defined its significance. Medieval Hungary's concept of nobility originated in the notion that nobles were "free men", eligible to own land.[10] This basic standard explains why the noble population was relatively large, although the economic status of its members varied widely. Untitled nobles were not infrequently wealthier than titled families, while considerable differences in wealth were also to be found within the titled nobility. The custom of granting titles was introduced to Hungary in the 16th century by the House of Habsburg. Historically, once nobility was granted, if a nobleman served the monarch well he might obtain the title of baron, and might later be elevated to the rank of count. As in other countries of post-medieval central Europe, hereditary titles were not attached to a particular land or estate but to the noble family itself, so that all patrilineal descendants shared a title of baron or count (cf. peerage). Neither nobility nor titles could be transmitted through women.[11]</p>
	<p> Some con artists sell fake titles of nobility, often with impressive-looking documentation. This may be illegal, depending on local law. They are more often illegal in countries that actually have nobilities, such as European monarchies. In the United States, such commerce may constitute actionable fraud rather than criminal usurpation of an exclusive right to use of any given title by an established class.</p>
	<p> Other terms[edit]</p>
	<p> "Aristocrat" and aristocracy, in modern usage, refer colloquially and broadly to persons who inherit elevated social status, whether due to membership in the (formerly) official nobility or the monied upper class.</p>
	<p> Blue blood is an English idiom recorded since 1834 for noble birth or descent; it is also known as a translation of the Spanish phrase sangre azul, which described the Spanish royal family and other high nobility who claimed to be of Visigothic descent,[12] in contrast to the Moors. The idiom originates from ancient and medieval societies of Europe and distinguishes an upper class (whose superficial veins appeared blue through their untanned skin) from a working class of the time. The latter consisted mainly of agricultural peasants who spent most of their time working outdoors and thus had tanned skin, through which superficial veins appear less prominently.</p>
	<p> Robert Lacey explains the genesis of the blue blood concept:</p>
	<p> It was the Spaniards who gave the world the notion that an aristocrat's blood is not red but blue. The Spanish nobility started taking shape around the ninth century in classic military fashion, occupying land as warriors on horseback. They were to continue the process for more than five hundred years, clawing back sections of the peninsula from its Moorish occupiers, and a nobleman demonstrated his pedigree by holding up his sword arm to display the filigree of blue-blooded veins beneath his pale skin—proof that his birth had not been contaminated by the dark-skinned enemy.[13]</p>
	<p> Europe[edit]</p>
	<p> Russian boyars</p>
	<p> European nobility originated in the feudal/seignorial system that arose in Europe during the Middle Ages.[14][15] Originally, knights or nobles were mounted warriors who swore allegiance to their sovereign and promised to fight for him in exchange for an allocation of land (usually together with serfs living thereon). During the period known as the Military Revolution, nobles gradually lost their role in raising and commanding private armies, as many nations created cohesive national armies.</p>
	<p> The Battle of Tewkesbury in 1471. Large numbers of English nobility perished in the Wars of the Roses</p>
	<p> This was coupled with a loss of the socio-economic power of the nobility, owing to the economic changes of the Renaissance and the growing economic importance of the merchant classes, which increased still further during the Industrial Revolution. In countries where the nobility was the dominant class, the bourgeoisie gradually grew in power; a rich city merchant came to be more influential than a nobleman, and the latter sometimes sought inter-marriage with families of the former to maintain their noble lifestyles.</p>
	<p> However, in many countries at this time, the nobility retained substantial political importance and social influence: for instance, the United Kingdom's government was dominated by the nobility until the middle of the 19th century. Thereafter the powers of the nobility were progressively reduced by legislation. However, until 1999, all hereditary peers were entitled to sit and vote in the House of Lords. Since then, only 92 of them have this entitlement, of whom 90 are elected by the hereditary peers as a whole to represent the peerage.</p>
	<p> The countries with the highest proportion of nobles were Castile (probably 10%), Polish–Lithuanian Commonwealth (15% of an 18th-century population of 800,000), Spain (722,000 in 1768 which was 7–8% of the entire population) and other countries with lower percentages, such as Russia in 1760 with 500,000–600,000 nobles (2–3% of the entire population), and pre-revolutionary France where there were no more than 300,000 prior to 1789, which was 1% of the population (although some scholars believe this figure is an overestimate). In 1718 Sweden had between 10,000 and 15,000 nobles, which was 0.5% of the population. In Germany 0.01%.</p>
	<p> In the Kingdom of Hungary nobles made up 5% of the population.[16] All the nobles in 18th-century Europe numbered perhaps 3–4 million out of a total of 170–190 million inhabitants.[17][18]</p>
	<p> Asia[edit]</p>
	<p> Maratha Peshwa Madhavrao II, surrounded by nobles in his court in the 18th century India.</p>
	<p> In Korea, royalty and yangban aristocrats were carried in litters called gama. A Korean gama, circa 1890.</p>
	<p> An aristocratic family in Lhasa, Tibet in 1936.</p>
	<p> Emperor Farrukhsiyar Bestows a Jewel on a Nobleman</p>
	<p> Many peoples and nations have had noble or aristocratic classes of various kinds: these are so diverse that there may be no clear equivalents in other cultures' histories, and care in translation and context is important to minimize misconstrual, in particular when contrasting concepts and terminology with those derived from Western feudalism.</p>
	<p> For the historical hierarchy of the Indian subcontinent, see princely state.</p>
	<p> China[edit]</p>
	<p> In East Asia the system was often modelled on imperial China, the leading culture. Emperors conferred titles of nobility. Imperial descendants formed the highest class of ancient Chinese nobility, their status based upon the rank of the empress or concubine from which they descend maternally (as emperors were polygamous). Numerous titles such as Taizi (crown prince), and equivalents of "prince" were accorded, and due to complexities in dynastic rules, rules were introduced for Imperial descendants. The titles of the junior princes were gradually lowered in rank by each generation while the senior heir continued to inherit their father's titles.</p>
	<p> It was a custom in China for the new dynasty to ennoble and enfeoff a member of the dynasty which they overthrew with a title of nobility and a fief of land so that they could offer sacrifices to their ancestors, in addition to members of other preceding dynasties.</p>
	<p> China had a feudal system in the Shang and Zhou dynasties, which gradually gave way to a more bureaucratic one beginning in the Qin dynasty (221 BC). This continued through the Song dynasty, and by its peak power shifted from nobility to bureaucrats.</p>
	<p> This development was gradual and generally only completed in full by the Song dynasty. In the Han dynasty, for example, even though noble titles were no longer given to those other than the Emperor's relatives, the fact that the process of selecting officials was mostly based on a vouching system by current officials as officials usually vouched for their own sons or those of other officials meant that a de facto aristocracy continued to exist. This process was further deepened during the Three Kingdoms period with the introduction of the Nine-rank system.</p>
	<p> By the Sui dynasty, however, the institution of the Imperial examination system marked the transformation of a power shift towards a full bureaucracy, though the process would not be truly completed until the Song dynasty.</p>
	<p> Titles of nobility became symbolic along with a stipend while governance of the country shifted to scholar officials.</p>
	<p> In the Qing dynasty titles of nobility were still granted by the emperor, but served merely as honorifics based on a loose system of favors to the Qing emperor.</p>
	<p> Under a centralized system, the empire's governance was the responsibility of the Confucian-educated scholar-officials and the local gentry, while the literati were accorded gentry status. For male citizens, advancement in status was possible via garnering the top three positions in imperial examinations.</p>
	<p> The Qing appointed the Ming imperial descendants to the title of Marquis of Extended Grace.</p>
	<p> The oldest held continuous noble title in Chinese history was that held by the descendants of Confucius, as Duke Yansheng, which was renamed as the Sacrificial Official to Confucius in 1935 by the Republic of China. The title is held by Kung Tsui-chang. There is also a "Sacrificial Official to Mencius" for a descendant of Mencius, a "Sacrificial Official to Zengzi" for a descendant of Zengzi, and a "Sacrificial Official to Yan Hui" for a descendant of Yan Hui.</p>
	<p> The bestowal of titles was abolished upon the establishment of the People's Republic of China in 1949, as part of a larger effort to remove feudal influences and practises from Chinese society.</p>
	<p> Islamic world[edit]</p>
	<p> In some Islamic countries, there are no definite noble titles (titles of hereditary rulers being distinct from those of hereditary intermediaries between monarchs and commoners). Persons who can trace legitimate descent from Muhammad or the clans of Quraysh, as can members of several present or formerly reigning dynasties, are widely regarded as belonging to the ancient, hereditary Islamic nobility. In some Islamic countries they inherit (through mother or father) hereditary titles, although without any other associated privilege, e.g., variations of the title Sayyid and Sharif. Regarded as more religious than the general population, many people turn to them for clarification or guidance in religious matters.</p>
	<p> In Iran, historical titles of the nobility including Mirza, Khan, ed-Dowleh and Shahzada ("Son of a Shah), are now no longer recognised. An aristocratic family is now recognised by their family name, often derived from the post held by their ancestors, considering the fact that family names in Iran only appeared in the beginning of the 20th century. Sultans have been an integral part of Islamic history .</p>
	<p> During the Ottoman Empire in the Imperial Court and the provinces there were many Ottoman titles and appellations forming a somewhat unusual and complex system in comparison with the other Islamic countries. The bestowal of noble and aristocratic titles was widespread across the empire even after its fall by independent monarchs. One of the most elaborate examples is that of the Egyptian aristocracy's largest clan, the Abaza family.</p>
	<p> Japan[edit]</p>
	<p> Japanese samurai, 1798</p>
	<p> Medieval Japan developed a feudal system similar to the European system, where land was held in exchange for military service. The daimyō class, or hereditary landowning nobles, held great socio-political power. As in Europe, they commanded private armies made up of samurai, an elite warrior class; for long periods, these held the real power without a real central government, and often plunged the country into a state of civil war. The daimyō class can be compared to European peers, and the samurai to European knights, but important differences exist.</p>
	<p> Feudal title and rank were abolished during the Meiji Restoration in 1868, and was replaced by the kazoku, a five-rank peerage system after the British example, which granted seats in the upper house of the Imperial Diet; this ended in 1947 following Japan's defeat in World War II.</p>
	<p> Philippines[edit]</p>
	<p> Left to right: Images from the Boxer Codex illustrating an ancient Filipino Nobilities wearing the distinctive colors of their social status: [1] a Visayan noble couple, [2] a Visayan royal couple, [3] a native princess, and [4] a Tagalog nobleman and his consort.</p>
	<p> Like other Southeast Asian countries, many regions in the Philippines have indigenous nobility, partially influenced by Hindu, Chinese, and Islamic custom. Since ancient times, Datu was the common title of a chief or monarch of the many pre-colonial principalities and sovereign dominions throughout the isles; in some areas the term Apo was also used.[19] With the titles Sultan and Rajah, Datu (and its Malay cognate, Datok) are currently used in some parts of the Philippines, Indonesia, Malaysia and Brunei. These titles are the rough equivalents of European titles, albeit dependent on the actual wealth and prestige of the bearer.</p>
	<p> Upon the islands' Christianisation, the datus retained governance of their territories despite annexation to the Spanish Empire. In a law signed 11 June 1594,[20] King Philip II of Spain ordered that the indigenous rulers continue to receive the same honours and privileges accorded them prior their conversion to Catholicism. The baptised nobility subsequently coalesced into the exclusive, landed ruling class of the lowlands known as the Principalía.</p>
	<p> On 22 March 1697, King Charles II of Spain confirmed the privileges granted by his predecessors (in Title VII, Book VI of the Laws of the Indies)[21] to indigenous nobilities of the Crown colonies, including the Principales of the Philippines, and extended to them and to their descendants the preeminence and honors customarily attributed to the Hidalgos of Castile.[22]</p>
	<p> The recognition of the rights and privileges of the Filipino Principalía as equivalent to those of the Hijosdalgos of Castile seems to facilitate entrance of Filipino nobles into institutions of under the Spanish Crown, either civil or religious, which required proofs of nobility. However, such approximation might not be correct since in reality, although the principales were vassals of the Crown, their rights as sovereign in their former dominions were guaranteed by the Laws of the Indies, more particularly the Royal Decree of Philip II of 11 June 1594, which Charles II confirmed for the purpose stated above in order to satisfy the requirements of the existing laws in the Peninsula. It must be recalled that ever since the beginning of the colonialization, the conquistador Miguel López de Legazpi did not strip the ancient sovereign rulers of the Archipelago (who vowed allegiance to the Spanish Crown) of their legitimate rights. Many of them accepted the Catholic religion and were his allies from the very beginning. He only demanded from these local rulers vassalage to the Spanish Crown.[23] An interesting question remains after the cessession of the Spanish rule in the Philippines, that is, what is the equivalent of the rank of the Filipino Principalía, freed from vassalage yet not able to exercise their sovereignty within the democratic society in the Archipelago?</p>
	<p> One logical conclusion would be the restoration of their ancient dignity as Datu — the historical dignity of local nobles respected and protected by the Indigenous Peoples' Rights Act of 1997, the existing pertinent law of the Philippines; and by a related international legislation, the Declaration on the Rights of Indigenous Peoples.</p>
	<p> See also: Lakan of the island of Luzon</p>
	<p> Africa[edit]</p>
	<p> Africa has a plethora of ancient lineages in its various constituent nations. Some, such as the numerous sharifian families of North Africa, the Keita dynasty of Mali, the Solomonic dynasty of Ethiopia and the Sherbro Tucker clan of Sierra Leone, claim descent from notables from outside of the continent. Most, such as those composed of the descendants of Shaka and Moshoeshoe of Southern Africa, belong to peoples that have been resident in the continent for millennia. Generally their royal or noble status is recognized by and derived from the authority of traditional custom. A number of them also enjoy either a constitutional or a statutory recognition of their high social positions.</p>
	<p> Ethiopia[edit]</p>
	<p> Ethiopia has a nobility that is almost as old as the country itself. Throughout the history of the Ethiopian Empire most of the titles of nobility have been tribal and/or military in nature. However the Ethiopian nobility resembled its European counterparts in some respects; until 1855, when Tewodros II ended the Zemene Mesafint its aristocracy was organised similarly to the feudal system in Europe during the Middle Ages. For more than seven centuries, Ethiopia (or Abyssinia, as it was then known) was made up of many small kingdoms, principalities, emirates and imamates, which owed their allegiance to the nəgusä nägäst (literally "King of Kings"). Despite its being a Christian monarchy, various Muslim states paid tribute to the emperors of Ethiopia for centuries: including the Adal Sultanate, the Emirate of Harar, and the Awsa sultanate.</p>
	<p> Ethiopian nobility were divided into two different categories: Mesafint ("prince"), the hereditary nobility that formed the upper echelon of the ruling class; and the Mekwanin ("governor") who were appointed nobles, often of humble birth, who formed the bulk of the nobility (cf. the Ministerialis of the Holy Roman Empire). In Ethiopia there were titles of nobility among the Mesafint borne by those at the apex of medieval Ethiopian society. The highest royal title (after that of emperor) was Negus ("king") which was held by hereditary governors of the provinces of Begemder, Shewa, Gojjam, and Wollo. The next highest seven titles were Ras, Dejazmach, Fit'awrari, Grazmach, Qenyazmach, Azmach and Balambaras. The title of Le'ul Ras was accorded to the heads of various noble families and cadet branches of the Solomonic dynasty, such as the princes of Gojjam, Tigray, and Selalle. The heirs of the Le'ul Rases were titled Le'ul Dejazmach, indicative of the higher status they enjoyed relative to Dejazmaches who were not of the blood imperial. There were various hereditary titles in Ethiopia: including that of Jantirar, reserved for males of the family of Empress Menen Asfaw who ruled over the mountain fortress of Ambassel in Wollo; Wagshum, a title created for the descendants of the deposed Zagwe dynasty; and Shum Agame, held by the descendants of Dejazmach Sabagadis, who ruled over the Agame district of Tigray. The vast majority of titles borne by nobles were not, however, hereditary.</p>
	<p> Despite being largely dominated by Christian elements, some Muslims obtained entrée into the Ethiopian nobility as part of their quest for aggrandizement during the 1800s. To do so they were generally obliged to abandon their faith and some are believed to have feigned conversion to Christianity for the sake of acceptance by the old Christian aristocratic families. One such family, the Wara Seh (more commonly called the "Yejju dynasty") converted to Christianity and eventually wielded power for over a century, ruling with the sanction of the Solomonic emperors. The last such Muslim noble to join the ranks of Ethiopian society was Mikael of Wollo who converted, was made Negus of Wollo, and later King of Zion, and even married into the Imperial family. He lived to see his son, Iyasu V, inherit the throne in 1913—only to be deposed in 1916 because of his conversion to Islam.</p>
	<p> Madagascar[edit]</p>
	<p> The nobility in Madagascar are known as the Andriana. In much of Madagascar, before French colonization of the island, the Malagasy people were organised into a rigid social caste system, within which the Andriana exercised both spiritual and political leadership. The word "Andriana" has been used to denote nobility in various ethnicities in Madagascar: including the Merina, the Betsileo, the Betsimisaraka, the Tsimihety, the Bezanozano, the Antambahoaka and the Antemoro.</p>
	<p> The word Andriana has often formed part of the names of Malagasy kings, princes and nobles. Linguistic evidence suggests that the origin of the title Andriana is traceable back to an ancient Javanese title of nobility. Before the colonization by France in the 1890s, the Andriana held various privileges, including land ownership, preferment for senior government posts, free labor from members of lower classes, the right to have their tombs constructed within town limits, etc. The Andriana rarely married outside their caste: a high-ranking woman who married a lower-ranking man took on her husband's lower rank, but a high-ranking man marrying a woman of lower rank did not forfeit his status, although his children could not inherit his rank or property (cf. morganatic marriage).</p>
	<p> In 2011, the Council of Kings and Princes of Madagascar endorsed the revival of a Christian Andriana monarchy that would blend modernity and tradition.</p>
	<p> Nigeria[edit]</p>
	<p> Contemporary Nigeria has a class of traditional notables whose titles are tied to those of its reigning monarchs, the Nigerian traditional rulers. Though their functions are largely ceremonial, their titles are often centuries old and are usually vested in the members of historically prominent families in the various subnational kingdoms of the country.</p>
	<p> Membership of initiatory societies that have inalienable functions within the kingdoms is also a common feature of Nigerian nobility, particularly among the southern tribes, where such figures as the Ogboni of the Yoruba, the Nze na Ozo of the Igbo and the Ekpe of the Efik are some of the most famous examples. Although many of their traditional functions have lapsed into abeyance with the advent of modern governance, their members retain precedence of a traditional nature and are especially prominent during festivals.</p>
	<p> Outside of this, many of the traditional nobles of Nigeria continue to serve as privy counsellors and viceroys in the service of their traditional sovereigns in a symbolic continuation of the way that their titled ancestors and predecessors did during the pre-colonial and colonial periods. Many of them are also members of the country's political elite due to their not being covered by the prohibition from involvement in politics that governs the activities of the traditional rulers.</p>
	<p> Holding a chieftaincy title, either of the traditional variety (which involves taking part in ritual re-enactments of your title's history during annual festivals, roughly akin to a British peerage) or the honorary variety (which does not involve the said re-enactments, roughly akin to a knighthood), grants an individual the right to use the word "chief" as a pre-nominal honourific while in Nigeria.</p>
	<p> Latin America[edit]</p>
	<p> In addition to a variety of indigenous peoples (such as the Aymara and the Quechua, who have long traditions of being led by nobles called Apu Mallkus and Mallkus), tribal connections exist among a number of other groups. Peerage traditions dating to the colonial period of such countries as Brazil, Cuba and Mexico have left noble families in each of them that have ancestral ties to those nations' native tribes, while such figures as the Afro-Bolivian king and the high priestess of the Ile Maroia Laji sect of Brazilian Candomblé trace their ancestries to and derive their prestige from ancient monarchs and nobles of the pre-colonial African continent.</p>
	<p> Brazil[edit]</p>
	<p> Portrait of Marquis of Paraná, Prime Minister of Brazil.</p>
	<p> The nobility in Brazil began during the colonial era with the Portuguese nobility. When Brazil became a united kingdom with Portugal in 1815, the first Brazilian titles of nobility were granted by the King of Portugal, Brazil and the Algarves.</p>
	<p> With the independence of Brazil in 1822 as a constitutional monarchy the titles of nobility initiated by the King of Portugal were continued and new titles of nobility were created by the Emperor of Brazil. However, according to the Brazilian Constitution of 1824, the Emperor conferred titles of nobility, which were personal and therefore non-hereditary, unlike its Portuguese and Portuguese-Brazilian predecessor, being inherited exclusively to the royal titles of the Brazilian Imperial Family.[citation needed]</p>
	<p> During the existence of the Empire of Brazil 1211 noble titles were acknowledged. With the proclamation of the First Brazilian Republic, in 1889, the Brazilian nobility was extinguished. It was also prohibited, under penalty of accusation of high treason and the suspension of political rights, to accept noble titles and foreign decorations without the proper permission of the State. In particular, the nobles of greater distinction, by respect and tradition, were allowed to use their titles during the republican regime. The Imperial Family also could not return to the Brazilian soil until 1921, when the Banishment Law was repealed.[citation needed]</p>
	<p> Pacific Islands[edit]</p>
	<p> Amongst the Polynesians of the Pacific the Ali'i occupied the traditional place of an Aristocratic class. The Kingdoms of Hawaii, Tahiti and presently the Kingdom of Tonga were all ruled by a ruling class known as the Ali'i</p>
	<p> The Ali'i routinely provided the kings and nobles of various Polynesian Kingdoms; including the Kingdom of Hawaii prior to its dissolution 1893, and have served as a bastion of Native Hawaiian revivalism since its occurrence. In Tonga, after contact with Western nations, the traditional system of chiefs was developed into a Western-style monarchy with a hereditary class of "barons", the Tongans even adopting that English title as a synonym for chief.</p>`
},{
	title: "Palestine",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 11 (1765), pp. 778–779",
	wSource: "https://en.wikipedia.org/wiki/Palestine",
	eConn: ["palestine","land","land","country","land","arabs","three","emir","nau","land","land","travel","land","region","land","occupy","land","nazareth","land","dangerous","father","land","emir","sanjaks"],
	wConn: ["state","palestine","region","palestine","byzantine","palaestina","syria","palaestina","palestinian","state","gaza","strip","british","mandate","palestinian","authority","palaestina","prima","land","syria","west","bank","ottoman","palestine"],
	eArt: `Palestine, the Holy Land , or the land of Canaan , is an Asian country, today under Ottoman control. It is a dry, entirely depopulated desert, which is moreover entirely covered with dry rocks. There is no doubt that it was as cultivated as it could have been when the Jews possessed it. They had palms, olive trees, beehives, and they had brought soil to the rocks so as to plant vines, which produced good wine. This soil, mixed with rock shards, was held in place by low walls. However, despite all the efforts of the ancient Jews, Palestine was never able to nourish its inhabitants; thus, it came to be that they spread far and wide, and went on to become the financiers in Asia and Africa that they are today. Alexandria had hardly been built before they had established themselves, and there were eight thousand of them in Rome during the rule of Augustus.
	<p> The current state of Palestine is more miserable than ever: There are only small towns, depopulated villages, and some old, ruined castles to be seen. The flat land is the quarry of the Arabs, who roam its entirety, and as it is only sown and cultivated in a few places, they attack travelers and foreigners to steal from them. The Turkish garrisons are too weak and are spread too thinly to suppress these robberies.</p>
	<p> The few Christians that are in Palestine are amassed in the valley of Lebanon under their Maronite bishops. As far as temporal authority is concerned, they are subject to an Arab leader who calls himself the Emir of Tripoli, and who is a dependent of Turks. The Druze, a people who have a different religion than Christians, Turks, and all of the other peoples in the land, inhabit the Anti-Lebanon Mountains.</p>
	<p> All of Palestine could be seven leagues long, from north to south, stretching from the 31st to the 33rd parallel, and its width perhaps 30 leagues.</p>
	<p> The pilgrims divide it into three provinces: Judea, Samaria, and Galilee, each governed by an Emir, subject to the will of an overlord, who, apart from this Emir, maintains there two Sanjaks which are subordinate to the Pasha of Damascus.</p>
	<p> These three Emirs are the Emir of Saida, the Emir of Caesarea, and the Emir of Gaza; the two Sanjaks take the names of their residences, Jerusalem and Nablus. Beyond the Jordan is what is known as the Kingdom of the Arabs. This kingdom consists of immense deserts, of which the king is an independent sovereign, who does not recognize the authority of the Porte.</p>
	<p> According to Father Nau, Palestine today includes the land of Gaza; Al-Khalil, or Hebron; the land of Al-Quds, or Jerusalem; the land of Neapolis, or Nablus; the land of Harcté; the land of Kafr Kanna, or Nazareth; the country of Safed; and finally, the region above Jordan, where it is dangerous to travel because of the Arabs who occupy it. He adds that these diverse regions form so many governments of which the number, however, is not at all fixed because the overlord oftentimes divides a government in two, and oftentimes he combines them.</p>
	<p> One should be cautious of the description of the places made famous by Holy Scripture. We have been given very suspect, circumstantial descriptions. What don’t they claim to show to those who undertake the pilgrimage to Palestine , and what is not offered to them to compensate them for their efforts? They are shown through imagination the place where Saint Epiphanius, born in Palestine around the year 320, founded a monastery himself. This father of the Church died in 403, and was older than 80. The best edition of his works is that of Father Petau, which was published in Greek and Latin in 1622, in folio, with scholarly notes. In these notes, however, he was unable to rectify either the errors or the lack of precision of Saint Epiphanius in the facts that he reports.</p>`,
	wArt:`Palestine (Arabic: فلسطين‎‎ Filasṭīn, Falasṭīn, Filisṭīn; Greek: Παλαιστίνη, Palaistinē; Latin: Palaestina; Hebrew: פלשתינה Palestina) is a geographic region in Western Asia between the Mediterranean Sea and the Jordan River. It is sometimes considered to include adjoining territories. The name was used by Ancient Greek writers, and was later used for the Roman province Syria Palaestina, the Byzantine Palaestina Prima, and the Islamic provincial district of Jund Filastin. The region comprises most of the territory claimed for the biblical regions known as the Land of Israel (Hebrew: ארץ־ישראל Eretz-Yisra'el), the Holy Land or Promised Land. Historically, it has been known as the southern portion of wider regional designations such as Canaan, Syria, ash-Sham, and the Levant.
	<p> Situated at a strategic location between Egypt, Syria and Arabia, and the birthplace of Judaism and Christianity, the region has a long and tumultuous history as a crossroads for religion, culture, commerce, and politics. The region has been controlled by numerous peoples, including Ancient Egyptians, Canaanites, Israelites and Judeans, Assyrians, Babylonians, Persians, Ancient Greeks and Macedonians, the Jewish Hasmonean Kingdom, Romans, Byzantines, the Arab Rashidun, Umayyad, Abbasid and Fatimid caliphates, Crusaders, Ayyubids, Mamluks, Mongols, Ottomans, the British, and modern Israelis, Jordanians, Egyptians and Palestinians.</p>
	<p> The boundaries of the region have changed throughout history. Today, the region comprises the State of Israel and the Palestinian territories in which the State of Palestine was declared.</p>
	<p> The name is found throughout recorded history. Examples shown above are (1) Pomponius Mela (Latin, c.43 CE); (2) Notitia Dignitatum (Latin, c.410 CE); (3) Tabula Rogeriana (Arabic, 1154 CE); (4) Cedid Atlas (Ottoman Turkish, 1803 CE)</p>
	<p> Modern archaeology has identified 12 ancient inscriptions from Egyptian and Assyrian records recording likely cognates of Hebrew Pelesheth. The term "Peleset" (transliterated from hieroglyphs as P-r-s-t) is found in five inscriptions referring to a neighboring people or land starting from c. 1150 BCE during the Twentieth dynasty of Egypt. The first known mention is at the temple at Medinet Habu which refers to the Peleset among those who fought with Egypt in Ramesses III's reign,[1][2] and the last known is 300 years later on Padiiset's Statue. Seven known Assyrian inscriptions refer to the region of "Palashtu" or "Pilistu", beginning with Adad-nirari III in the Nimrud Slab in c. 800 BCE through to a treaty made by Esarhaddon more than a century later.[3][4] Neither the Egyptian nor the Assyrian sources provided clear regional boundaries for the term.[i]</p>
	<p> The first clear use of the term Palestine to refer to the entire area between Phoenicia and Egypt was in 5th century BC Ancient Greece,[7][8] when Herodotus wrote of a 'district of Syria, called Palaistinê" in The Histories, which included the Judean mountains and the Jordan Rift Valley.[9][ii] Approximately a century later, Aristotle used a similar definition for the region in Meteorology, in which he included the Dead Sea.[11] Later Greek writers such as Polemon and Pausanias also used the term to refer to the same region, which was followed by Roman writers such as Ovid, Tibullus, Pomponius Mela, Pliny the Elder, Dio Chrysostom, Statius, Plutarch as well as Roman Judean writers Philo of Alexandria and Josephus.[12] The term was first used to denote an official province in c.135 CE, when the Roman authorities, following the suppression of the Bar Kokhba Revolt, combined Iudaea Province with Galilee and the Paralia to form "Syria Palaestina". There is circumstantial evidence linking Hadrian with the name change,[13] but the precise date is not certain[13] and the assertion of some scholars that the name change was intended "to complete the dissociation with Judaea"[14] is disputed.[15]</p>
	<p> The term is generally accepted to be a translation of the Biblical name Peleshet (פלשת Pəlésheth, usually transliterated as Philistia). The term and its derivates are used more than 250 times in Masoretic-derived versions of the Hebrew Bible, of which 10 uses are in the Torah, with undefined boundaries, and almost 200 of the remaining references are in the Book of Judges and the Books of Samuel.[3][4][12][16] The term is rarely used in the Septuagint, who used a transliteration Land of Phylistieim (Γῆ τῶν Φυλιστιείμ) different from the contemporary Greek place name Palaistínē (Παλαιστίνη).[15]</p>
	<p> The Septuagint instead used the term "allophuloi" (άλλόφυλοι, "other nations") throughout the Books of Judges and Samuel,[17][18] such that the term "Philistines" has been interpreted to mean "non-Israelites of the Promised Land" when used in the context of Samson, Saul and David,[19] and Rabbinic sources explain that these peoples were different from the Philistines of the Book of Genesis.[20]</p>
	<p> During the Byzantine period, the region of Palestine within Syria Palaestina was subdivided into Palaestina Prima and Secunda,[21] and an area of land including the Negev and Sinai became Palaestina Salutaris.[21] Following the Muslim conquest, place names that were in use by the Byzantine administration generally continued to be used in Arabic.[3][22] The use of the name "Palestine" became common in Early Modern English,[23] was used in English and Arabic during the Mutasarrifate of Jerusalem[24][25][iii] and was revived as an official place name with the British Mandate for Palestine.</p>
	<p> Some other terms that have been used to refer to all or part of this land include Canaan, Land of Israel (Eretz Yisrael or Ha'aretz),[27][iv] Greater Syria, the Holy Land, Iudaea Province, Judea, Coele-Syria,[v] "Israel HaShlema", Kingdom of Israel, Kingdom of Jerusalem, Zion, Retenu (Ancient Egyptian), Southern Syria, Southern Levant and Syria Palaestina.</p>
	<p> History</p>
	<p> Main article: History of Palestine</p>
	<p> Further information: Time periods in the Palestine region</p>
	<p> Overview</p>
	<p> Situated at a strategic location between Egypt, Syria and Arabia, and the birthplace of Judaism and Christianity, the region has a long and tumultuous history as a crossroads for religion, culture, commerce, and politics. The region has been controlled by numerous peoples, including Ancient Egyptians, Canaanites, Israelites, Assyrians, Babylonians, Persians, Ancient Greeks, Romans, Byzantines, the Arab Rashidun, Umayyad, Abbasid and Fatimid caliphates, Crusaders, Ayyubids, Mamluks, Mongols, Ottomans, the British, and modern Israelis and Palestinians. Modern archaeologists and historians of the region refer to their field of study as Levantine archaeology.</p>
	<p>  </p>
	<p> Ancient period</p>
	<p> Depiction of Biblical Palestine in c. 1020 BCE according to George Adam Smith's 1915 Atlas of the Historical Geography of the Holy Land. Smith's book was used as a reference by Lloyd George during the negotiations for the British Mandate for Palestine.[33]</p>
	<p> The region was among the earliest in the world to see human habitation, agricultural communities and civilization.[34] During the Bronze Age, independent Canaanite city-states were established, and were influenced by the surrounding civilizations of ancient Egypt, Mesopotamia, Phoenicia, Minoan Crete, and Syria. Between 1550–1400 BCE, the Canaanite cities became vassals to the Egyptian New Kingdom who held power until the 1178 BCE Battle of Djahy (Canaan) during the wider Bronze Age collapse.[35] The Israelites emerged from a dramatic social transformation that took place in the people of the central hill country of Canaan around 1200 BCE, with no signs of violent invasion or even of peaceful infiltration of a clearly defined ethnic group from elsewhere.[36][37]</p>
	<p> The region became part of the Neo-Assyrian Empire from c. 740 BCE, which was itself replaced by the Neo-Babylonian Empire in c. 627 BCE.[38] According to the Bible, a war with Egypt culminated in 586 BCE when Jerusalem was destroyed by the Babylonian king Nebuchadnezzar II and the local leaders of the region of Judea were deported to Babylonia. In 539 BCE, the Babylonian empire was replaced by the Achaemenid Empire. According to the Bible and implications from the Cyrus Cylinder, the exiled population of Judea was allowed to return to Jerusalem.[39] Southern Palestine became a province of the Achaemenid Empire, called Idumea, and the evidence from ostraca suggests that a Nabataean-type society, since the Idumeans appear to be connected to the Nabataeans, took shape in southern Palestine in the 4th century B.C.E., and that the Qedarite Arab kingdom penetrated throughout this area through the period of Persian and Hellenistic dominion.[40]</p>
	<p> Classical antiquity</p>
	<p> Herod's Temple in Jerusalem functioned as the spiritual center of the various sects of Second Temple Judaism until it was destroyed in 70 CE. This picture shows the temple as imagined in 1966 in the Holyland Model of Jerusalem.</p>
	<p> In the 330s BCE, Macedonian ruler Alexander the Great conquered the region, which changed hands several times during the wars of the Diadochi and later Syrian Wars. It ultimately fell to the Seleucid Empire between 219–200 BCE. In 116 BCE, a Seleucid civil war resulted in the independence of certain regions including the Hasmonean principality in the Judaean Mountains.[41] From 110 BCE, the Hasmoneans extended their authority over much of Palestine, creating a Judaean–Samaritan–Idumaean–Ituraean–Galilean alliance.[42] The Judaean (Jewish, see Ioudaioi) control over the wider region resulted in it also becoming known as Judaea, a term that had previously only referred to the smaller region of the Judaean Mountains.[43][44] Between 73–63 BCE, the Roman Republic extended its influence into the region in the Third Mithridatic War, conquering Judea in 63 BCE, and splitting the former Hasmonean Kingdom into five districts. The three-year Ministry of Jesus, culminating in his crucifixion, is estimated to have occurred from 28–30 CE, although the historicity of Jesus is disputed by a minority of scholars.[vi] In 70 CE, Titus sacked Jerusalem, resulting in the dispersal of the city's Jews and Christians to Yavne and Pella. In 132 CE, Hadrian joined the province of Iudaea with Galilee and the Paralia to form new province of Syria Palaestina, and Jerusalem was renamed "Aelia Capitolina". Between 259–272, the region fell under the rule of Odaenathus as King of the Palmyrene Empire. Following the victory of Christian emperor Constantine in the Civil wars of the Tetrarchy, the Christianization of the Roman Empire began, and in 326, Constantine's mother Saint Helena visited Jerusalem and began the construction of churches and shrines. Palestine became a center of Christianity, attracting numerous monks and religious scholars. The Samaritan Revolts during this period caused their near extinction. In 614 CE, Palestine was annexed by another Persian dynasty; the Sassanids, until returning to Byzantine control in 628 CE.[46]</p>
	<p> Middle Ages</p>
	<p> The Dome of the Rock, the world's first great work of Islamic architecture, constructed in 691.</p>
	<p> Minaret of the White Mosque in Ramla, constructed in 1318</p>
	<p> Arab architecture in the Middle Ages</p>
	<p> Palestine was conquered by the Islamic Caliphate, beginning in 634 CE.[47] In 636, the Battle of Yarmouk during the Muslim conquest of the Levant marked the start of Muslim hegemony over the region, which became known as Jund Filastin within the province of Bilâd al-Shâm (Greater Syria).[48] In 661, with the Assassination of Ali, Muawiyah I became the Caliph of the Islamic world after being crowned in Jerusalem.[49] The Dome of the Rock, completed in 691, was the world's first great work of Islamic architecture.[50]</p>
	<p> The majority of the population was Christian and was to remain so until the conquest of Saladin in 1187. The Muslim conquest apparently had little impact on social and administrative continuities for several decades.[51][52][53][vii] The word 'Arab' at the time referred predominantly to Bedouin nomads, though Arab settlement is attested in the Judean highlands and near Jerusalem by the 5th century, and some tribes had converted to Christianity.[55] The local population engaged in farming, which was considered demeaning, and were called Nabaț, referring to Aramaic-speaking villagers. A ḥadīth, brought in the name of a Muslim freedman who settled in Palestine, ordered the Muslim Arabs not to settle in the villages, "for he who abides in villages it is as if he abides in graves".[56]</p>
	<p> The Umayyads, who had spurred a strong economic resurgence in the area,[57] were replaced by the Abbasids in 750. Ramla became the administrative centre for the following centuries, while Tiberias became a thriving centre of Muslim scholarship.[58] From 878, Palestine was ruled from Egypt by semi-autonomous rulers for almost a century, beginning with the Turkish freeman Ahmad ibn Tulun, for whom both Jews and Christians prayed when he lay dying[59] and ending with the Ikhshidid rulers. Reverence for Jerusalem increased during this period, with many of the Egyptian rulers choosing to be buried there.[60] However, the later period became characterized by persecution of Christians as the threat from Byzantium grew.[61] The Fatimids, with a predominantly Berber army, conquered the region in 970, a date that marks the beginning of a period of unceasing warfare between numerous enemies, which destroyed Palestine, and in particular devastating its Jewish population.[62] Between 1071-73, Palestine was captured by the Great Seljuq Empire,[63] only to be recaptured by the Fatimids in 1098,[64] who then lost the region to the Crusaders in 1099.[65] Their control of Jerusalem and most of Palestine lasted almost a century until their defeat by Saladin's forces in 1187,[66] after which most of Palestine was controlled by the Ayyubids.[66] A rump crusader state in the northern coastal cities survived for another century, but, despite seven further crusades, the Crusaders were no longer a significant power in the region.[67] The Fourth Crusade, which did not reach Palestine, led directly to the decline of the Byzantine Empire, dramatically reducing Christian influence throughout the region.[68]</p>
	<p> The Crusader fortress in Acre, also known as the Hospitaller Fortress, was built during the 12th century.</p>
	<p> The Mamluk Sultanate was indirectly created in Egypt as a result of the Seventh Crusade.[69] The Mongol Empire reached Palestine for the first time in 1260, beginning with the Mongol raids into Palestine under Nestorian Christian general Kitbuqa, and reaching an apex at the pivotal Battle of Ain Jalut, where they were routed by the Mamluks.[70]</p>
	<p> Ottoman era</p>
	<p> Main article: History of Palestine § Ottoman era</p>
	<p> The Khan al-Umdan, constructed in Acre in 1784, is the largest and best preserved caravanserai in the region.</p>
	<p> In 1486, hostilities broke out between the Mamluks and the Ottoman Empire in a battle for control over western Asia, and the Ottomans conquered Palestine in 1516.[71] Between the mid-16th and 17th centuries, a close-knit alliance of three local dynasties, the Ridwans of Gaza, the Turabays of al-Lajjun and the Farrukhs of Nablus, governed Palestine on behalf of the Porte (imperial Ottoman government).[72]</p>
	<p> In the 18th century, the Zaydani clan under the leadership of Zahir al-Umar ruled large parts of Palestine autonomously[73] until the Ottomans were able to defeat them in their Galilee strongholds in 1775-76.[74] Zahir had turned the port city of Acre into a major regional power, partly fueled by his monopolization of the cotton and olive oil trade from Palestine to Europe. Acre's regional dominance was further elevated under Zahir's successor Ahmad Pasha al-Jazzar at the expense of Damascus.[75]</p>
	<p> In 1830, on the eve of Muhammad Ali's invasion,[76] the Porte transferred control of the sanjaks of Jerusalem and Nablus to Abdullah Pasha, the governor of Acre. According to Silverburg, in regional and cultural terms this move was important for creating an Arab Palestine detached from greater Syria (bilad al-Sham).[77] According to Pappe, it was an attempt to reinforce the Syrian front in face of Muhammad Ali's invasion.[78] Two years later, Palestine was conquered by Muhammad Ali's Egypt,[76] but Egyptian rule was challenged in 1834 by a countrywide popular uprising against conscription and other measures considered intrusive by the population.[79] Its suppression devastated many of Palestine's villages and major towns.[80]</p>
	<p> In 1840, Britain intervened and returned control of the Levant to the Ottomans in return for further capitulations.[81] The death of Aqil Agha marked the last local challenge to Ottoman centralization in Palestine,[82] and beginning in the 1860s, Palestine underwent an acceleration in its socio-economic development, due to its incorporation into the global, and particularly European, economic pattern of growth. The beneficiaries of this process were Arabic-speaking Muslims and Christians who emerged as a new layer within the Arab elite.[83] The end of the 19th century saw the beginning of Zionist immigration and the revival of the Hebrew language and culture.[84] The movement was publicly supported by Great Britain during World War I with the Balfour Declaration of 1917.[85]</p>
	<p> British mandate and partition</p>
	<p> The new era in Palestine. The arrival of Herbert Samuel as the first High Commissioner for Palestine in 1920. Samuel had promoted Zionism within the British Cabinet, beginning with his 1915 memorandum entitled The Future of Palestine. Beside him are Lawrence of Arabia, Emir Abdullah, Air Marshal Salmond and Wyndham Deedes.</p>
	<p> Further information: History of Zionism and History of Israel</p>
	<p> Palestine passport and Palestine coin. The Mandatory authorities agreed a compromise position regarding the Hebrew name: in English and Arabic the name was simply "Palestine" ("فلسطين"), but the Hebrew version "(פלשתינה)" also included the acronym "(א״י)" for Eretz Yisrael (Land of Israel).</p>
	<p> The British began their Sinai and Palestine Campaign in 1915.[86] The war reached southern Palestine in 1917, progressing to Gaza and around Jerusalem by the end of the year.[86] The British secured Jerusalem in December 1917.[87] They moved into the Jordan valley in 1918 and a campaign by the Entente into northern Palestine led to victory at Megiddo in September.[87]</p>
	<p> The British were formally awarded the mandate to govern the region in 1922.[88] The non-Jewish Palestinians revolted in 1920, 1929, and 1936.[89] In 1947, following World War II and The Holocaust, the British Government announced its desire to terminate the Mandate, and the United Nations General Assembly adopted in November 1947 a Resolution 181(II) recommending partition into an Arab state, a Jewish state and the Special International Regime for the City of Jerusalem.[90] The Jewish leadership accepted the proposal, but the Arab Higher Committee rejected it; a civil war began immediately after the Resolution's adoption. The State of Israel was declared in May 1948.[91]</p>
	<p> Post–1948</p>
	<p> In the 1948 Arab–Israeli War, Israel captured and incorporated a further 26% of the Mandate territory, Jordan captured the region of Judea and Samaria,[92][93][94] renaming it the "West Bank", while the Gaza Strip was captured by Egypt.[95][96] Following the 1948 Palestinian exodus, also known as al-Nakba, the 700,000 Palestinians who fled or were driven from their homes were not allowed to return following the Lausanne Conference of 1949.[97]</p>
	<p> In the course of the Six-Day War in June 1967, Israel captured the rest of Mandate Palestine from Jordan and Egypt, and began a policy of establishing Jewish settlements in those territories. From 1987 to 1993, the First Palestinian Intifada against Israel took place, which included the Declaration of the State of Palestine in 1988 and ended with the 1993 Oslo Peace Accords and the creation of the Palestinian National Authority.</p>
	<p> In 2000, the Second Intifada (also called al-Aqsa Intifada) began, and Israel built a separation barrier. In the 2005 Israeli disengagement from Gaza, Israel withdrew all settlers and military presence from the Gaza Strip, but maintained military control of numerous aspects of the territory including its borders, air space and coast. Israel's ongoing military occupation of the Gaza Strip, the West Bank and East Jerusalem continues to be the world's longest military occupation in modern times.[viii][ix]</p>
	<p> In November 2012, the status of Palestinian delegation in the United Nations was upgraded to non-member observer state as the State of Palestine.[108][x]</p>
	<p> Boundaries</p>
	<p> Satellite image of the region of Palestine, 2003.</p>
	<p> Ancient and Medieval</p>
	<p> The boundaries of Palestine have varied throughout history.[xi][xii] The Jordan Rift Valley (comprising Wadi Arabah, the Dead Sea and River Jordan) has at times formed a political and administrative frontier, even within empires that have controlled both territories.[111] At other times, such as during certain periods during the Hasmonean and Crusader states for example, as well as during the biblical period, territories on both sides of the river formed part of the same administrative unit. During the Arab Caliphate period, parts of southern Lebanon and the northern highland areas of Palestine and Jordan were administered as Jund al-Urdun, while the southern parts of the latter two formed part of Jund Dimashq, which during the 9th century was attached to the administrative unit of Jund Filastin.[112]</p>
	<p> The boundaries of the area and the ethnic nature of the people referred to by Herodotus in the 5th century BCE as Palaestina vary according to context. Sometimes, he uses it to refer to the coast north of Mount Carmel. Elsewhere, distinguishing the Syrians in Palestine from the Phoenicians, he refers to their land as extending down all the coast from Phoenicia to Egypt.[113] Pliny, writing in Latin in the 1st century CE, describes a region of Syria that was "formerly called Palaestina" among the areas of the Eastern Mediterranean.[114]</p>
	<p> Since the Byzantine Period, the Byzantine borders of Palaestina (I and II, also known as Palaestina Prima, "First Palestine", and Palaestina Secunda, "Second Palestine"), have served as a name for the geographic area between the Jordan River and the Mediterranean Sea. Under Arab rule, Filastin (or Jund Filastin) was used administratively to refer to what was under the Byzantines Palaestina Secunda (comprising Judaea and Samaria), while Palaestina Prima (comprising the Galilee region) was renamed Urdunn ("Jordan" or Jund al-Urdunn).[3]</p>
	<p> Modern period</p>
	<p> Nineteenth-century sources refer to Palestine as extending from the sea to the caravan route, presumably the Hejaz-Damascus route east of the Jordan River valley.[115] Others refer to it as extending from the sea to the desert.[115] Prior to the Allied Powers victory in World War I and the Partitioning of the Ottoman Empire, which created the British mandate in the Levant, most of the northern area of what is today Jordan formed part of the Ottoman Vilayet of Damascus (Syria), while the southern part of Jordan was part of the Vilayet of Hejaz.[116] What later became Mandatory Palestine was in late Ottoman times divided between the Vilayet of Beirut (Lebanon) and the Sanjak of Jerusalem.[26] The Zionist Organization provided its definition of the boundaries of Palestine in a statement to the Paris Peace Conference in 1919.[117][118]</p>
	<p> The British administered Mandatory Palestine after World War I, having promised to establish a homeland for the Jewish people. The modern definition of the region follows the boundaries of that entity, which were fixed in the North and East in 1920-23 by the British Mandate for Palestine (including the Transjordan memorandum) and the Paulet–Newcombe Agreement,[27] and on the South by following the 1906 Turco-Egyptian boundary agreement.[119][120]</p>
	<p> Modern evolution of Palestine v t e</p>
	<p> 1916–1922 proposals: Three proposals for the post World War I administration of Palestine. The red line is the "International Administration" proposed in the 1916 Sykes–Picot Agreement, the dashed blue line is the 1919 Zionist Organization proposal at the Paris Peace Conference, and the thin blue line refers to the final borders of the 1923–48 Mandatory Palestine.</p>
	<p> 1937 proposal: The first official proposal for partition, published in 1937 by the Peel Commission. An ongoing British Mandate was proposed to keep "the sanctity of Jerusalem and Bethlehem", in the form of an enclave from Jerusalem to Jaffa, including Lydda and Ramle.</p>
	<p> 1947 (proposal): Proposal per the United Nations Partition Plan for Palestine (UN General Assembly Resolution 181 (II), 1947), prior to the 1948 Arab–Israeli War. The proposal included a Corpus Separatum for Jerusalem, extraterritorial crossroads between the non-contiguous areas, and Jaffa as an Arab exclave.</p>
	<p> 1947 (actual): Mandatory Palestine, showing Jewish-owned regions in Palestine as of 1947 in blue, constituting 6% of the total land area, of which more than half was held by the JNF and PICA. The Jewish population had increased from 83,790 in 1922 to 608,000 in 1946.</p>
	<p> 1948–1967 (actual): The Jordanian-annexed West Bank (light green) and Egyptian-occupied Gaza Strip (dark green), after the 1948 Arab–Israeli War, showing 1949 armistice lines.</p>
	<p> 1967–1994: During the Six-Day War, Israel captured the West Bank, the Gaza Strip, and the Golan Heights, together with the Sinai Peninsula (later traded for peace after the Yom Kippur War). In 1980–81 Israel annexed East Jerusalem and the Golan Heights. Neither Israel's annexation nor Palestine's claim over East Jerusalem has been internationally recognized.</p>
	<p> 1994–2006: Under the Oslo Accords, the Palestinian National Authority was created to provide civil government in certain urban areas of the West Bank and the Gaza Strip.</p>
	<p> 2006–present: After the Israeli disengagement from Gaza and clashes between the two main Palestinian parties following the Hamas electoral victory, two separate executive governments took control in Gaza and the West Bank.</p>
	<p> Current usage</p>
	<p> Further information: Palestinian people, Palestinian territories, State of Palestine, and Palestinian National Authority</p>
	<p> The region of Palestine is the eponym for the Palestinian people and the culture of Palestine, both of which are defined as relating to the whole historical region, usually defined as the localities within the border of Mandatory Palestine. The 1968 Palestinian National Covenant described Palestine as the "homeland of the Arab Palestinian people", with "the boundaries it had during the British Mandate".[121]</p>
	<p> However, since the 1988 Palestinian Declaration of Independence, the term State of Palestine refers only to the West Bank and the Gaza Strip. This discrepancy was described by the Palestinian president Mahmoud Abbas as a negotiated concession in a September 2011 speech to the United Nations: "... we agreed to establish the State of Palestine on only 22% of the territory of historical Palestine - on all the Palestinian Territory occupied by Israel in 1967."[122]</p>
	<p> The term Palestine is also sometimes used in a limited sense to refer to the parts of the Palestinian territories currently under the administrative control of the Palestinian National Authority, a quasi-governmental entity which governs parts of the State of Palestine under the terms of the Oslo Accords.[xiii]</p>
	<p> Demographics</p>
	<p> Main article: Demographic history of Palestine</p>
	<p> Early demographics</p>
	<p> Year	Jews	Christians	Muslims	Total</p>
	<p> First half 1st century CE	Majority	–	–	~2,500</p>
	<p> 5th century	Minority	Majority	–	>1st C</p>
	<p> End 12th century	Minority	Minority	Majority	>225</p>
	<p> 14th century before Black Death	Minority	Minority	Majority	225</p>
	<p> 14th century after Black Death	Minority	Minority	Majority	150</p>
	<p> Historical population table compiled by Sergio DellaPergola.[124] Figures in thousands.</p>
	<p> Estimating the population of Palestine in antiquity relies on two methods – censuses and writings made at the times, and the scientific method based on excavations and statistical methods that consider the number of settlements at the particular age, area of each settlement, density factor for each settlement.</p>
	<p> According to Israeli archaeologists Magen Broshi and Yigal Shiloh, the population of ancient Palestine did not exceed one million.[125][126] By 300AD, Christianity had spread so significantly that Jews comprised only a quarter of the population.[66]</p>
	<p> Late Ottoman and British Mandate periods</p>
	<p> In the middle of the 1st century of the Ottoman rule, i.e. 1550 AD, Bernard Lewis in a study of Ottoman registers of the early Ottoman Rule of Palestine reports:[127]</p>
	<p> From the mass of detail in the registers, it is possible to extract something like a general picture of the economic life of the country in that period. Out of a total population of about 300,000 souls, between a fifth and a quarter lived in the six towns of Jerusalem, Gaza, Safed, Nablus, Ramle, and Hebron. The remainder consisted mainly of peasants, living in villages of varying size, and engaged in agriculture. Their main food-crops were wheat and barley in that order, supplemented by leguminous pulses, olives, fruit, and vegetables. In and around most of the towns there was a considerable number of vineyards, orchards, and vegetable gardens.</p>
	<p> Historical population table compiled by Sergio DellaPergola.[124] Figures in thousands.</p>
	<p> According to Alexander Scholch, the population of Palestine in 1850 was about 350,000 inhabitants, 30% of whom lived in 13 towns; roughly 85% were Muslims, 11% were Christians and 4% Jews.[128]</p>
	<p> According to Ottoman statistics studied by Justin McCarthy, the population of Palestine in the early 19th century was 350,000, in 1860 it was 411,000 and in 1900 about 600,000 of whom 94% were Arabs.[129] In 1914 Palestine had a population of 657,000 Muslim Arabs, 81,000 Christian Arabs, and 59,000 Jews.[130] McCarthy estimates the non-Jewish population of Palestine at 452,789 in 1882; 737,389 in 1914; 725,507 in 1922; 880,746 in 1931; and 1,339,763 in 1946.[131]</p>
	<p> In 1920, the League of Nations' Interim Report on the Civil Administration of Palestine described the 700,000 people living in Palestine as follows:[132]</p>
	<p> Of these, 235,000 live in the larger towns, 465,000 in the smaller towns and villages. Four-fifths of the whole population are Moslems. A small proportion of these are Bedouin Arabs; the remainder, although they speak Arabic and are termed Arabs, are largely of mixed race. Some 77,000 of the population are Christians, in large majority belonging to the Orthodox Church, and speaking Arabic. The minority are members of the Latin or of the Uniate Greek Catholic Church, or—a small number—are Protestants.</p>
	<p> The Jewish element of the population numbers 76,000. Almost all have entered Palestine during the last 40 years. Prior to 1850, there were in the country only a handful of Jews. In the following 30 years, a few hundreds came to Palestine. Most of them were animated by religious motives; they came to pray and to die in the Holy Land, and to be buried in its soil. After the persecutions in Russia forty years ago, the movement of the Jews to Palestine assumed larger proportions.</p>
	<p> Current demographics</p>
	<p> See also: Demographics of Israel and Demographics of the Palestinian territories</p>
	<p> According to the Israel Central Bureau of Statistics, as of 2015, the total population of Israel was 8.5 million people, of which 75% were Jews, 21% Arabs, and 4% "others."[133] Of the Jewish group, 76% were Sabras (born in Israel); the rest were olim (immigrants) — 16% from Europe, the former Soviet republics, and the Americas, and 8% from Asia and Africa, including the Arab countries.[134]</p>
	<p> According to the Palestinian Central Bureau of Statistics evaluations, in 2015 the Palestinian population of the West Bank was approximately 2.9 million and that of the Gaza Strip was 1.8 million.[135] Gaza's population is expected to increase to 2.1 million people in 2020, leading to a density of more than 5,800 people per square kilometre.[136]</p>
	<p> Both Israeli and Palestinian statistics include Arab residents of East Jerusalem in their reports.[137] According to these estimates the total population in the region of Palestine, as defined as Israel and the Palestinian territories, stands approximately 12.8 million.</p>`
},{
	title: "Religion",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 14 (1765), p. 83",
	wSource: "",
	eConn: ["sense","religion","roman","religion","religion","turks","religion","siamese","religion","savages","religion","greeks","religion","america","zealots","catholics","worship","through","through","church","religion","princes","rejecting","through"],
	wConn: ["study","religion","religion","mythology","academic","religion","religious","movements","religious","beliefs","asian","religions","african","mythology","religion","law","religion","psychology","history","religion","disciplines","religion","comparative","religion"],
	eArt: `Religion, more particularly the specific system of belief and the worship that takes place in one country or another, in one sect or another, in one era or another, etc.
	<p> In this sense, one speaks of Roman religion , Reformed religion , the religion of the Greeks, that of the Turks, of the savages of America, the Siamese, etc.</p>
	<p> Minister Claude maintains that the diversity of religions , that is to say, the various manners of honoring God, are agreeable to Him because they all have the same object, they all tend to the same purpose, whatever their various means.</p>
	<p> [This is] a false principle since God has declared that he was rejecting one cult or another as insufficient or imperfect, and that he was adopting another one as more pure and more reasonable; moreover, if he has established in the world some visible authority that ought with full power to govern the manner and ceremonies of the worship that he has approved, and this is what he has done through revelation and through the establishment of his Church.</p>
	<p> Thus it is wrong that the same minister claims that the feeling of these idolators is much more equitable than that of the zealots who believe that only their own cult is agreeable to God, and one senses that by these zealots he wants to designate the Catholics. For they do not condemn other cults precisely by their own lights, but because God has rejected them, because they are not in conformity with the one he has established, and ultimately because they are not authorized by the power to whom he has confided the interpretation of his laws.</p>
	<p> The religion of a rather large part of the world is one which one may find exactly described in one of the choruses of Seneca's trilogy, at the end of the second act which begins thus:</p>
	<p> " Verum est, an timidos fabula decipit? Umbras corporibus vivere conditis," etc . [Is it true, or does a story deceive the fearful, that shades live when bodies have been buried. [1]]</p>
	<p> According to Guy Patin, [this is] the religion of princes, nobles, magistrates and even some doctors and philosophers, and he adds that the Duke of Mayenne, head of the League in France, had a custom of saying that princes do not begin to have religion until after having reached forty years of age, " cum numina nobis mors instans majora facit." [When imminent death makes divine powers greater.] [2] (Patin, Lettres Choisies , Letter 106). This false idea is belied by the experience of every century.</p>`,
	wArt:`Religion is any cultural system of designated behaviors and practices, world views, texts, sanctified places, ethics, or organizations, that relate humanity to the supernatural or transcendental. Religions relate humanity to what anthropologist Clifford Geertz has referred to as a cosmic "order of existence".
	<p> Different religions may or may not contain various elements ranging from the "divine",[2] "sacred things",[3] "faith",[4] a "supernatural being or supernatural beings"[5] or "some sort of ultimacy and transcendence that will provide norms and power for the rest of life".[6] Religious practices may include rituals, sermons, commemoration or veneration (of deities), sacrifices, festivals, feasts, trances, initiations, funerary services, matrimonial services, meditation, prayer, music, art, dance, public service, or other aspects of human culture. Religions have sacred histories and narratives, which may be preserved in sacred scriptures, and symbols and holy places, that aim mostly to give a meaning to life. Religions may contain symbolic stories, which are sometimes said by followers to be true, that have the side purpose of explaining the origin of life, the Universe and other things. Traditionally, faith, in addition to reason, has been considered a source of religious beliefs.[7] There are an estimated 10,000 distinct religions worldwide.[8] About 84% of the world's population is affiliated with one of the five largest religions, namely Christianity, Islam, Hinduism, Buddhism or forms of folk religion.[9]</p>
	<p> With the onset of the modernisation of and the scientific revolution in the western world, some aspects of religion have cumulatively been criticized. The religiously unaffiliated demographic include those who do not identify with any particular religion, atheists and agnostics. While the religiously unaffiliated have grown globally, many of the religiously unaffiliated still have various religious beliefs.[10]The study of religion encompasses a wide variety of academic disciplines, including theology, comparative religion and social scientific studies. Theories of religion offer various explanations for the origins and workings of religion.</p>
	<p> Etymology and history of the concept of religion</p>
	<p> Religion</p>
	<p> Religion (from O.Fr. religion "religious community", from L. religionem (nom. religio) "respect for what is sacred, reverence for the gods",[11] "obligation, the bond between man and the gods"[12]) is derived from the Latin religiō, the ultimate origins of which are obscure. One possible interpretation traced to Cicero, connects lego "read", i.e. re (again) with lego in the sense of "choose", "go over again" or "consider carefully". Modern scholars such as Tom Harpur and Joseph Campbell favor the derivation from ligare "bind, connect", probably from a prefixed re-ligare, i.e. re (again) + ligare or "to reconnect", which was made prominent by St. Augustine, following the interpretation of Lactantius.[13][14] The medieval usage alternates with order in designating bonded communities like those of monastic orders: "we hear of the 'religion' of the Golden Fleece, of a knight 'of the religion of Avys'".[15]</p>
	<p> In the ancient and medieval world, the etymological Latin root religio was understood as an individual virtue of worship, never as doctrine, practice, or actual source of knowledge.[16] The modern concept of "religion" as an abstraction which entails distinct sets of beliefs or doctrines is a recent invention in the English language since such usage began with texts from the 17th century due to the splitting of Christendom during the Protestant Reformation and more prevalent colonization or globalization in the age of exploration which involved contact with numerous foreign and indigenous cultures with non-European languages.[16][17] It was in the 17th century that the concept of "religion" received its modern shape despite the fact that ancient texts like the Bible, the Quran, and other ancient sacred texts did not have a concept of religion in the original languages and neither did the people or the cultures in which these sacred texts were written.[18] For example, the Greek word threskeia, which was used by Greek writers such as Herodotus and Josephus and is found in texts like the New Testament, is sometimes translated as "religion" today, however, the term was understood as "worship" well into the medieval period.[18] In the Quran, the Arabic word din is often translated as "religion" in modern translations, but up to the mid-1600s translators expressed din as "law".[18] Even in the 1st century AD, Josephus had used the Greek term ioudaismos, which some translate as "Judaism" today, even though he used it as an ethnic term, not one linked to modern abstract concepts of religion as a set of beliefs.[18] It was in the 19th century that the terms "Buddhism", "Hinduism", "Taoism", and "Confucianism" first emerged.[16][19] Throughout its long history, Japan had no concept of "religion" since there was no corresponding Japanese word, nor anything close to its meaning, but when American warships appeared off the coast of Japan in 1853 and forced the Japanese government to sign treaties demanding, among other things, freedom of religion, the country had to contend with this Western idea.[19]</p>
	<p> According to the philologist Max Müller in the 19th century, the root of the English word "religion", the Latin religio, was originally used to mean only "reverence for God or the gods, careful pondering of divine things, piety" (which Cicero further derived to mean "diligence").[20][21] Max Müller characterized many other cultures around the world, including Egypt, Persia, and India, as having a similar power structure at this point in history. What is called ancient religion today, they would have only called "law".[22]</p>
	<p> Some languages have words that can be translated as "religion", but they may use them in a very different way, and some have no word for religion at all. For example, the Sanskrit word dharma, sometimes translated as "religion", also means law. Throughout classical South Asia, the study of law consisted of concepts such as penance through piety and ceremonial as well as practical traditions. Medieval Japan at first had a similar union between "imperial law" and universal or "Buddha law", but these later became independent sources of power.[23][24]</p>
	<p> There is no precise equivalent of "religion" in Hebrew, and Judaism does not distinguish clearly between religious, national, racial, or ethnic identities.[25] One of its central concepts is "halakha", meaning the "walk" or "path" sometimes translated as "law", which guides religious practice and belief and many aspects of daily life.[26]</p>
	<p> Faith</p>
	<p> The word religion is sometimes used interchangeably with faith or set of duties;[27] however, in the words of Émile Durkheim, religion differs from private belief in that it is "something eminently social".[28]</p>
	<p> Other terms</p>
	<p> The use of other terms, such as obedience to God or Islam are likewise grounded in particular histories and vocabularies.[29]</p>
	<p> Definitions</p>
	<p> Main article: Definition of religion</p>
	<p> There is no final definition of religion, even though many a scientist has and still tries to define religion. There are two general definition systems: the sociological/functional and the phenomenological/philosophical.[30][31][32][33][34]</p>
	<p> Religion as modern western construct</p>
	<p> An increasing number of scholars have expressed reservations about ever defining the "essence" of religion.[35] They observe that the way we use the concept today is a particularly modern construct that would not have been understood through much of history and in many cultures outside the West (or even in the West until after the Peace of Westphalia).[36] The MacMIllan Encyclopedia of Religions states:</p>
	<p> The very attempt to define religion, to find some distinctive or possibly unique essence or set of qualities that distinguish the "religious" from the remainder of human life, is primarily a Western concern. The attempt is a natural consequence of the Western speculative, intellectualistic, and scientific disposition. It is also the product of the dominant Western religious mode, what is called the Judeo-Christian climate or, more accurately, the theistic inheritance from Judaism, Christianity, and Islam. The theistic form of belief in this tradition, even when downgraded culturally, is formative of the dichotomous Western view of religion. That is, the basic structure of theism is essentially a distinction between a transcendent deity and all else, between the creator and his creation, between God and man.[37]</p>
	<p> Classical definitions</p>
	<p> Urarina shaman, Peru, 1988</p>
	<p> Friedrich Schleiermacher in the late 18th century defined religion as das schlechthinnige Abhängigkeitsgefühl, commonly translated as "the feeling of absolute dependence".[38]</p>
	<p> His contemporary Hegel disagreed thoroughly, defining religion as "the Divine Spirit becoming conscious of Himself through the finite spirit."[39]</p>
	<p> Edward Burnett Tylor defined religion in 1871 as "the belief in spiritual beings".[40] He argued that narrowing the definition to mean the belief in a supreme deity or judgment after death or idolatry and so on, would exclude many peoples from the category of religious, and thus "has the fault of identifying religion rather with particular developments than with the deeper motive which underlies them". He also argued that the belief in spiritual beings exists in all known societies.</p>
	<p> In his book The Varieties of Religious Experience, the psychologist William James defined religion as "the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine".[2] By the term "divine" James meant "any object that is godlike, whether it be a concrete deity or not"[41] to which the individual feels impelled to respond with solemnity and gravity.[42]</p>
	<p> The sociologist Durkheim, in his seminal book The Elementary Forms of the Religious Life, defined religion as a "unified system of beliefs and practices relative to sacred things".[3] By sacred things he meant things "set apart and forbidden—beliefs and practices which unite into one single moral community called a Church, all those who adhere to them". Sacred things are not, however, limited to gods or spirits.[note 1] On the contrary, a sacred thing can be "a rock, a tree, a spring, a pebble, a piece of wood, a house, in a word, anything can be sacred".[43] Religious beliefs, myths, dogmas and legends are the representations that express the nature of these sacred things, and the virtues and powers which are attributed to them.[44]</p>
	<p> Echoes of James' and Durkheim's definitions are to be found in the writings of, for example, Frederick Ferré who defined religion as "one's way of valuing most comprehensively and intensively".[45] Similarly, for the theologian Paul Tillich, faith is "the state of being ultimately concerned",[4] which "is itself religion. Religion is the substance, the ground, and the depth of man's spiritual life."[46]</p>
	<p> When religion is seen in terms of "sacred", "divine", intensive "valuing", or "ultimate concern", then it is possible to understand why scientific findings and philosophical criticisms (e.g. Richard Dawkins) do not necessarily disturb its adherents.[47]</p>
	<p> Modern definitions</p>
	<p> The anthropologist Clifford Geertz defined religion as a</p>
	<p> […] system of symbols which acts to establish powerful, pervasive, and long-lasting moods and motivations in men by formulating conceptions of a general order of existence and clothing these conceptions with such an aura of factuality that the moods and motivations seem uniquely realistic."[1]</p>
	<p> Alluding perhaps to Tylor's "deeper motive", Geertz remarked that</p>
	<p> […] we have very little idea of how, in empirical terms, this particular miracle is accomplished. We just know that it is done, annually, weekly, daily, for some people almost hourly; and we have an enormous ethnographic literature to demonstrate it".[48]</p>
	<p> The theologian Antoine Vergote took the term "supernatural" simply to mean whatever transcends the powers of nature or human agency. He also emphasized the "cultural reality" of religion, which he defined as</p>
	<p> […] the entirety of the linguistic expressions, emotions and, actions and signs that refer to a supernatural being or supernatural beings.[5]</p>
	<p> Peter Mandaville and Paul James intended to get away from the modernist dualisms or dichotomous understandings of immanence/transcendence, spirituality/materialism, and sacredness/secularity. They define religion as</p>
	<p> […] a relatively-bounded system of beliefs, symbols and practices that addresses the nature of existence, and in which communion with others and Otherness is lived as if it both takes in and spiritually transcends socially-grounded ontologies of time, space, embodiment and knowing.[6]</p>
	<p> According to the MacMillan Encyclopedia of Religions, there is an experiential aspect to religion which can be found in almost every culture:</p>
	<p> […] almost every known culture [has] a depth dimension in cultural experiences […] toward some sort of ultimacy and transcendence that will provide norms and power for the rest of life. When more or less distinct patterns of behavior are built around this depth dimension in a culture, this structure constitutes religion in its historically recognizable form. Religion is the organization of life around the depth dimensions of experience—varied in form, completeness, and clarity in accordance with the environing culture.[49]</p>
	<p> Aspects</p>
	<p> [icon]	This section needs expansion. You can help by adding to it. (December 2015)</p>
	<p> A religion is a cultural system of behaviors and practices, world views, sacred texts, holy places, ethics, and societal organisation that relate humanity to an order of existence.</p>
	<p> Practices</p>
	<p> Main articles: Religious behaviour and Religious practice</p>
	<p> The practices of a religion may include rituals, sermons, commemoration or veneration (of a deity, gods, or goddesses), sacrifices, festivals, feasts, trances, initiations, funerary services, matrimonial services, meditation, prayer, music, art, dance, public service, or other aspects of human culture.[50]</p>
	<p> Worldview</p>
	<p> Religions have sacred histories, narratives, and mythologies which may be preserved in sacred scriptures, and symbols and holy places, that aim to explain the meaning of life, the origin of life, or the Universe.[citation needed]</p>
	<p> Religious beliefs</p>
	<p> Main article: Religious beliefs</p>
	<p> Traditionally, faith, in addition to reason, has been considered a source of religious beliefs. The interplay between faith and reason, and their use as actual or perceived support for religious beliefs, have been a subject of interest to philosophers and theologians.[7]</p>
	<p> Mythology</p>
	<p> Main article: Mythology</p>
	<p> The word myth has several meanings.</p>
	<p> A traditional story of ostensibly historical events that serves to unfold part of the world view of a people or explain a practice, belief, or natural phenomenon;</p>
	<p> A person or thing having only an imaginary or unverifiable existence; or</p>
	<p> A metaphor for the spiritual potentiality in the human being.[51]</p>
	<p> Ancient polytheistic religions, such as those of Greece, Rome, and Scandinavia, are usually categorized under the heading of mythology. Religions of pre-industrial peoples, or cultures in development, are similarly called "myths" in the anthropology of religion. The term "myth" can be used pejoratively by both religious and non-religious people. By defining another person's religious stories and beliefs as mythology, one implies that they are less real or true than one's own religious stories and beliefs. Joseph Campbell remarked, "Mythology is often thought of as other people's religions, and religion can be defined as mis-interpreted mythology."[52]</p>
	<p> In sociology, however, the term myth has a non-pejorative meaning. There, myth is defined as a story that is important for the group whether or not it is objectively or provably true.[53] Examples include the resurrection of their real-life founder Jesus, which, to Christians, explains the means by which they are freed from sin, is symbolic of the power of life over death, and is also said to be a historical event. But from a mythological outlook, whether or not the event actually occurred is unimportant. Instead, the symbolism of the death of an old "life" and the start of a new "life" is what is most significant. Religious believers may or may not accept such symbolic interpretations.</p>
	<p> Social organisation</p>
	<p> Religions have a societal basis, either as a living tradition which is carried by lay participants, or with an organized clergy, and a definition of what constitutes adherence or membership.</p>
	<p> Types and demographics</p>
	<p> Main article: Major religious groups</p>
	<p> Further information: Organized religion</p>
	<p> The list of still-active religious movements given here is an attempt to summarize the most important regional and philosophical influences on local communities, but it is by no means a complete description of every religious community, nor does it explain the most important elements of individual religiousness.</p>
	<p> Types of religion</p>
	<p> Further information: History of religions</p>
	<p> A map of major denominations and religions of the world</p>
	<p> In the 19th and 20th centuries, the academic practice of comparative religion divided religious belief into philosophically defined categories called "world religions." Some academics studying the subject have divided religions into three broad categories:</p>
	<p> world religions, a term which refers to transcultural, international faiths;</p>
	<p> indigenous religions, which refers to smaller, culture-specific or nation-specific religious groups; and</p>
	<p> new religious movements, which refers to recently developed faiths.[54]</p>
	<p> Some recent scholarship has argued that not all types of religion are necessarily separated by mutually exclusive philosophies, and furthermore that the utility of ascribing a practice to a certain philosophy, or even calling a given practice religious, rather than cultural, political, or social in nature, is limited.[55][56][57] The current state of psychological study about the nature of religiousness suggests that it is better to refer to religion as a largely invariant phenomenon that should be distinguished from cultural norms (i.e. "religions").[58]</p>
	<p> Some scholars classify religions as either universal religions that seek worldwide acceptance and actively look for new converts, or ethnic religions that are identified with a particular ethnic group and do not seek converts.[59] Others reject the distinction, pointing out that all religious practices, whatever their philosophical origin, are ethnic because they come from a particular culture.[60][61][62]</p>
	<p> Demographics</p>
	<p> The five largest religious groups by world population, estimated to account for 5.8 billion people and 84% of the population, are Christianity, Islam, Buddhism, Hinduism (with the relative numbers for Buddhism and Hinduism dependent on the extent of syncretism) and traditional folk religion.</p>
	<p> Five largest religions	2010 (billion)[9]	2010 (%)	2000 (billion)[63][64]	2000 (%)	Demographics</p>
	<p> Christianity	2.2	32%	2.0	33%	Christianity by country</p>
	<p> Islam	1.6	23%	1.2	19.6%	Islam by country</p>
	<p> Hinduism	1.0	15%	0.811	13.4%	Hinduism by country</p>
	<p> Buddhism	0.5	7%	0.360	5.9%	Buddhism by country</p>
	<p> Folk religion	0.4	6%	0.385	6.4%	</p>
	<p> Total	5.8	84%	4.8	78.3%	</p>
	<p> A global poll in 2012 surveyed 57 countries and reported that 59% of the world's population identified as religious, 23% as not religious, 13% as "convinced atheists", and also a 9% decrease in identification as "religious" when compared to the 2005 average from 39 countries.[65] A follow up poll in 2015 found that 63% of the globe identified as religious, 22% as not religious, and 11% as "convinced atheists".[66] On average, women are "more religious" than men.[67] Some people follow multiple religions or multiple religious principles at the same time, regardless of whether or not the religious principles they follow traditionally allow for syncretism.[68][69][70]</p>
	<p> Abrahamic</p>
	<p> The patriarch Abraham (by József Molnár)</p>
	<p> Abrahamic religions are monotheistic religions which believe they descend from Abraham.</p>
	<p> Judaism</p>
	<p> The Torah is the primary sacred text of Judaism.</p>
	<p> Judaism is the oldest Abrahamic religion, originating in the people of ancient Israel and Judea. The Torah is its foundational text, and is part of the larger text known as the Tanakh or Hebrew Bible. It is supplemented by oral tradition, set down in written form in later texts such as the Midrash and the Talmud. Judaism includes a wide corpus of texts, practices, theological positions, and forms of organization. Within Judaism there are a variety of movements, most of which emerged from Rabbinic Judaism, which holds that God revealed his laws and commandments to Moses on Mount Sinai in the form of both the Written and Oral Torah; historically, this assertion was challenged by various groups. The Jewish people were scattered after the destruction of the Temple in Jerusalem in 70 CE. Today there are about 13 million Jews, about 40 per cent living in Israel and 40 per cent in the United States.[71] The largest Jewish religious movements are Orthodox Judaism (Haredi Judaism and Modern Orthodox Judaism), Conservative Judaism and Reform Judaism.</p>
	<p> Christianity</p>
	<p> Jesus is the central figure of Christianity.</p>
	<p> Christianity is based on the life and teachings of Jesus of Nazareth (1st century) as presented in the New Testament. The Christian faith is essentially faith in Jesus as the Christ, the Son of God, and as Savior and Lord. Almost all Christians believe in the Trinity, which teaches the unity of Father, Son (Jesus Christ), and Holy Spirit as three persons in one Godhead. Most Christians can describe their faith with the Nicene Creed. As the religion of Byzantine Empire in the first millennium and of Western Europe during the time of colonization, Christianity has been propagated throughout the world. The main divisions of Christianity are, according to the number of adherents:</p>
	<p> The Catholic Church, led by the Bishop of Rome and the bishops worldwide in communion with him, is a communion of 24 Churches sui iuris, including the Latin Church and 23 Eastern Catholic churches, such as the Maronite Catholic Church.</p>
	<p> Eastern Christianity, which include Eastern Orthodoxy, Oriental Orthodoxy, and the Church of the East.</p>
	<p> Protestantism, separated from the Catholic Church in the 16th-century Protestant Reformation and is split into thousands of denominations. Major branches of Protestantism include Anglicanism, Baptists, Calvinism, Lutheranism, and Methodism, though each of these contain many different denominations or groups.</p>
	<p> There are also smaller groups, including:</p>
	<p> Restorationism, the belief that Christianity should be restored (as opposed to reformed) along the lines of what is known about the apostolic early church.</p>
	<p> Latter Day Saint movement, founded by Joseph Smith in the late 1820s.</p>
	<p> Jehovah's Witnesses, founded in the late 1870s by Charles Taze Russell.</p>
	<p> Islam</p>
	<p> Muslims circumambulating the Kaaba, the most sacred site in Islam</p>
	<p> Islam is based on the Quran, one of the holy books considered by Muslims to be revealed by God, and on the teachings (hadith) of the Islamic prophet Muhammad, a major political and religious figure of the 7th century CE. Islam is the most widely practiced religion of Southeast Asia, North Africa, Western Asia, and Central Asia, while Muslim-majority countries also exist in parts of South Asia, Sub-Saharan Africa, and Southeast Europe. There are also several Islamic republics, including Iran, Pakistan, Mauritania, and Afghanistan.</p>
	<p> Sunni Islam is the largest denomination within Islam and follows the Quran, the hadiths which record the sunnah, whilst placing emphasis on the sahabah.</p>
	<p> Shia Islam is the second largest denomination of Islam and its adherents believe that Ali succeeded Muhammad and further places emphasis on Muhammad's family.</p>
	<p> Ahmadiyya adherents believe that the awaited Imam Mahdi and the Promised Messiah has arrived, believed to be Mirza Ghulam Ahmad by Ahmadis.</p>
	<p> There are also Muslim revivalist movements such as Muwahhidism and Salafism.</p>
	<p> Other denominations of Islam include Nation of Islam, Ibadi, Sufism, Quranism, Mahdavia, and non-denominational Muslims. Wahhabism is the dominant Muslim schools of thought in the Kingdom of Saudi Arabia.</p>
	<p> Other</p>
	<p> The Bahá'í Faith is an Abrahamic religion founded in 19th century Iran and since then has spread worldwide. It teaches unity of all religious philosophies and accepts all of the prophets of Judaism, Christianity, and Islam as well as additional prophets including its founder Bahá'u'lláh. One of its divisions is the Orthodox Bahá'í Faith.</p>
	<p> Smaller regional Abrahamic groups also exist, including Samaritanism (primarily in Israel and the West Bank), the Rastafari movement (primarily in Jamaica), and Druze (primarily in Syria and Lebanon).</p>
	<p> East Asian religions</p>
	<p> Main article: East Asian religions</p>
	<p> East Asian religions (also known as Far Eastern religions or Taoic religions) consist of several religions of East Asia which make use of the concept of Tao (in Chinese) or Dō (in Japanese or Korean). They include:</p>
	<p> Taoism and Confucianism, as well as Korean, Vietnamese, and Japanese religion influenced by Chinese thought.</p>
	<p> Chinese folk religion: the indigenous religions of the Han Chinese, or, by metonymy, of all the populations of the Chinese cultural sphere. It includes the syncretism of Confucianism, Taoism and Buddhism, Wuism, as well as many new religious movements such as Chen Tao, Falun Gong and Yiguandao.</p>
	<p> Other folk and new religions of East Asia and Southeast Asia such as Korean shamanism, Chondogyo, and Jeung San Do in Korea; Shinto, Shugendo, Ryukyuan religion, and Japanese new religions in Japan; Satsana Phi in Laos; Cao Đài, Hòa Hảo, and Vietnamese folk religion in Vietnam.</p>
	<p> Indian religions</p>
	<p> Hindu statue of Lord Rama in Kalaram Temple (India)</p>
	<p> The Buddha, in a Sanskrit manuscript, Nālandā, Bihar, India</p>
	<p> Indian religions are practiced or were founded in the Indian subcontinent. They are sometimes classified as the dharmic religions, as they all feature dharma, the specific law of reality and duties expected according to the religion.[72]</p>
	<p> Hinduism is a synecdoche describing the similar philosophies of Vaishnavism, Shaivism, and related groups practiced or founded in the Indian subcontinent. Concepts most of them share in common include karma, caste, reincarnation, mantras, yantras, and darśana.[note 2] Hinduism is the most ancient of still-active religions,[73][74] with origins perhaps as far back as prehistoric times.[75] Hinduism is not a monolithic religion but a religious category containing dozens of separate philosophies amalgamated as Sanātana Dharma, which is the name by which Hinduism has been known throughout history by its followers.</p>
	<p> Jainism, taught primarily by Parsva (9th century BCE) and Mahavira (6th century BCE), is an ancient Indian religion that prescribes a path of non-violence for all forms of living beings in this world. Jains are found mostly in India.</p>
	<p> Buddhism was founded by Siddhattha Gotama in the 6th century BCE. Buddhists generally agree that Gotama aimed to help sentient beings end their suffering (dukkha) by understanding the true nature of phenomena, thereby escaping the cycle of suffering and rebirth (saṃsāra), that is, achieving nirvana.</p>
	<p> Theravada Buddhism, which is practiced mainly in Sri Lanka and Southeast Asia alongside folk religion, shares some characteristics of Indian religions. It is based in a large collection of texts called the Pali Canon.</p>
	<p> Mahayana Buddhism (or the "Great Vehicle") under which are a multitude of doctrines that became prominent in China and are still relevant in Vietnam, Korea, Japan and to a lesser extent in Europe and the United States. Mahayana Buddhism includes such disparate teachings as Zen, Pure Land, and Soka Gakkai.</p>
	<p> Vajrayana Buddhism first appeared in India in the 3rd century CE.[76] It is currently most prominent in the Himalaya regions[77] and extends across all of Asia[78] (cf. Mikkyō).</p>
	<p> Two notable new Buddhist sects are Hòa Hảo and the Navayana (Dalit Buddhist movement), which were developed separately in the 20th century.</p>
	<p> Fresco of Guru Nanak at Goindwal Sahib Gurdwara</p>
	<p> Sikhism is a monotheistic religion founded on the teachings of Guru Nanak and ten successive Sikh gurus in 15th century Punjab. It is the fifth-largest organized religion in the world, with approximately 30 million Sikhs.[79][80] Sikhs are expected to embody the qualities of a Sant-Sipāhī—a saint-soldier, have control over one's internal vices and be able to be constantly immersed in virtues clarified in the Guru Granth Sahib. The principal beliefs of Sikhi are faith in Waheguru—represented by the phrase ik ōaṅkār, meaning one God, who prevails in everything, along with a praxis in which the Sikh is enjoined to engage in social reform through the pursuit of justice for all human beings.</p>
	<p> Local religions</p>
	<p> Indigenous and folk</p>
	<p> Incense burner in China</p>
	<p> Indigenous religions or folk religions refers to a broad category of traditional religions that can be characterised by shamanism, animism and ancestor worship, where traditional means "indigenous, that which is aboriginal or foundational, handed down from generation to generation…".[81] These are religions that are closely associated with a particular group of people, ethnicity or tribe; they often have no formal creeds or sacred texts.[82] Some faiths are syncretic, fusing diverse religious beliefs and practices.[83]</p>
	<p> Australian Aboriginal religions.</p>
	<p> Folk religions of the Americas: Native American religions</p>
	<p> Folk religions are often omitted as a category in surveys even in countries where they are widely practiced, e.g. in China.[82]</p>
	<p> African traditional</p>
	<p> Shango, the Orisha (god) of fire, lightning, and thunder, in the Yoruba religion, depicted on horseback</p>
	<p> Main article: Traditional African religion</p>
	<p> Further information: African diasporic religions</p>
	<p> African traditional religion encompasses the traditional religious beliefs of people in Africa. In north Africa, these religions have included traditional Berber religion, ancient Egyptian religion, and Waaq. West African religions include Akan religion, Dahomey (Fon) mythology, Efik mythology, Odinani of the Igbo people, Serer religion, and Yoruba religion, while Bushongo mythology, Mbuti (Pygmy) mythology, Lugbara mythology, Dinka religion, and Lotuko mythology come from central Africa. Southern African traditions include Akamba mythology, Masai mythology, Malagasy mythology, San religion, Lozi mythology, Tumbuka mythology, and Zulu mythology. Bantu mythology is found throughout central, southeast, and southern Africa.</p>
	<p> There are also notable African diasporic religions practiced in the Americas, such as Santeria, Candomble, Vodun, Lucumi, Umbanda, and Macumba.</p>
	<p> Iranian</p>
	<p> Zoroastrian Fire Temple</p>
	<p> Iranian religions are ancient religions whose roots predate the Islamization of Greater Iran. Nowadays these religions are practiced only by minorities.</p>
	<p> Zoroastrianism is based on the teachings of prophet Zoroaster in the 6th century BC. Zoroastrians worship the creator Ahura Mazda. In Zoroastrianism good and evil have distinct sources, with evil trying to destroy the creation of Mazda, and good trying to sustain it.</p>
	<p> Mandaeism is a monotheistic religion with a strongly dualistic worldview. Mandaeans are sometime labeled as the "Last Gnostics".</p>
	<p> Kurdish religions include the traditional beliefs of the Yazidi, Alevi, and Ahl-e Haqq. Sometimes these are labeled Yazdânism.</p>
	<p> New religious movements</p>
	<p> Main article: New religious movement</p>
	<p> Shinshūkyō is a general category for a wide variety of religious movements founded in Japan since the 19th century. These movements share almost nothing in common except the place of their founding. The largest religious movements centered in Japan include Soka Gakkai, Tenrikyo, and Seicho-No-Ie among hundreds of smaller groups.</p>
	<p> Cao Đài is a syncretistic, monotheistic religion, established in Vietnam in 1926.</p>
	<p> Raëlism is a new religious movement founded in 1974 teaching that humans were created by aliens. It is numerically the world's largest UFO religion.</p>
	<p> Hindu reform movements, such as Ayyavazhi, Swaminarayan Faith and Ananda Marga, are examples of new religious movements within Indian religions.</p>
	<p> Unitarian Universalism is a religion characterized by support for a "free and responsible search for truth and meaning", and has no accepted creed or theology.</p>
	<p> Noahidism is a monotheistic ideology based on the Seven Laws of Noah, and on their traditional interpretations within Rabbinic Judaism.</p>
	<p> Scientology teaches that people are immortal beings who have forgotten their true nature. Its method of spiritual rehabilitation is a type of counseling known as auditing, in which practitioners aim to consciously re-experience and understand painful or traumatic events and decisions in their past in order to free themselves of their limiting effects.</p>
	<p> Eckankar is a pantheistic religion with the purpose of making God an everyday reality in one's life.</p>
	<p> Wicca is a neo-pagan religion first popularised in 1954 by British civil servant Gerald Gardner, involving the worship of a God and Goddess.</p>
	<p> Druidry is a religion promoting harmony with nature, and drawing on the practices of the druids.</p>
	<p> There are various Neopagan movements that attempt to reconstruct or revive ancient pagan practices. These include Heathenry, Hellenism, and Kemeticism.</p>
	<p> Satanism is a broad category of religions that, for example, worship Satan as a deity (Theistic Satanism) or use "Satan" as a symbol of carnality and earthly values (LaVeyan Satanism).</p>
	<p> Sociological classifications of religious movements suggest that within any given religious group, a community can resemble various types of structures, including "churches", "denominations", "sects", "cults", and "institutions".</p>
	<p> Interfaith cooperation</p>
	<p> Because religion continues to be recognized in Western thought as a universal impulse[citation needed], many religious practitioners[who?] have aimed to band together in interfaith dialogue, cooperation, and religious peacebuilding. The first major dialogue was the Parliament of the World's Religions at the 1893 Chicago World's Fair, which affirmed "universal values" and recognition of the diversity of practices among different cultures. The 20th century has been especially fruitful in use of interfaith dialogue as a means of solving ethnic, political, or even religious conflict, with Christian–Jewish reconciliation representing a complete reverse in the attitudes of many Christian communities towards Jews.[citation needed]</p>
	<p> Recent interfaith initiatives include "A Common Word", launched in 2007 and focused on bringing Muslim and Christian leaders together,[84] the "C1 World Dialogue",[85] the "Common Ground" initiative between Islam and Buddhism,[86] and a United Nations sponsored "World Interfaith Harmony Week".[87][88]</p>
	<p> Academic study of religion</p>
	<p> Main article: Religious studies</p>
	<p> A number of disciplines study the phenomenon of religion: theology, comparative religion, history of religion, evolutionary origin of religions, anthropology of religion, psychology of religion, including neurosciences of religion and evolutionary psychology of religion, sociology of religion, and Law and Religion.</p>
	<p> Daniel L. Pals mentions eight classical theories of religion, focusing on various aspects of religion: animism and magic, by E.B. Tylor and J.G. Frazer; the psycho-analytic approach of Sigmund Freud; and further Emile Durkheim, Karl Marx, Max Weber, Mircea Eliade, E.E. Evans-Pritchard, and Clifford Geertz.[89]</p>
	<p> Michael Stausberg gives an overview of contemporary theories of religion, including cognitive and biological approaches.[90]</p>
	<p> Comparative religion</p>
	<p> Main article: Comparative religion</p>
	<p> Nicholas de Lange, Professor of Hebrew and Jewish Studies at Cambridge University, says that</p>
	<p> The comparative study of religions is an academic discipline which has been developed within Christian theology faculties, and it has a tendency to force widely differing phenomena into a kind of strait-jacket cut to a Christian pattern. The problem is not only that other 'religions' may have little or nothing to say about questions which are of burning importance for Christianity, but that they may not even see themselves as religions in precisely the same way in which Christianity sees itself as a religion.[91]</p>
	<p> Theories of religion</p>
	<p> Main article: Theories of religion</p>
	<p> Origins and development</p>
	<p> The Yazılıkaya sanctuary in Turkey, with the twelve gods of the underworld</p>
	<p> The origin of religion is uncertain. There are a number of theories regarding the subsequent origins of religious practices.</p>
	<p> According to anthropologists John Monaghan and Peter Just, "Many of the great world religions appear to have begun as revitalization movements of some sort, as the vision of a charismatic prophet fires the imaginations of people seeking a more comprehensive answer to their problems than they feel is provided by everyday beliefs. Charismatic individuals have emerged at many times and places in the world. It seems that the key to long-term success – and many movements come and go with little long-term effect – has relatively little to do with the prophets, who appear with surprising regularity, but more to do with the development of a group of supporters who are able to institutionalize the movement."[92]</p>
	<p> The development of religion has taken different forms in different cultures. Some religions place an emphasis on belief, while others emphasize practice. Some religions focus on the subjective experience of the religious individual, while others consider the activities of the religious community to be most important. Some religions claim to be universal, believing their laws and cosmology to be binding for everyone, while others are intended to be practiced only by a closely defined or localized group. In many places religion has been associated with public institutions such as education, hospitals, the family, government, and political hierarchies.[93]</p>
	<p> Anthropologists John Monoghan and Peter Just state that, "it seems apparent that one thing religion or belief helps us do is deal with problems of human life that are significant, persistent, and intolerable. One important way in which religious beliefs accomplish this is by providing a set of ideas about how and why the world is put together that allows people to accommodate anxieties and deal with misfortune."[93]</p>
	<p> Cultural system</p>
	<p> While religion is difficult to define, one standard model of religion, used in religious studies courses, was proposed by Clifford Geertz, who simply called it a "cultural system".[94] A critique of Geertz's model by Talal Asad categorized religion as "an anthropological category".[95] Richard Niebuhr's (1894-1962) five-fold classification of the relationship between Christ and culture, however, indicates that religion and culture can be seen as two separate systems, though not without some interplay.[96]</p>
	<p> Social constructionism</p>
	<p> Main article: Social constructionism</p>
	<p> One modern academic theory of religion, social constructionism, says that religion is a modern concept that suggests all spiritual practice and worship follows a model similar to the Abrahamic religions as an orientation system that helps to interpret reality and define human beings.[97] Among the main proponents of this theory of religion are Daniel Dubuisson, Timothy Fitzgerald, Talal Asad, and Jason Ānanda Josephson. The social constructionists argue that religion is a modern concept that developed from Christianity and was then applied inappropriately to non-Western cultures.</p>
	<p> Law</p>
	<p> Main article: Law and religion</p>
	<p> The study of law and religion is a relatively new field, with several thousand scholars involved in law schools, and academic departments including political science, religion, and history since 1980.[98] Scholars in the field are not only focused on strictly legal issues about religious freedom or non-establishment, but also study religions as they are qualified through judicial discourses or legal understanding of religious phenomena. Exponents look at canon law, natural law, and state law, often in a comparative perspective.[99][100] Specialists have explored themes in western history regarding Christianity and justice and mercy, rule and equity, and discipline and love.[101] Common topics of interest include marriage and the family[102] and human rights.[103] Outside of Christianity, scholars have looked at law and religion links in the Muslim Middle East[104] and pagan Rome.[105]</p>
	<p> Studies have focused on secularization.[106][107] In particular the issue of wearing religious symbols in public, such as headscarves that are banned in French schools, have received scholarly attention in the context of human rights and feminism.[108]</p>
	<p> Related aspects</p>
	<p> Reason and science</p>
	<p> Main articles: Faith and rationality, Relationship between religion and science, and Epistemology</p>
	<p> Science acknowledges reason, empiricism, and evidence; and religions include revelation, faith and sacredness whilst also acknowledging philosophical and metaphysical explanations with regard to the study of the universe. Both science and religion are not monolithic, timeless, or static because both are complex social and cultural endeavors that have changed through time across languages and cultures.[109]</p>
	<p> The concepts of "science" and "religion" are a recent invention: "religion" emerged in the 17th century in the midst of colonization and globalization and the Protestant Reformation,[16][18] "science" emerged in the 19th century out of natural philosophy in the midst of attempts to narrowly define those who studied nature ("natural science"),[16][110][111] and the phrase "religion and science" emerged in the 19th century due to the reification of both concepts.[16] It was in the 19th century that the terms "Buddhism", "Hinduism", "Taoism", and "Confucianism" first emerged.[16] In the ancient and medieval world, the etymological Latin roots of both science (scientia) and religion (religio) were understood as inner qualities of the individual or virtues, never as doctrines, practices, or actual sources of knowledge.[16]</p>
	<p> In general the scientific method gains knowledge by testing hypotheses to develop theories through elucidation of facts or evaluation by experiments and thus only answers cosmological questions about the universe that can be observed and measured. It develops theories of the world which best fit physically observed evidence. All scientific knowledge is subject to later refinement, or even rejection, in the face of additional evidence. Scientific theories that have an overwhelming preponderance of favorable evidence are often treated as de facto verities in general parlance, such as the theories of general relativity and natural selection to explain respectively the mechanisms of gravity and evolution.</p>
	<p> Religion does not have a method per se partly because religions emerge through time from diverse cultures and it is an attempt to find meaning in the world, and to explain humanity's place in it and relationship to it and to any posited entities. In terms of Christian theology and ultimate truths, people rely on reason, experience, scripture, and tradition to test and gauge what they experience and what they should believe. Furthermore, religious models, understanding, and metaphors are also revisable, as are scientific models.[112]</p>
	<p> Regarding religion and science, Albert Einstein states (1940): "For science can only ascertain what is, but not what should be, and outside of its domain value judgments of all kinds remain necessary. Religion, on the other hand, deals only with evaluations of human thought and action; it cannot justifiably speak of facts and relationships between facts…Now, even though the realms of religion and science in themselves are clearly marked off from each other, nevertheless there exist between the two strong reciprocal relationships and dependencies. Though religion may be that which determine the goals, it has, nevertheless, learned from science, in the broadest sense, what means will contribute to the attainment of the goals it has set up." [113]</p>
	<p> Morality and religion</p>
	<p> Main article: Morality and religion</p>
	<p> Many religions have value frameworks regarding personal behavior meant to guide adherents in determining between right and wrong. These include the Triple Jems of Jainism, Judaism's Halacha, Islam's Sharia, Catholicism's Canon Law, Buddhism's Eightfold Path, and Zoroastrianism's "good thoughts, good words, and good deeds" concept, among others.[114] Religion and morality are not synonymous. Morality does not necessarily depend upon religion although this is "an almost automatic assumption."[115] According to The Westminster Dictionary of Christian Ethics, religion and morality "are to be defined differently and have no definitional connections with each other. Conceptually and in principle, morality and a religious value system are two distinct kinds of value systems or action guides."[116]</p>
	<p> According to global research done by Gallup on people from 145 countries, adherents of all the major world religions who attended religious services in the past week have higher rates of generosity such as donating money, volunteering, and helping a stranger than do their coreligionists who did not attend services (non-attenders). Even for people who were nonreligious, those who said they attended religious services in the past week exhibited more generous behaviors.[117] Another global study by Gallup on people from 140 countries showed that highly religious people are more likely to help others in terms of donating money, volunteering, and helping strangers despite them having, on average, lower incomes than those who are less religious or nonreligious.[118]</p>
	<p> A comprehensive study by Harvard University professor Robert Putnam found that religious people are more charitable than their irreligious counterparts.[119][120] The study revealed that forty percent of worship service attending Americans volunteer regularly to help the poor and elderly as opposed to 15% of Americans who never attend services.[119] Moreover, religious individuals are more likely than non-religious individuals to volunteer for school and youth programs (36% vs. 15%), a neighborhood or civic group (26% vs. 13%), and for health care (21% vs. 13%).[119] Other research has shown similar correlations between religiosity and giving.[121]</p>
	<p> Religious belief appears to be the strongest predictor of charitable giving.[122][123][124][125][126] One study found that average charitable giving in 2000 by religious individuals ($2,210) was over three times that of secular individuals ($642). Giving to non-religious charities by religious individuals was $88 higher. Religious individuals are also more likely to volunteer time, donate blood, and give back money when accidentally given too much change.[124] A 2007 study by the The Barna Group found that "active-faith" individuals (those who had attended a church service in the past week) reported that they had given on average $1,500 in 2006, while "no-faith" individuals reported that they had given on average $200. "Active-faith" adults claimed to give twice as much to non-church-related charities as "no-faith" individuals claimed to give. They were also more likely to report that they were registered to vote, that they volunteered, that they personally helped someone who was homeless, and to describe themselves as "active in the community."[127]</p>
	<p> Some scientific studies show that the degree of religiosity is generally found to be associated with higher ethical attitudes[128][129][130][131] — for example, surveys suggesting a positive connection between faith and altruism.[132] Survey research suggests that believers do tend to hold different views than non-believers on a variety of social, ethical and moral questions. According to a 2003 survey conducted in the United States by The Barna Group, those who described themselves as believers were less likely than those describing themselves as atheists or agnostics to consider the following behaviors morally acceptable: cohabitating with someone of the opposite sex outside of marriage, enjoying sexual fantasies, having an abortion, sexual relationships outside of marriage, gambling, looking at pictures of nudity or explicit sexual behavior, getting drunk, and "having a sexual relationship with someone of the same sex."[133]</p>
	<p> Politics</p>
	<p> Religion has a significant impact on the political system in many countries. Notably, most Muslim-majority countries adopt various aspects of sharia, the Islamic law. Some countries even define themselves in religious terms, such as The Islamic Republic of Iran. The sharia thus affects up to 23% of the global population, or 1.57 billion people who are Muslims. However, religion also affects political decisions in many western countries. For instance, in the United States, 51% of voters would be less likely to vote for a presidential candidate who did not believe in God, and only 6% more likely.[134] Christians make up 92% of members of the US Congress, compared with 71% of the general public (as of 2014). At the same time, while 23% of U.S. adults are religiously unaffiliated, only one member of Congress (Kyrsten Sinema, D-Arizona), or 0.2% of that body, claims no religious affiliation.[135] In most European countries, however, religion has a much smaller influence on politics[136] although it used to be much more important. For instance, same-sex marriage and abortion were illegal in many European countries until recently, following Christian (usually Catholic) doctrine. Several European leaders are atheists (e.g. France’s president Francois Hollande or Greece's prime minister Alexis Tsipras). In Asia, the role of religion differs widely between countries. For instance, India is still one of the most religious countries and religion still has a strong impact on politics, given that Hindu nationalists have been targeting minorities like the Muslims and the Christians, who historically belonged to the lower castes.[137] By contrast, countries such as China or Japan are largely secular and thus religion has a much smaller impact on politics.</p>
	<p> Economics</p>
	<p> Average income correlates negatively with (self-defined) religiosity.[65]</p>
	<p> Main article: Economics of religion</p>
	<p> Further information: Religion and business and Wealth and religion</p>
	<p> One study has found there is a negative correlation between self-defined religiosity and the wealth of nations.[138] In other words, the richer a nation is, the less likely its inhabitants to call themselves "religious", whatever this word means to them (Many people identify themselves as part of a religion (not irreligion) but do not self-identify as "religious").[138]</p>
	<p> Sociologist and political economist Max Weber has argued that Protestant Christian countries are wealthier because of their Protestant work ethic.[139]</p>
	<p> According to a study from 2015, Christians hold the largest amount of wealth (55% of the total world wealth), followed by Muslims (5.8%), Hindus (3.3%) and Jewish (1.1%). According to the same study it was found that adherents under the classification Irreligion or other religions hold about 34.8% of the total global wealth.[140]</p>
	<p> Health</p>
	<p> Main article: Impacts of religion on health</p>
	<p> Mayo Clinic researchers examined the association between religious involvement and spirituality, and physical health, mental health, health-related quality of life, and other health outcomes. The authors reported that: "Most studies have shown that religious involvement and spirituality are associated with better health outcomes, including greater longevity, coping skills, and health-related quality of life (even during terminal illness) and less anxiety, depression, and suicide."[141]</p>
	<p> The authors of a subsequent study concluded that the influence of religion on health is "largely beneficial", based on a review of related literature.[142] According to academic James W. Jones, several studies have discovered "positive correlations between religious belief and practice and mental and physical health and longevity." [143]</p>
	<p> An analysis of data from the 1998 US General Social Survey, whilst broadly confirming that religious activity was associated with better health and well-being, also suggested that the role of different dimensions of spirituality/religiosity in health is rather more complicated. The results suggested "that it may not be appropriate to generalize findings about the relationship between spirituality/religiosity and health from one form of spirituality/religiosity to another, across denominations, or to assume effects are uniform for men and women.[144]</p>
	<p> Superstition</p>
	<p> Further information: Superstition, Magical thinking, and Magic and religion</p>
	<p> Superstition has been described as "the incorrect establishment of cause and effect" or a false conception of causation.[145] Religion is more complex and is mostly composed of social institutions and morality. But some religions may include superstitions or make use of magical thinking. Adherents of one religion sometimes think of other religions as superstition.[146][147] Some atheists, deists, and skeptics regard religious belief as superstition.</p>
	<p> Greek and Roman pagans, who saw their relations with the gods in political and social terms, scorned the man who constantly trembled with fear at the thought of the gods (deisidaimonia), as a slave might fear a cruel and capricious master. The Romans called such fear of the gods superstitio.[148]</p>
	<p> Ancient greek historian Polybius described superstition in Ancient Rome as an instrumentum regni, an instrument of maintaining the cohesion of the Empire.[149]</p>
	<p> The Roman Catholic Church considers superstition to be sinful in the sense that it denotes a lack of trust in the divine providence of God and, as such, is a violation of the first of the Ten Commandments. The Catechism of the Catholic Church states that superstition "in some sense represents a perverse excess of religion" (para. #2110). "Superstition," it says, "is a deviation of religious feeling and of the practices this feeling imposes. It can even affect the worship we offer the true God, e.g., when one attributes an importance in some way magical to certain practices otherwise lawful or necessary. To attribute the efficacy of prayers or of sacramental signs to their mere external performance, apart from the interior dispositions that they demand is to fall into superstition. Cf. Matthew 23:16-22" (para. #2111)</p>
	<p> Secularism and atheism</p>
	<p> Ranjit Singh established secular rule over Punjab in the early 19th century.</p>
	<p> Secularisation</p>
	<p> Main articles: Secularism, Secularization, and Irreligion</p>
	<p> Secularization is the transformation of a society from close identification with religious values and institutions toward nonreligious values and secular institutions. The term secularization is also used in the context of the lifting of the monastic restrictions from a member of the clergy.[150]</p>
	<p> Agnosticism and Atheism</p>
	<p> Main articles: Atheism, Agnosticism, Antireligion, and Humanism</p>
	<p> See also: Criticism of atheism</p>
	<p> The terms "atheist" (lack of belief in any gods) and "agnostic" (belief in the unknowability of the existence of gods), though specifically contrary to theistic (e.g. Christian, Jewish, and Muslim) religious teachings, do not by definition mean the opposite of "religious". There are religions (including Buddhism, Taoism, and Hinduism), in fact, that classify some of their followers as agnostic, atheistic, or nontheistic. The true opposite of "religious" is the word "irreligious". Irreligion describes an absence of any religion; antireligion describes an active opposition or aversion toward religions in general.</p>
	<p> Criticism of religious violence</p>
	<p> Main article: Criticism of religion</p>
	<p> Violence</p>
	<p> Main article: Religious violence</p>
	<p> See also: Christianity and violence, Islam and violence, and Judaism and violence</p>
	<p> United Airlines Flight 175 hits the South Tower during the September 11 attacks of 2001 in New York City. The September 11 attacks (also referred to as "9/11") were a series of four coordinated terrorist attacks by the Islamic terrorist group al-Qaeda on the United States on the morning of Tuesday, September 11, 2001.</p>
	<p> Critics like Hector Avalos[151] Regina Schwartz,[152] Christopher Hitchens and Richard Dawkins have argued that religions are inherently violent and harmful to society by using violence to promote their goals, in ways that are endorsed and exploited by their leaders.[153][page needed][154][page needed]</p>
	<p> Anthropologist Jack David Eller asserts that religion is not inherently violent, arguing "religion and violence are clearly compatible, but they are not identical." He asserts that "violence is neither essential to nor exclusive to religion" and that " virtually every form of religious violence has its nonreligious corollary."[155][156]</p>
	<p> Animal sacrifice</p>
	<p> Done by some (but not all) religions, animal sacrifice is the ritual killing and offering of an animal to appease or maintain favour with a deity. It has been banned in India.[157]</p>`
},{
	title: "Science",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 14 (1765), pp. 787–788",
	wSource: "https://en.wikipedia.org/wiki/Science",
	eConn: ["science","knowledge","science","doubt","skeptics","nothing","skeptics","knowledge","sense","doubt","science","principles","opposite","doubt","knowledge","principles","habitus","ratione","certa","knowledge"],
	wConn: ["public","science","natural","sciences","scientific","research","formal","sciences","communication","science","science","knowledge","scientific","method","sciences","study","type","knowledge","social","sciences","scientific","community","science","popular"],
	eArt: `Science, as a philosophical concept, means the clear and certain knowledge of something, whether founded on self-evident principles, or via systematic demonstration.
	<p> The word science is, in this sense, the opposite of doubt; opinion stands midway between science and doubt.</p>
	<p> Skeptics deny the possibility of a science of anything; in other words, according to skeptics, there's nothing about which we can have certain knowledge.</p>
	<p> Science is divided into four branches: intelligence, wisdom, prudence and art.</p>
	<p> Intelligence is constituted by the mind's intuitive perception of the felicitous accord, or lack thereof, between two ideas; such as that of the science of God, and that of the knowledge we have of first principles.</p>
	<p> Wisdom is always striving for generalities, and is only interested in the relations between beings in order to arrive at universal truths. Spiritual beings are also part of wisdom's scope.</p>
	<p> Prudence's aim is to form habits of honesty consonant with eternal and immutable laws. In schools, this is called, habitus verâ cum ratione activus.</p>
	<p> Art confers fail-free rules that allow one to reason well. In school, it is defined as habitus verâ cum ratione effectivus.</p>`,
	wArt:`Science[a][1]:58[2] is a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the universe.[b]
	<p> Contemporary science is typically subdivided into the natural sciences, which study the material universe; the social sciences, which study people and societies; and the formal sciences, which study logic and mathematics. The formal sciences are often excluded as they do not depend on empirical observations.[3] Disciplines which use science, like engineering and medicine, may also be considered to be applied sciences.[4]</p>
	<p> From classical antiquity through the 19th century, science as a type of knowledge was more closely linked to philosophy than it is now, and in the Western world the term "natural philosophy" once encompassed fields of study that are today associated with science, such as astronomy, medicine, and physics.[5][c] However, during the Islamic Golden Age foundations for the scientific method were laid by Ibn al-Haytham in his Book of Optics.[6][7][8][9][10] While the classification of the material world by the ancient Indians and Greeks into air, earth, fire and water was more philosophical, medieval Middle Easterns used practical and experimental observation to classify materials.[11]</p>
	<p> In the 17th and 18th centuries, scientists increasingly sought to formulate knowledge in terms of physical laws. Over the course of the 19th century, the word "science" became increasingly associated with the scientific method itself as a disciplined way to study the natural world. It was during this time that scientific disciplines such as biology, chemistry, and physics reached their modern shapes. That same time period also included the origin of the terms "scientist" and "scientific community", the founding of scientific institutions, and the increasing significance of their interactions with society and other aspects of culture.[12][13]</p>
	<p> The scale of the universe mapped to the branches of science, with formal sciences as the foundation.[14]: Vol.1, Chaps.1,2,&3.</p>
	<p> History</p>
	<p> Main article: History of science</p>
	<p> Science in a broad sense existed before the modern era and in many historical civilizations.[d] Modern science is distinct in its approach and successful in its results, so it now defines what science is in the strictest sense of the term.[15]</p>
	<p> Science in its original sense was a word for a type of knowledge rather than a specialized word for the pursuit of such knowledge. In particular, it was the type of knowledge which people can communicate to each other and share. For example, knowledge about the working of natural things was gathered long before recorded history and led to the development of complex abstract thought. This is shown by the construction of complex calendars, techniques for making poisonous plants edible, and buildings such as the Pyramids. However, no consistent conscientious distinction was made between knowledge of such things, which are true in every community, and other types of communal knowledge, such as mythologies and legal systems.</p>
	<p> Antiquity</p>
	<p> See also: Nature (philosophy)</p>
	<p> Maize, known in some English-speaking countries as corn, is a large grain plant domesticated by indigenous peoples in Mesoamerica in prehistoric times</p>
	<p> Before the invention or discovery of the concept of "nature" (ancient Greek phusis) by the Pre-Socratic philosophers, the same words tend to be used to describe the natural "way" in which a plant grows,[16] and the "way" in which, for example, one tribe worships a particular god. For this reason, it is claimed these men were the first philosophers in the strict sense, and also the first people to clearly distinguish "nature" and "convention."[17]: p.209 Science was therefore distinguished as the knowledge of nature and things which are true for every community, and the name of the specialized pursuit of such knowledge was philosophy — the realm of the first philosopher-physicists. They were mainly speculators or theorists, particularly interested in astronomy. In contrast, trying to use knowledge of nature to imitate nature (artifice or technology, Greek technē) was seen by classical scientists as a more appropriate interest for lower class artisans.[18] A clear-cut distinction between formal (eon) and empirical science (doxa) was made by the pre-Socratic philosopher Parmenides (fl. late sixth or early fifth century BCE). Although his work Peri Physeos (On Nature) is a poem, it may be viewed as an epistemological essay on method in natural science. Parmenides' ἐὸν may refer to a formal system or calculus which can describe nature more precisely than natural languages. "Physis" may be identical to ἐὸν.[19]</p>
	<p> Aristotle, 384 BCE – 322 BCE, one of the early figures in the development of the scientific method[20]</p>
	<p> A major turning point in the history of early philosophical science was the controversial but successful attempt by Socrates to apply philosophy to the study of human things, including human nature, the nature of political communities, and human knowledge itself. He criticized the older type of study of physics as too purely speculative and lacking in self-criticism. He was particularly concerned that some of the early physicists treated nature as if it could be assumed that it had no intelligent order, explaining things merely in terms of motion and matter. The study of human things had been the realm of mythology and tradition, however, so Socrates was executed as a heretic.[21]: 30e Aristotle later created a less controversial systematic programme of Socratic philosophy which was teleological and human-centred. He rejected many of the conclusions of earlier scientists. For example, in his physics, the sun goes around the earth, and many things have it as part of their nature that they are for humans. Each thing has a formal cause and final cause and a role in the rational cosmic order. Motion and change is described as the actualization of potentials already in things, according to what types of things they are. While the Socratics insisted that philosophy should be used to consider the practical question of the best way to live for a human being (a study Aristotle divided into ethics and political philosophy), they did not argue for any other types of applied science.</p>
	<p> Aristotle maintained the sharp distinction between science and the practical knowledge of artisans, treating theoretical speculation as the highest type of human activity, practical thinking about good living as something less lofty, and the knowledge of artisans as something only suitable for the lower classes. In contrast to modern science, Aristotle's influential emphasis was upon the "theoretical" steps of deducing universal rules from raw data and did not treat the gathering of experience and raw data as part of science itself.[e]</p>
	<p> Medieval science</p>
	<p> De potentiis anime sensitive, Gregor Reisch (1504) Margarita philosophica. Medieval science postulated a ventricle of the brain as the location for our common sense,[22] where the forms from our sensory systems commingled.</p>
	<p> Ibn al-Haytham (Alhazen), 965–1039 Basra, Buyid Emirate. The Muslim scholar who is considered by some to be the father of modern scientific methodology due to his emphasis on experimental data and reproducibility of its results.[23][f]</p>
	<p> During late antiquity and the early Middle Ages, the Aristotelian approach to inquiries on natural phenomena was used. Some ancient knowledge was lost, or in some cases kept in obscurity, during the fall of the Roman Empire and periodic political struggles. However, the general fields of science (or "natural philosophy" as it was called) and much of the general knowledge from the ancient world remained preserved through the works of the early Latin encyclopedists like Isidore of Seville. In the Byzantine empire, many Greek science texts were preserved in Syriac translations done by groups such as the Nestorians and Monophysites.[24] Many of these were later on translated into Arabic under the Caliphate, during which many types of classical learning were preserved and in some cases improved upon.[24][g]</p>
	<p> The House of Wisdom was established in Abbasid-era Baghdad, Iraq.[25] It is considered to have been a major intellectual center during the Islamic Golden Age, where Muslim scholars such as al-Kindi and Ibn Sahl in Baghdad and Ibn al-Haytham in Cairo flourished from the ninth to the thirteenth centuries until the Mongol sack of Baghdad. Ibn al-Haytham, known later to the West as Alhazen, furthered the Aristotelian viewpoint[26] by emphasizing experimental data.[h][27]</p>
	<p> In the later medieval period, as demand for translations grew (for example, from the Toledo School of Translators), western Europeans began collecting texts written not only in Latin, but also Latin translations from Greek, Arabic, and Hebrew. In particular, the texts of Aristotle, Ptolemy,[i] and Euclid, preserved in the Houses of Wisdom, were sought amongst Catholic scholars. In Europe, the Latin translation of Alhazen's Book of Optics directly influenced Roger Bacon (13th century) in England, who argued for more experimental science as demonstrated by Alhazen. By the late Middle Ages, a synthesis of Catholicism and Aristotelianism known as Scholasticism was flourishing in western Europe, which had become a new geographic center of science, but all aspects of scholasticism were criticized in the 15th and 16th centuries.</p>
	<p> Renaissance and early modern science</p>
	<p> Main article: Scientific revolution</p>
	<p> Galen (129–c. 216) noted the optic chiasm is X-shaped. (Engraving from Vesalius, 1543)</p>
	<p> Medieval science carried on the views of the Hellenist civilization of Socrates, Plato, and Aristotle, as shown by Alhazen's lost work A Book in which I have Summarized the Science of Optics from the Two Books of Euclid and Ptolemy, to which I have added the Notions of the First Discourse which is Missing from Ptolemy's Book from Ibn Abi Usaibia's catalog, as cited in (Smith 2001).:91(vol.1),p.xv Alhazen conclusively disproved Ptolemy's theory of vision, but he retained Aristotle's ontology; Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon Alhazen's Book of Optics, a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle.[28] This model of vision became known as Perspectivism, which was exploited and studied by the artists of the Renaissance.</p>
	<p> Galileo Galilei, father of modern science.[29]: Vol. 24, No. 1, p. 36</p>
	<p> A. Mark Smith points out the perspectivist theory of vision, which pivots on three of Aristotle's four causes, formal, material, and final, "is remarkably economical, reasonable, and coherent."[30] Although Alhacen knew that a scene imaged through an aperture is inverted, he argued that vision is about perception. This was overturned by Kepler,[31]:p.102 who modelled the eye as a water-filled glass sphere with an aperture in front of it to model the entrance pupil. He found that all the light from a single point of the scene was imaged at a single point at the back of the glass sphere. The optical chain ends on the retina at the back of the eye and the image is inverted.[j]</p>
	<p> Copernicus formulated a heliocentric model of the solar system unlike the geocentric model of Ptolemy's Almagest.</p>
	<p> Galileo made innovative use of experiment and mathematics. However, he became persecuted after Pope Urban VIII blessed Galileo to write about the Copernican system. Galileo had used arguments from the Pope and put them in the voice of the simpleton in the work "Dialogue Concerning the Two Chief World Systems," which greatly offended him.[32]</p>
	<p> In Northern Europe, the new technology of the printing press was widely used to publish many arguments, including some that disagreed widely with contemporary ideas of nature. René Descartes and Francis Bacon published philosophical arguments in favor of a new type of non-Aristotelian science. Descartes argued that mathematics could be used in order to study nature, as Galileo had done, and Bacon emphasized the importance of experiment over contemplation. Bacon questioned the Aristotelian concepts of formal cause and final cause, and promoted the idea that science should study the laws of "simple" natures, such as heat, rather than assuming that there is any specific nature, or "formal cause," of each complex type of thing. This new modern science began to see itself as describing "laws of nature". This updated approach to studies in nature was seen as mechanistic. Bacon also argued that science should aim for the first time at practical inventions for the improvement of all human life.</p>
	<p> Age of Enlightenment</p>
	<p> Isaac Newton, shown here in a 1689 portrait, made seminal contributions to classical mechanics, gravity, and optics. Newton shares credit with Gottfried Leibniz for the development of calculus.</p>
	<p> In the 17th and 18th centuries, the project of modernity, as had been promoted by Bacon and Descartes, led to rapid scientific advance and the successful development of a new type of natural science, mathematical, methodically experimental, and deliberately innovative. Newton and Leibniz succeeded in developing a new physics, now referred to as classical mechanics, which could be confirmed by experiment and explained using mathematics. Leibniz also incorporated terms from Aristotelian physics, but now being used in a new non-teleological way, for example, "energy" and "potential" (modern versions of Aristotelian "energeia and potentia"). In the style of Bacon, he assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes for each type of thing. It is during this period that the word "science" gradually became more commonly used to refer to a type of pursuit of a type of knowledge, especially knowledge of nature — coming close in meaning to the old term "natural philosophy."</p>
	<p> 19th century</p>
	<p> Charles Darwin in 1854, by then working towards publication of On the Origin of Species</p>
	<p> Both John Herschel and William Whewell systematized methodology: the latter coined the term scientist.[33] When Charles Darwin published On the Origin of Species he established evolution as the prevailing explanation of biological complexity. His theory of natural selection provided a natural explanation of how species originated, but this only gained wide acceptance a century later. John Dalton developed the idea of atoms. The laws of thermodynamics and the electromagnetic theory were also established in the 19th century, which raised new questions which could not easily be answered using Newton's framework. The phenomena that would allow the deconstruction of the atom were discovered in the last decade of the 19th century: the discovery of X-rays inspired the discovery of radioactivity. In the next year came the discovery of the first subatomic particle, the electron.</p>
	<p> Combustion and chemical reactions were studied by Michael Faraday and reported in his lectures before the Royal Institution: The Chemical History of a Candle, 1861</p>
	<p> 20th century and beyond</p>
	<p> A simulated event in the CMS detector of the Large Hadron Collider, featuring a possible appearance of the Higgs boson</p>
	<p> Einstein's theory of relativity and the development of quantum mechanics led to the replacement of classical mechanics with a new physics which contains two parts that describe different types of events in nature.</p>
	<p> In the first half of the century, the development of artificial fertilizer made global human population growth possible. At the same time, the structure of the atom and its nucleus was discovered, leading to the release of "atomic energy" (nuclear power). In addition, the extensive use of scientific innovation stimulated by the wars of this century led to antibiotics and increased life expectancy, revolutions in transportation (automobiles and aircraft), the development of ICBMs, a space race, and a nuclear arms race, all giving a widespread public appreciation of the importance of modern science.</p>
	<p> Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones.</p>
	<p> More recently, it has been argued that the ultimate purpose of science is to make sense of human beings and our nature. For example, in his book Consilience, E. O. Wilson said: "The human condition is the most important frontier of the natural sciences".[1]:334</p>
	<p> Scientific method</p>
	<p> Axis scale: billions of years.</p>
	<p> Also see: Human timeline and Life timeline</p>
	<p> Main article: Scientific method</p>
	<p> The scientific method seeks to explain the events of nature in a reproducible way.[k] An explanatory thought experiment or hypothesis is put forward as explanation using principles such as parsimony (also known as "Occam's Razor") and are generally expected to seek consilience—fitting well with other accepted facts related to the phenomena.[1] This new explanation is used to make falsifiable predictions that are testable by experiment or observation. The predictions are to be posted before a confirming experiment or observation is sought, as proof that no tampering has occurred. Disproof of a prediction is evidence of progress.[l][m] This is done partly through observation of natural phenomena, but also through experimentation that tries to simulate natural events under controlled conditions as appropriate to the discipline (in the observational sciences, such as astronomy or geology, a predicted observation might take the place of a controlled experiment). Experimentation is especially important in science to help establish causal relationships (to avoid the correlation fallacy).</p>
	<p> When a hypothesis proves unsatisfactory, it is either modified or discarded.[34] If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural phenomena. A theory typically describes the behavior of much broader sets of phenomena than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. In addition to testing hypotheses, scientists may also generate a model, an attempt to describe or depict the phenomenon in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested, based on observable phenomena.[35]</p>
	<p> While performing experiments to test hypotheses, scientists may have a preference for one outcome over another, and so it is important to ensure that science as a whole can eliminate this bias.[36][37] This can be achieved by careful experimental design, transparency, and a thorough peer review process of the experimental results as well as any conclusions.[38][39] After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be.[40] Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing any effects of subjective bias on the part of its users (especially the confirmation bias).[41]</p>
	<p> Mathematics and formal sciences</p>
	<p> Main article: Mathematics</p>
	<p> A Venn diagram illustrating the intersection of two sets.</p>
	<p> Mathematics is essential to the sciences. One important function of mathematics in science is the role it plays in the expression of scientific models. Observing and collecting measurements, as well as hypothesizing and predicting, often require extensive use of mathematics. For example, arithmetic, algebra, geometry, trigonometry, and calculus are all essential to physics. Virtually every branch of mathematics has applications in science, including "pure" areas such as number theory and topology.</p>
	<p> Statistical methods, which are mathematical techniques for summarizing and analyzing data, allow scientists to assess the level of reliability and the range of variation in experimental results. Statistical analysis plays a fundamental role in many areas of both the natural sciences and social sciences.</p>
	<p> Computational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. According to the Society for Industrial and Applied Mathematics, computation is now as important as theory and experiment in advancing scientific knowledge.[42]</p>
	<p> A great amount of interest was taken in the study of formal logic in the early 20th century among mathematicians and philosophers with the rise of set theory and its use for the foundations of mathematics. Notable mathematicians and philosophers who contributed to this field include: Gottlob Frege, Giuseppe Peano, George Boole, Ernst Zermelo, Abraham Fraenkel, David Hilbert, Bertrand Russell, and Alfred Whitehead among many others. Various axiomatic systems such as Peano arithmetic, the Zermelo–Fraenkel system of set theory, as well as the system in Principia Mathematica, were thought by many to prove the foundations of math. However, in 1931, with the publication of Kurt Gödel's incompleteness theorem, much of their efforts were undermined.[43] Formal logic is still studied today at universities by students of mathematics, philosophy, and computer science. For example, boolean algebra is employed by all modern computers to function, and thus is an extremely useful branch of knowledge for programmers.</p>
	<p> Whether mathematics itself is properly classified as science has been a matter of some debate. Some thinkers see mathematicians as scientists, regarding physical experiments as inessential or mathematical proofs as equivalent to experiments. Others do not see mathematics as a science because it does not require an experimental test of its theories and hypotheses. Mathematical theorems and formulas are obtained by logical derivations which presume axiomatic systems, rather than the combination of empirical observation and logical reasoning that has come to be known as the scientific method. In general, mathematics is classified as formal science, while natural and social sciences are classified as empirical sciences.[44]</p>
	<p> Scientific community</p>
	<p> Main article: Scientific community</p>
	<p> The scientific community is the group of all interacting scientists. It includes many sub-communities working on particular scientific fields, and within particular institutions; interdisciplinary and cross-institutional activities are also significant.</p>
	<p> Branches and fields</p>
	<p> Main article: Branches of science</p>
	<p> The somatosensory system is located throughout our bodies but is integrated in the brain.</p>
	<p> Scientific fields are commonly divided into two major groups: natural sciences, which study natural phenomena (including biological life), and social sciences, which study human behavior and societies. These are both empirical sciences, which means their knowledge must be based on observable phenomena and capable of being tested for its validity by other researchers working under the same conditions.[45] There are also related disciplines that are grouped into interdisciplinary applied sciences, such as engineering and medicine. Within these categories are specialized scientific fields that can include parts of other scientific disciplines but often possess their own nomenclature and expertise.[46]</p>
	<p> Mathematics, which is classified as a formal science,[47][48] has both similarities and differences with the empirical sciences (the natural and social sciences). It is similar to empirical sciences in that it involves an objective, careful and systematic study of an area of knowledge; it is different because of its method of verifying its knowledge, using a priori rather than empirical methods.[49] The formal sciences, which also include statistics and logic, are vital to the empirical sciences. Major advances in formal science have often led to major advances in the empirical sciences. The formal sciences are essential in the formation of hypotheses, theories, and laws,[50] both in discovering and describing how things work (natural sciences) and how people think and act (social sciences).</p>
	<p> Apart from its broad meaning, the word "science" sometimes may specifically refer to fundamental sciences (maths and natural sciences) alone. Science schools or faculties within many institutions are separate from those for medicine or engineering, each of which is an applied science.</p>
	<p> Institutions</p>
	<p> Learned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance period.[51] The oldest surviving institution is the Italian Accademia dei Lincei which was established in 1603.[52] The respective National Academies of Science are distinguished institutions that exist in a number of countries, beginning with the British Royal Society in 1660[53] and the French Académie des Sciences in 1666.[54]</p>
	<p> International scientific organizations, such as the International Council for Science, have since been formed to promote cooperation between the scientific communities of different nations. Many governments have dedicated agencies to support scientific research. Prominent scientific organizations include the National Science Foundation in the U.S., the National Scientific and Technical Research Council in Argentina, CSIRO in Australia, Centre national de la recherche scientifique in France, the Max Planck Society and Deutsche Forschungsgemeinschaft in Germany, and CSIC in Spain.</p>
	<p> Literature</p>
	<p> Main article: Scientific literature</p>
	<p> An enormous range of scientific literature is published.[55] Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, Journal des Sçavans followed by the Philosophical Transactions, began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500.[56] The United States National Library of Medicine currently indexes 5,516 journals that contain articles on topics related to the life sciences. Although the journals are in 39 languages, 91 percent of the indexed articles are published in English.[57]</p>
	<p> Most scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is generally considered necessary to communicate the achievements, news, and ambitions of scientists to a wider populace.</p>
	<p> Science magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science books engage the interest of many more people. Tangentially, the science fiction genre, primarily fantastic in nature, engages the public imagination and transmits the ideas, if not the methods, of science.</p>
	<p> Recent efforts to intensify or develop links between science and non-scientific disciplines such as literature or more specifically, poetry, include the Creative Writing Science resource developed through the Royal Literary Fund.[58]</p>
	<p> Science and society</p>
	<p> "Science and society" redirects here. For the academic journal, see Science & Society.</p>
	<p> Women in science</p>
	<p> Main article: Women in science</p>
	<p> Marie Curie was the first person to be awarded two Nobel Prizes: Physics in 1903 and Chemistry in 1911[59]</p>
	<p> Science has historically been a male-dominated field, with some notable exceptions.[n] Women faced considerable discrimination in science, much as they did in other areas of male-dominated societies, such as frequently being passed over for job opportunities and denied credit for their work.[o] For example, Christine Ladd (1847–1930) was able to enter a PhD program as "C. Ladd"; Christine "Kitty" Ladd completed the requirements in 1882, but was awarded her degree only in 1926, after a career which spanned the algebra of logic (see truth table), color vision, and psychology. Her work preceded notable researchers like Ludwig Wittgenstein and Charles Sanders Peirce. The achievements of women in science have been attributed to their defiance of their traditional role as laborers within the domestic sphere.[60]</p>
	<p> In the late 20th century, active recruitment of women and elimination of institutional discrimination on the basis of sex greatly increased the number of women scientists, but large gender disparities remain in some fields; over half of new biologists are female, while 80% of PhDs in physics are given to men.[citation needed] Feminists claim this is the result of culture rather than an innate difference between the sexes, and some experiments have shown that parents challenge and explain more to boys than girls, asking them to reflect more deeply and logically.[61]: 258–261. In the early part of the 21st century, in America, women earned 50.3% bachelor's degrees, 45.6% master's degrees, and 40.7% of PhDs in science and engineering fields with women earning more than half of the degrees in three fields: Psychology (about 70%), Social Sciences (about 50%), and Biology (about 50-60%). However, when it comes to the Physical Sciences, Geosciences, Math, Engineering, and Computer Science, women earned less than half the degrees.[62] However, lifestyle choice also plays a major role in female engagement in science; women with young children are 28% less likely to take tenure-track positions due to work-life balance issues,[63] and female graduate students' interest in careers in research declines dramatically over the course of graduate school, whereas that of their male colleagues remains unchanged.[64]</p>
	<p> Science policy</p>
	<p> Main articles: Science policy, History of science policy, Funding of science, and Economics of science</p>
	<p> President Clinton meets the 1998 U.S. Nobel Prize winners in the White House</p>
	<p> Science policy is an area of public policy concerned with the policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care and environmental monitoring. Science policy also refers to the act of applying scientific knowledge and consensus to the development of public policies. Science policy thus deals with the entire domain of issues that involve the natural sciences. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public.</p>
	<p> State policy has influenced the funding of public works and science for thousands of years, dating at least from the time of the Mohists, who inspired the study of logic during the period of the Hundred Schools of Thought, and the study of defensive fortifications during the Warring States period in China. In Great Britain, governmental approval of the Royal Society in the 17th century recognized a scientific community which exists to this day. The professionalization of science, begun in the 19th century, was partly enabled by the creation of scientific organizations such as the National Academy of Sciences, the Kaiser Wilhelm Institute, and state funding of universities of their respective nations. Public policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research. Vannevar Bush, director of the Office of Scientific Research and Development for the United States government, the forerunner of the National Science Foundation, wrote in July 1945 that "Science is a proper concern of government."[65]</p>
	<p> Science and technology research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP.[66] In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain industries is higher, and it dominates research in social science and humanities. Similarly, with some exceptions (e.g. biotechnology) government provides the bulk of the funds for basic scientific research. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialisation possibilities rather than "blue-sky" ideas or technologies (such as nuclear fusion).</p>
	<p> Media perspectives</p>
	<p> The mass media face a number of pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter.[67] Few journalists have real scientific knowledge, and even beat reporters who know a great deal about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.[68][69]</p>
	<p> Political usage</p>
	<p> See also: Politicization of science</p>
	<p> Many issues damage the relationship of science to the media and the use of science and scientific arguments by politicians. As a very broad generalisation, many politicians seek certainties and facts whilst scientists typically offer probabilities and caveats. However, politicians' ability to be heard in the mass media frequently distorts the scientific understanding by the public. Examples in the United Kingdom include the controversy over the MMR inoculation, and the 1988 forced resignation of a Government Minister, Edwina Currie, for revealing the high probability that battery farmed eggs were contaminated with Salmonella.[70]</p>
	<p> John Horgan, Chris Mooney, and researchers from the US and Canada have described Scientific Certainty Argumentation Methods (SCAMs), where an organization or think tank makes it their only goal to cast doubt on supported science because it conflicts with political agendas.[71][72][73][74] Hank Campbell and microbiologist Alex Berezow have described "feel-good fallacies" used in politics, especially on the left, where politicians frame their positions in a way that makes people feel good about supporting certain policies even when scientific evidence shows there is no need to worry or there is no need for dramatic change on current programs.[75]: Vol. 78, No. 1. 2–38</p>
	<p> Science and the public</p>
	<p> Various activities are developed to facilitate communication between the general public and science/scientists, such as science outreach, public awareness of science, science communication, science festivals, citizen science, science journalism, public science, and popular science. See Science and the public for related concepts.</p>
	<p> Science is represented by the 'S' in STEM fields.</p>
	<p> Philosophy of science</p>
	<p> See also: Philosophy of science</p>
	<p> Working scientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: (1) that there is an objective reality shared by all rational observers; (2) that this objective reality is governed by natural laws; (3) that these laws can be discovered by means of systematic observation and experimentation.[15] Philosophy of science seeks a deep understanding of what these underlying assumptions mean and whether they are valid.</p>
	<p> The belief that scientific theories should and do represent metaphysical reality is known as realism. It can be contrasted with anti-realism, the view that the success of science does not depend on it being accurate about unobservable entities such as electrons. One form of anti-realism is idealism, the belief that the mind or consciousness is the most basic essence, and that each mind generates its own reality.[p] In an idealistic world view, what is true for one mind need not be true for other minds.</p>
	<p> The Sand Reckoner is a work by Archimedes in which he sets out to determine an upper bound for the number of grains of sand that fit into the universe. In order to do this, he had to estimate the size of the universe according to the contemporary model, and invent a way to analyze extremely large numbers.</p>
	<p> There are different schools of thought in philosophy of science. The most popular position is empiricism,[q] which holds that knowledge is created by a process involving observation and that scientific theories are the result of generalizations from such observations.[76] Empiricism generally encompasses inductivism, a position that tries to explain the way general theories can be justified by the finite number of observations humans can make and hence the finite amount of empirical evidence available to confirm scientific theories. This is necessary because the number of predictions those theories make is infinite, which means that they cannot be known from the finite amount of evidence using deductive logic only. Many versions of empiricism exist, with the predominant ones being Bayesianism[77] and the hypothetico-deductive method.[78]:p236</p>
	<p> Empiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation.[78]:p20 Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories and that the only way a theory can be affected by observation is when it comes in conflict with it.[78]:pp63–7 Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories and replacing induction with falsification as the empirical method.[78]:p68 Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error.[79] It covers all products of the human mind, including science, mathematics, philosophy, and art.[80]</p>
	<p> Another approach, instrumentalism, colloquially termed "shut up and multiply,"[81] emphasizes the utility of theories as instruments for explaining and predicting phenomena.[82] It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should simply be ignored and that scientists shouldn't make a fuss about (see interpretations of quantum mechanics). Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.</p>
	<p> Paul Feyerabend advanced the idea of epistemological anarchism, which holds that there are no useful and exception-free methodological rules governing the progress of science or the growth of knowledge and that the idea that science can or should operate according to universal and fixed rules are unrealistic, pernicious and detrimental to science itself.[83] Feyerabend advocates treating science as an ideology alongside others such as religion, magic, and mythology, and considers the dominance of science in society authoritarian and unjustified. He also contended (along with Imre Lakatos)[discuss] that the demarcation problem of distinguishing science from pseudoscience on objective grounds is not possible and thus fatal to the notion of science running according to fixed, universal rules.[83] Feyerabend also stated that science does not have evidence for its philosophical precepts, particularly the notion of uniformity of law and process across time and space.[84]</p>
	<p> Finally, another approach often cited in debates of scientific skepticism against controversial movements like "creation science" is methodological naturalism. Its main point is that a difference between natural and supernatural explanations should be made and that science should be restricted methodologically to natural explanations.[r] That the restriction is merely methodological (rather than ontological) means that science should not consider supernatural explanations itself, but should not claim them to be wrong either. Instead, supernatural explanations should be left a matter of personal belief outside the scope of science. Methodological naturalism maintains that proper science requires strict adherence to empirical study and independent verification as a process for properly developing and evaluating explanations for observable phenomena.[85] The absence of these standards, arguments from authority, biased observational studies and other common fallacies are frequently cited by supporters of methodological naturalism as characteristic of the non-science they criticize.</p>
	<p> Certainty and science</p>
	<p> The DNA double helix is a molecule that encodes the genetic instructions used in the development and functioning of all known living organisms and many viruses.</p>
	<p> A scientific theory is empirical[q][86] and is always open to falsification if new evidence is presented. That is, no theory is ever considered strictly certain as science accepts the concept of fallibilism.[s] The philosopher of science Karl Popper sharply distinguished truth from certainty. He wrote that scientific knowledge "consists in the search for truth," but it "is not the search for certainty ... All human knowledge is fallible and therefore uncertain."[87]:p4</p>
	<p> New scientific knowledge rarely results in vast changes in our understanding. According to psychologist Keith Stanovich, it may be the media's overuse of words like "breakthrough" that leads the public to imagine that science is constantly proving everything it thought was true to be false.[88]:119–138 While there are such famous cases as the theory of relativity that required a complete reconceptualization, these are extreme exceptions. Knowledge in science is gained by a gradual synthesis of information from different experiments by various researchers across different branches of science; it is more like a climb than a leap.[88]:123 Theories vary in the extent to which they have been tested and verified, as well as their acceptance in the scientific community.[t] For example, heliocentric theory, the theory of evolution, relativity theory, and germ theory still bear the name "theory" even though, in practice, they are considered factual.[89] Philosopher Barry Stroud adds that, although the best definition for "knowledge" is contested, being skeptical and entertaining the possibility that one is incorrect is compatible with being correct. Ironically, then, the scientist adhering to proper scientific approaches will doubt themselves even once they possess the truth.[90] The fallibilist C. S. Peirce argued that inquiry is the struggle to resolve actual doubt and that merely quarrelsome, verbal, or hyperbolic doubt is fruitless[91]—but also that the inquirer should try to attain genuine doubt rather than resting uncritically on common sense.[92] He held that the successful sciences trust not to any single chain of inference (no stronger than its weakest link) but to the cable of multiple and various arguments intimately connected.[93]</p>
	<p> Stanovich also asserts that science avoids searching for a "magic bullet"; it avoids the single-cause fallacy. This means a scientist would not ask merely "What is the cause of ...", but rather "What are the most significant causes of ...". This is especially the case in the more macroscopic fields of science (e.g. psychology, physical cosmology).[88]:141–147 Of course, research often analyzes few factors at once, but these are always added to the long list of factors that are most important to consider.[88]:141–147 For example, knowing the details of only a person's genetics, or their history and upbringing, or the current situation may not explain a behavior, but a deep understanding of all these variables combined can be very predictive.</p>
	<p> Fringe science, pseudoscience, and junk science</p>
	<p> An area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science.[u] Physicist Richard Feynman coined the term "cargo cult science" for cases in which researchers believe they are doing science because their activities have the outward appearance of science but actually lack the "kind of utter honesty" that allows their results to be rigorously evaluated.[94] Various types of commercial advertising, ranging from hype to fraud, may fall into these categories.</p>
	<p> There can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as "bad science," research that may be well-intended but is actually incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term "scientific misconduct" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.[95]</p>
	<p> Scientific practice</p>
	<p> Astronomy became much more accurate after Tycho Brahe devised his scientific instruments for measuring angles between two celestial bodies, before the invention of the telescope. Brahe's observations were the basis for Kepler's laws.</p>
	<p> Although encyclopedias such as Pliny's (fl. 77 AD) Natural History offered purported fact, they proved unreliable. A skeptical point of view, demanding a method of proof, was the practical position taken to deal with unreliable knowledge. As early as 1000 years ago, scholars such as Alhazen (Doubts Concerning Ptolemy), Roger Bacon, Witelo, John Pecham, Francis Bacon (1605), and C. S. Peirce (1839–1914) provided the community to address these points of uncertainty. In particular, fallacious reasoning can be exposed, such as "affirming the consequent."</p>
	<p> "If a man will begin with certainties, he shall end in doubts; but if he will be content to begin with doubts, he shall end in certainties."</p>
	<p> — Francis Bacon, "The Advancement of Learning", Book 1, v, 8</p>
	<p> The methods of inquiry into a problem have been known for thousands of years,[96] and extend beyond theory to practice. The use of measurements, for example, is a practical approach to settle disputes in the community.</p>
	<p> John Ziman points out that intersubjective pattern recognition is fundamental to the creation of all scientific knowledge.[97]:p44 Ziman shows how scientists can identify patterns to each other across centuries; he refers to this ability as "perceptual consensibility."[98]:p46 He then makes consensibility, leading to consensus, the touchstone of reliable knowledge.[98]:p104</p>
	<p> Basic and applied research</p>
	<p> Anthropogenic pollution has an effect on the Earth's environment and climate</p>
	<p> Although some scientific research is applied research into specific problems, a great deal of our understanding comes from the curiosity-driven undertaking of basic research. This leads to options for technological advance that were not planned or sometimes even imaginable. This point was made by Michael Faraday when allegedly in response to the question "what is the use of basic research?" he responded: "Sir, what is the use of a new-born child?".[99] For example, research into the effects of red light on the human eye's rod cells did not seem to have any practical purpose; eventually, the discovery that our night vision is not troubled by red light would lead search and rescue teams (among others) to adopt red light in the cockpits of jets and helicopters.[88]:106–110 In a nutshell, basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Finally, even basic research can take unexpected turns, and there is some sense in which the scientific method is built to harness luck.</p>
	<p> Research in practice</p>
	<p> Due to the increasing complexity of information and specialization of scientists, most of the cutting-edge research today is done by well-funded groups of scientists, rather than individuals.[100] D.K. Simonton notes that due to the breadth of very precise and far reaching tools already used by researchers today and the amount of research generated so far, creation of new disciplines or revolutions within a discipline may no longer be possible as it is unlikely that some phenomenon that merits its own discipline has been overlooked. Hybridizing of disciplines and finessing knowledge is, in his view, the future of science.[100]</p>
	<p> Practical impacts of scientific research</p>
	<p> Discoveries in fundamental science can be world-changing. For example:</p>
	<p> Research	Impact</p>
	<p> Static electricity and magnetism (c. 1600)</p>
	<p> Electric current (18th century)	All electric appliances, dynamos, electric power stations, modern electronics, including electric lighting, television, electric heating, transcranial magnetic stimulation, deep brain stimulation, magnetic tape, loudspeaker, and the compass and lightning rod.</p>
	<p> Diffraction (1665)	Optics, hence fiber optic cable (1840s), modern intercontinental communications, and cable TV and internet</p>
	<p> Germ theory (1700)	Hygiene, leading to decreased transmission of infectious diseases; antibodies, leading to techniques for disease diagnosis and targeted anticancer therapies.</p>
	<p> Vaccination (1798)	Leading to the elimination of most infectious diseases from developed countries and the worldwide eradication of smallpox.</p>
	<p> Photovoltaic effect (1839)	Solar cells (1883), hence solar power, solar powered watches, calculators and other devices.</p>
	<p> The strange orbit of Mercury (1859) and other research</p>
	<p> leading to special (1905) and general relativity (1916)	Satellite-based technology such as GPS (1973), satnav and satellite communications[v]</p>
	<p> Radio waves (1887)	Radio had become used in innumerable ways beyond its better-known areas of telephony, and broadcast television (1927) and radio (1906) entertainment. Other uses included – emergency services, radar (navigation and weather prediction), medicine, astronomy, wireless communications, geophysics, and networking. Radio waves also led researchers to adjacent frequencies such as microwaves, used worldwide for heating and cooking food.</p>
	<p> Radioactivity (1896) and antimatter (1932)	Cancer treatment (1896), Radiometric dating (1905), nuclear reactors (1942) and weapons (1945), mineral exploration, PET scans (1961), and medical research (via isotopic labeling)</p>
	<p> X-rays (1896)	Medical imaging, including computed tomography</p>
	<p> Crystallography and quantum mechanics (1900)	Semiconductor devices (1906), hence modern computing and telecommunications including the integration with wireless devices: the mobile phone[v]</p>
	<p> Plastics (1907)	Starting with Bakelite, many types of artificial polymers for numerous applications in industry and daily life</p>
	<p> Antibiotics (1880s, 1928)	Salvarsan, Penicillin, doxycycline etc.</p>
	<p> Nuclear magnetic resonance (1930s)	Nuclear magnetic resonance spectroscopy (1946), magnetic resonance imaging (1971), functional magnetic resonance imaging (1990s).</p>`
},{
	title: "Slavery",
	eYear: 1755,
	wYear: 2017,
	eSource: "https://quod.lib.umich.edu/cgi/t/text/text-idx?c=did;cc=did;rgn=main;view=text;idno=did2222.0000.667",
	wSource: "",
	eConn: ["civil","law","master","slave","slavery","law","master","life","slavery","nature","man","life","slaves","land","servitude","master","law","master","countries","slavery"],
	wConn: ["slave","trade","forced","marriage","labour","slavery","forced","labour","arab","slave","unfree","labour","slavery","europe","african","slaves","were","sold","slave","empire","million","slaves","labour","against"],
	eArt: `Slavery is the establishment of a right founded on force which renders one man property to another man, who is absolute master of his life, his goods, and his liberty.

	<p> This definition applies almost equally to civil slavery , and to political slavery : in order to sketch its origin, nature, and foundation, I will borrow many things from the author of l’Esprit des lois, without stopping at borrowing the sturdiness of his principles, because I can add nothing to his glory.</p>

	<p> All men are born free; in the beginning they only had one name, one condition. In the times of Saturn and of Rhea, according to Plutarch, there were neither masters nor slaves, nature made them all equal. But this natural equality was gradually set aside and servitude was introduced by degrees, probably founded originally on free contracts, although necessity must have been its source and origin.
	</p>
	<p> When, as a necessary result of the multiplication of the human race, we began to leave behind the simplicity of previous centuries, we sought new means of increasing leisure, and of acquiring surplus goods. There is much evidence that rich men hired the poor to work for them in exchange for a fixed wage. This resource having appeared very useful to both of them, several among them resolved to ensure their state and to enter permanently on the same footing into another’s family, on condition that he furnish food and all other necessities of life. Thus servitude was originally formed by free consent, and by a contract of labor in exchange for goods: do ut fascias . This arrangement was limited to certain things, according to the laws of each country, and the contracts of the interested parties. In essence, such slaves were only properly servitors or mercenaries, similar enough to our domestic servants.
	</p>
	<p> But we didn’t stay that way for long; we found too much advantage in having someone else do that which we would have been obliged to do ourselves. As we sought to expand forces under arms, we established the custom of granting to prisoners of war life and bodily liberty, on condition that they serve forever in the capacity of slaves those into whose hands they had fallen.
	</p>
	<p> As one maintains some residual animosity toward the unfortunates whom one reduced to slavery through force of arms, they were ordinarily treated with much rigor. Cruelty seemed excusable toward people at whose hands one had risked the same fate; it is thus easy to imagine being able to kill such slaves with impunity, as a result of anger or for the slightest error.
	</p>
	<p> This license having once been authorized, it was extended under an even less plausible pretext to those who were born from these slaves, and even to those purchased or acquired in some other manner. Thus servitude came to be naturalized, so to speak, through the lot of war. Those whom fortune favored, and who were left in the state in which nature had created them, were called free. By contrast, those whom weakness and misfortune had subjected to the victors, were called slaves. The philosopher-judges of the merit of men’s actions regard as charitable the conduct of this victor who enslaves his vanquished instead of ending his life.
	</p>
	<p> Slavery was introduced by the law of the strongest, that law of war in offense of nature, and by ambition, thirst for conquest, love of domination and apathy. To the shame of humanity, it has been accepted by almost all of the world’s peoples. Indeed, we could hardly cast our eyes on sacred History without discovering the horrors of servitude. The profane histories of the Greeks, of the Romans, and of all the other peoples who are considered civilized, are all monuments to this ancient injustice exercised with more or less violence across the face of the world, in all times, places, and nations.
	</p>
	<p> There are two kinds of slavery or servitude, real and personal: real servitude includes the slave in the value of land; personal servitude concerns the care of the house, and relates more to the person of the master. The extreme abuse of slavery is when it is at once personal and real. Such was the servitude of foreigners among the Jews, against whom they practiced the harshest treatments. Moses cried in vain to them: “you will not have full dominion over your slaves; you will not oppress them.” His exhortations never succeeded in alleviating the hardness of his ferocious nation, so he strove through his laws to find a remedy.
	</p>
	<p> He began by fixing the term of enslavement, and by ordering that it could only endure until the Jubilee year for foreigners, and for Hebrews only for six years (Leviticus 25:39).
	</p>
	<p> One of the principle reasons for his institution of the Sabbath was to obtain relief for servants and slaves (Exodus 20 and 23, Deuteronomy 16).
	</p>
	<p> He then decreed that no one could sell his own liberty, unless he was reduced to absolutely no livelihood. He mandated that when slaves purchased themselves, their past service had to be accounted for, just as when revenues already realized from sold land were counted in the price of purchase, the former proprietor recovered them. Deuteronomy, chapter xv. Leviticus, chapter xxv.
	</p>
	<p> If a master put out an eye or broke a tooth of his slave (and even more so, of course, if he did something worse), the slave should have his freedom in restitution for this loss.
	</p>
	<p> Another of this legislator’s laws holds that if a master strikes his slave, and the slave dies under the rod, the master must be punished as guilty of homicide: although it is true that the law adds that if the slave lives one or two days, the master is exempt from the penalty. The reason for this law was perhaps that when the slave did not die in the field, one could presume that the master did not intend to kill him; and thus that he could be seen as punished enough in having lost the slave’s value or the service that he would have gotten from him: at least this is what we are led to believe by the commentary on the text, because the slave is his money.
	</p>
	<p> Anyway, it was a very unusual nation, according to M. de Montesquieu, where civil law loosened natural law. That’s not what Saint Paul thought about this issue, when, preaching the enlightenment of the Gospel, he offered this principle of nature and of religion that should be deeply engraved in the hearts of all men: Masters (Letter to Colossians, iv, 1), render to your slaves that which the law and equity demand of you, knowing that you have a master in heaven; that is to say a master that pays no mind to these distinctions of conditions, forged by pride and injustice.
	</p>
	<p> The Lacedemonians were the first in Greece who would introduce the use of slaves, or who first reduced to servitude the Greeks that they had made prisoners of war: they would go even further (and I regret very much that I cannot pull the curtain on this part of their history), they treated their Helots with every last barbarity. These peoples, inhabitants of Spartan territory, having been vanquished during their revolt by the Spartans, were condemned to perpetual slavery , with prohibitions against their masters freeing them or selling them outside the land: thus the Helots found themselves subjected to all of the work outside of the house, and all sorts of insults inside the house. Their misfortune extended to the point that they were not only the slaves of a citizen, but of also of the public. Many peoples only experienced real slavery , because their women and children did domestic work. Other peoples experienced personal slavery , because luxury demanded service of slaves in the house; but here we find in the same individuals both real and personal slavery .
	</p>
	<p> It was not the same among the other peoples of Greece; slavery there was extremely gentle, and even the slaves most rudely treated by their masters could ask to be sold to someone else. We learn this from Plutarch, De superstitione , p. 66. t. I., édition de Wechel.
	</p>
	<p> The Athenians in particular, reports Xenophon, dealt with their slaves with much gentleness: they punished severely, sometimes even with death, those who beat the slave of another. The law of Athens, rightly, did not want to add loss of security to that of liberty; likewise, we do not find that slaves disturbed this republic, as they shook Lacedaemon.
	</p>
	<p> It is easy to see that only humanity exercised toward slaves can prevent, in a moderate government, the dangers that one fears from their too great numbers. Men become accustomed to servitude, provided that their master is not harder than their servitude: nothing more fully confirms this truth, than the state of slaves among the Romans during the beautiful days of the republic; consideration of this state deserves our attention for a few moments.
	</p>
	<p> The first Romans treated their slaves with more goodness than had any other people: the masters regarded them as their companions; they lived, worked, and ate with them. The greatest chastisement that they inflicted on a slave who had committed some fault was to attach a forked rod to his back or his chest, to extend his arms to the two ends of the fork, and to lead him about in public places; this was an ignominious penalty, and nothing more so: morals sufficed to maintain the slaves’ fidelity.
	</p>
	<p> Far from preventing by the force of law the multiplication of these living, animated economic organs, on the contrary they favored it with all of their might, and joined them with a kind of marriage called contuberniis . In this manner they filled their houses with domestics of both sexes and populated the state with innumerable people. The children of slaves eventually composed the fortune of their master, born in trust around him; he alone was charged with their upkeep and their education. The fathers, freed from this burden, followed the inclinations of nature, and reproduced without fear of a large family. They saw without jealousy a happy society, of which they regarded themselves as members. They believed that their soul could be elevated like that of their master, and they did not sense the difference that existed between the condition of a slave and that of a free man. It was often the case that generous masters taught exercises, music, and Greek letters to those among their slaves who showed talents; Terence and Phaedra are very good examples of this kind of education.
	</p>
	<p> The republic created for itself an infinite advantage in this nation of slaves, or rather of subjects: each of them had their peculium , that is to say his small treasure, his small fund, that he possessed on conditions that his master determined. With this peculium he worked on the side according to his talents; this one established a bank, that one devoted himself to the sea trade; one sold retail merchandise, the other applied himself to some mechanical art, leasing or adding value to land. There were none who weren’t devoted to making grow their peculium , which simultaneously procured an easing of present servitude and the hope of future liberty. All these means spread abundance, animating the arts and industry.
	</p>
	<p> These slaves, once enriched, freed themselves and became citizens; the republic renewed itself ceaselessly, and received into its heart new families at the rate that the ancients destroyed each other. Such were the good days of slavery , as long as the Romans preserved their morals and their integrity.
	</p>
	<p> But when expanded through their conquests and their plunder, such that their slaves were no longer their companions in their works, and that they used them to become the instruments of their luxury and their pride, the condition of the slaves changed its complexion entirely. They came to be regarded as the most vile part of the nation, and in consequence no one had any scruples about treating them inhumanely. Because Romans no longer had any morals, they had recourse to laws, which had to be terrible to establish the safety of these cruel masters, living in the midst of their slaves as if in the middle of their enemies.
	</p>
	<p> Under Augustus, which is to say at the beginning of the tyranny, the Syllanien senatorial decree and several other laws were passed that ordained that if a master were to be killed, all of the slaves who were under the same roof or in a place close enough to the house to be able to hear a man’s voice, would be condemned to death. Those who in this case hid a slave to save him would be punished like the murderers. Even those whose master had ordered them to kill him and who had obeyed would be held culpable: he who had not prevented the murder himself would be punished. If a master were killed on a voyage, those who had remained with him were killed as well as those who had fled: we should add that this master, during his life, could kill with impunity his slaves and also torture them. It is true that subsequently there were emperors who mitigated this power. Claudius ordered that ill slaves who were abandoned by their masters would be free if they returned to health. This law assured their liberty in a rare case; it should as well have served to ensure their life, as M. de Montesquieu said so well.
	</p>
	<p> Furthermore, all of these cruel laws that we’ve just described were used even against slaves whose innocence was proven. The laws didn’t depend on civil government, they depended on a vice of civil government. They did not derive from the equity of civil laws, since they were contrary to their principles. They were properly founded on the principle of war, except that in this case the enemies were in the heart of the state. The Syllanien senatorial decree derived, it is said, from the law of nations, which intends that even an imperfect society preserve itself: but a prudent legislator foresees the ill consequences of rendering the legislature terrible. The slaves amongst the Romans could have no confidence in the laws; and therefore the laws could have none in them. In the end the barbarous treatment of the slaves was pushed so far, that it produced the civil war that Florus compared to the Punic wars, and which by its violence shook the Roman Empire to its foundations.
	</p>
	<p> I like to dream that there are still on the earth happy climes whose inhabitants are sweet, tender, and compassionate: such are the Indians of the sub-continent, on this side of the Ganges; they treat their slaves as they treat themselves; they take care of their infants; they marry them and easily give them liberty. In general the slaves of simple working peoples, among whom reigns simplicity of manners, are more happy than everywhere else; they only suffer real slavery , which is less hard for them and more useful for their masters: such were the slaves of the ancient Germans. These peoples, Tacitus said, did not hold them as we do in their houses to make them work there each at a certain task, on the contrary they assigned to each slave his own manor, in which he lived as the father of the family. The only servitude that the master imposed upon him was the obligation to pay a tax in grain, in livestock, in skins, or in fabric: in this manner, the historian adds, you could not distinguish the master from the slave by the pleasures of life.
	</p>
	<p> When they conquered the Gauls, under the name Franks, they would send their slaves to cultivate the lands that thus fell to them: the slaves were called the people of the poet, in Latin gentes potestatis , attached to the land, addicti gleboe [serfs of the land]; and it is from among these serfs that France was thereafter populated. Their multiplication created almost as many villages as there were cultivated farms, and these lands retain the city names that the Romans gave them, and from which came the names village and villains, in Latin villa and villani , to designate the people of the country and of low extraction. One thus sees in France two kinds of slaves, those of the Franks and those of the Gauls, and all went to war, as has been said by M. de Boulainvilliers.
	</p>
	<p> These slaves belonged to their patrons, of whom they were considered to be body men, as it was said then: they became in time subject to rough duties and so attached to the land of their masters that they seemed to be a part of it, such that they could not move elsewhere, nor marry onto the land of another lord without paying what one would call the right of fors-mariage  [1]; and even the children who came from the union of two slaves of different masters were shared, or one of the patrons, to avoid such division, would give another slave in exchange.
	</p>
	<p> A military government where authority is divided among several lords inevitably degenerates into tyranny. This did not fail to happen: the ecclesiastical patrons and the lay patrons everywhere abused their power over their slaves; they weakened theme with too much work, taxes, chores, and with too much ill-treatment. Eventually the unhappy serfs, no longer able to tolerate the heaviness of the yoke, in 1108 staged the famous revolt described by the historians, which ended finally in the attainment of their freedom. Our kings had previously tried without success to soften the state of slavery through their laws.
	</p>
	<p> Meanwhile Christianity, beginning to gain currency, embraced the most humane sentiments; then our sovereigns, determined to weaken the lords and to free the common people from the yoke of their power, took the side of freeing the slaves. Louis the Fat set the example and in freeing the serfs in 1135 he partly succeeded in reclaiming over his vassals the authority they had previously captured: Louis VIII signaled the beginning of his reign by a similar liberation in 1223; finally Louis X called Hutin [the Quarreler], delivered an edict on this subject that seems to us worthy of being reproduced here:
	</p>
	<p> “Louis, by the grace of God, king of France and of Navarre: to our beloved and loyal supporters... as according to the law of nature each must be born free.... We, considering that our kingdom is called and named the kingdom of the Franks, and desiring that the thing in truth should be recognized in name... by deliberation with our grand council, have ordained and do ordain that generally throughout our realm freedom be given in good and valid conditions and so that all the lords who have body men take our example to make them free, etc. Promulgated at Paris the third of July, year of grace 1315.”
	</p>
	<p> Nevertheless it was not until almost the fifteenth century that slavery was abolished in the majority of Europe: meanwhile it remains in much of Poland, in Hungary, in Bohemia, and in several places in lower Germany; see Les ouvrages de MM. Thomasius et Hertins: there are even some traces in our customs, see Coquille. In any case, practically in the space of the century that followed the abolition of slavery in Europe, the Christian powers having made conquests in lands where they believed it in their interest to have slaves, permitted them to be bought and sold, having forgotten the principles of Nature and of Christianity, which render all men equal.
	</p>
	<p> After having reviewed the history of slavery , from its origin to our days, we now will prove that it damages the liberty of man and that it is contrary to natural and civil law, that it offends the structures of the best governments, and that finally it is useless in and of itself.
	</p>
	<p> The liberty of man is a principle which had been recognized for a long time before the birth of J.C. by all of the nations which have practiced generosity. The natural liberty of man is to know no sovereign power on the earth, and to never be subjected to legislative authority of any kind, but to follow only the laws of Nature: liberty in society is to be submitted to a legislative power established by the consent of the community, and not to be subject to whim, to the inconstant, uncertain, and arbitrary will of a single man in particular.
	</p>
	<p> This liberty, by which one is never subjected to absolute power, is united so closely with the safekeeping of man, that it cannot be separated without destroying at the same time his safety and his life. Whoever attempts therefore to usurp absolute power over another, puts himself thereby in a state of war with him, such that the first can only regard the actions of the other as an obvious attempt upon his life. Indeed, from the moment that a man wants me to submit, despite myself, to his empire, I have reason to presume that if I fall into his hands, he will treat me according to his caprice and have no scruples against killing me when the whim takes him. Liberty is, so to speak, the bulwark of my safekeeping, and the foundation of all the other things that belong to me. Thus, he who, in the state of nature, wants to make me a slave authorizes me to resist by all means in order to ensure the security of my person and my goods.
	</p>
	<p> All men naturally having equal liberty and they cannot be stripped of it unless as a result of some criminal action. Certainly, if a man in the state of nature deserves death for something he has done to another man, who has as a result become the master of his life, the latter trade with him, and use him for service since he holds the guilty man’s life in his hands. In this he does no wrong, because in essence, when the criminal finds that his slavery is more heavy and more annoying than is the loss of his existence, he has it in his power to attain the death that he desires through resistance and disobedience to his master.
	</p>
	<p> What makes the death of a criminal in civil society a legitimate choice is that the law that punishes him has been made for his protection. A murderer, for example, has enjoyed the protection of the law that condemns him; it has protected his life in all instances; he can make no complaint against this law. It would not be the same with the law of slavery . The law that establishes slavery would in all cases be against the slave, without ever being for him, and is thus is contrary to the fundamental principle of all societies.
	</p>
	<p> The rights of property over men and over things are two very different rights. Although all lords say ‘this person here is mine’ of each who is submitted to his domination, the property he has in such a man is not the same as that which he can claim for himself when he says, ‘this thing here is mine.’ Property in a thing carries the full right to make use of it, to consume it, and to destroy it, whether for profit or by caprice; as a result, no matter in what manner one disposes of it, one does it no wrong. But the same expression applied to a person signifies only that the lord has a right, exclusive of others, to govern and to prescribe laws for that person, while at the same time he is himself is severally obligated to this same person; furthermore his power over that person is quite limited.
	</p>
	<p> However grand the injuries that one has received from a man, humanity does not permit, once one has reconciled with him, his reduction to a condition where there no longer remains any trace of the natural equality of all men and as a consequence his treatment as an animal of which one is the master to dispose of at one’s whim. Peoples who treated slaves as a goods which they could dispose of at will were nothing other than barbarians.
	</p>
	<p> Not only can one not have property as such in persons, but furthermore it offends reason that a man who has no power over his own life can give to another, either by his consent or by any convention, the right that he does not himself have. It is therefore not true that a free man can sell himself. A sale presupposes a price; when the slave sells himself, all his goods merge with the property of the master. Thus the master gives nothing, and the slave receives nothing. He would have a peculium , one might answer, but the peculium is attached to the person. The liberty of each citizen is a part of the public liberty: this quality, in a popular state is also a part of the sovereignty. If liberty has a price for the buyer, it is priceless for the seller.
	</p>
	<p> Civil law, which has allowed the division of goods among men, is not empowered to count among the number of goods a section of the men who take part in this division. Civil law, which makes restitution for contracts that contain injuries, cannot help but rectify an agreement that contains the most enormous injury of all. Slavery is therefore no less opposed to civil law than it is to natural law. What civil law could prevent a slave from saving himself from servitude, he who is not part of society and as a consequence is not bound by any civil law? He can only be detained by a law of the family, by the law of the master, that is to say by the law of the strongest.
	</p>
	<p> If slavery offends natural law and civil law, it injures as well the best forms of government: it is contrary to monarchical government, in which it is supremely important not to humble or debase human nature. In democracy, where everyone is equal and in aristocracy, where the laws must work so that everyone is as equal as the nature of government can permit, slaves are against the spirit of the constitution; they only serve to give citizens a power and a luxury which they should not have.
	</p>
	<p> Furthermore, in every government and in every country, no matter how punitive the work that the society there demands, everything can be done with free men by encouraging them through compensation and privileges, in apportioning their work to their capabilities, or in supplementing them with machines that art invents and applies according to needs and locales. See evidence in M. de Montesquieu.
	</p>
	<p> Finally we should further add with this illustrious author that slavery is not useful either for the master or for the slave: for the slave, because he can do nothing out of virtue; for the master, because he contracts with his slaves all kinds of vices and bad habits that are contrary to the laws of society. He unwittingly becomes accustomed to the lack of all moral virtues and he becomes proud, touchy, angry, hard, voluptuous, barbaric.
	</p>
	<p> Thus everything converges to leave to man the dignity which is natural to him. Everything cries out to us that one cannot deprive him of that natural dignity which is liberty. The rule of justice is not founded on power, but on that which conforms to nature. Slavery is not only a humiliating state for those who suffer it, but for humanity itself which is degraded by it.
	</p>
	<p> The principles just posed being unassailable, it will not be difficult to demonstrate that slavery can never be whitewashed on any reasonable grounds, not by the law of war, as thought the roman jurisconsults, by the law of acquisition, nor by that of birth, as some moderns have wanted to persuade us. In a word, nothing in the world can render slavery legitimate.
	</p>
	<p> In past centuries, the law of war was said to authorize that of slavery . According to it, prisoners were made slaves so that they would not be killed; but today we are disabused of this nicety, which consisted of making one’s vanquished one’s slave rather than massacring him. It is understood that this supposed charity is only that of a brigand, which glorifies him for having given life to those whom he has not killed. There is no longer anyone except the Tartars who put their prisoners of war to the sword, and who believe that they are pardoning them when they sell them or distribute them to their soldiers. Among all other peoples, those who have not been stripped of all generous sentiment, it is only permissible to kill in war in the case of necessity. From the time that one man makes another his prisoner, it can no longer be said that it is necessary to kill him since he did not do so originally. The only right that war can grant victors over captives is to be able to ensure that their own people are not in any danger.
	</p>
	<p> The acquisition of slaves by means of money can even less establish the right of slavery , because money and all it represents cannot grant the right to strip someone of his liberty. Furthermore, trafficking in slaves like brutal beasts in order to make a vile living is repulsive to our religion, which has emerged in order to efface all traces of tyranny.
	</p>
	<p> Slavery is certainly no better founded on birth. This claimed right falls with the other two, because if a man could not be bought or sold even less could he sell his unborn child. If a prisoner of war cannot be reduced to servitude, even less his child. In vain would one argue that if the children are conceived and put into the world by a slave mother, the master does them no wrong by claiming them and reducing them to the same condition, since the mother having nothing of her own, her children cannot be nourished except by means of the master before whom they are in a state of servitude and who supplies her with food and other necessities of life. These are only frivolous ideas.
	</p>
	<p> If it is absurd that a man could have over another man a right of property, all the more reason that he cannot have it over that man’s children. Moreover, nature gives milk to mothers and has provided sufficiently for their nourishment. The rest of their childhood is so close to the age when they are most capable of being useful, that one could say that he who feeds them in order to be their master gives them nothing. If he has furnished something for the support of the child, the object is so small that any man, however mediocre might be the faculties of his soul and his body, can in a small number of years earn enough to clear this debt. If slavery was founded on food, it would be reduced to those unable to earn their living, but we don’t find any slaves of that sort.
	</p>
	<p> There could be no justice in an agreement, overt or tacit, by which a slave mother would subject the children that she put into the world to the same condition in which she has fallen, because she cannot stipulate for her children.
	</p>
	<p> It has been said, in order to put this reason for enslaving children in a good light, that they would not exist if the master had wanted to use the right given him by war, to kill their mother. But this is to suppose that which is false, that all those who are taken in war (were it the most just in the world) above all the women in question, could legitimately be killed. Esprit des lois , liv. XV .
	</p>
	<p> It was a proud pretention of the Greeks to imagine that since the barbarians were slaves by nature (it was thus that they spoke of them), and the Greeks free, it was just that the first obey the latter. On these grounds, it would be easy to treat as barbarians all peoples whose morals and customs are different than ours and (without other pretext) to attack them in order to subject them to our laws. It is only prejudices of pride and of ignorance that make us renounce humanity.
	</p>
	<p> It is therefore to go directly against the law of nations and against nature to believe that the Christian religion gives those who profess it the right to reduce to servitude those who do not profess it, so as to work more easily for its propagation. It was however this manner of thinking that encouraged the destroyers of America in their crimes; and that is not the only time that religion has been utilized against its own maxims, which teach us that the status of fellow man applies universally.
	</p>
	<p> Finally, it is to play with words, or rather to mock them, to write as has one of our modern authors, that it is small-minded to imagine that it would degrade humanity to have slaves, because the liberty which each European is believed to enjoy is nothing other than the power to break his chain in order to take a new master; as if the chain of a European was the same as that of a slave in our colonies: we can well see that this author has never been put in chains.
	</p>
	<p> Nevertheless, are there no cases or locations where slavery derives from the nature of things? I respond 1) to this question, there are none; I respond next, with M. de Montesquieu, that if there are countries where slavery appears founded on a natural cause, it is those where heat enervates the body, and weakens courage so much that men are only brought to hard labor by fear of chastisement: in those countries, the master being as lax from the perspective of his prince as his slave is in his own view, civil slavery is still accompanied by political slavery .
	</p>
	<p> In arbitrary governments, it is easy to sell oneself, because there political slavery in some fashion annihilates civil liberty. At Achim, Dampier says, everyone seeks to sell himself: some of the principle lords have no fewer than a thousand slaves, who are themselves principle merchants, who have also many slaves below them, and they many others; they are inherited and traded. Free men there, being too weak against the government, seek to become the slaves of those who tyrannize the government.
	</p>
	<p> Note that in these despotic states, where one is already under political slavery , civil slavery is more tolerable than elsewhere: each is content enough to have his subsistence and his life. Thus the condition of the slave is hardly more to bear than the condition of the subject: the two conditions are adjacent. However although in these countries slavery is, as it were, founded on natural causes, it is no less true that slavery is against nature.
	</p>
	<p> In all Muslim states servitude is rewarded by the laziness which is allowed to the slaves that serve for pleasure. It is this laziness which renders the seraglios of the Orient places of delights for even those against whom they are made. Nations that fear only work can find their happiness in these tranquil places; but one sees that there even the goal of the establishment of slavery is betrayed. These last reflections are from de l’Esprit des lois.
	</p>
	<p> We conclude that slavery founded by force, by violence, and in certain climates by an excess of servitude, cannot maintain itself in the world except by the same means.</p>`,
	wArt: `Slavery is, in the strictest sense of the term, any system in which principles of property law are applied to people, allowing individuals to own, buy and sell other individuals, as a de jure form of property.[1] A slave is unable to withdraw unilaterally from such an arrangement and works without remuneration. Many scholars now use the term chattel slavery to refer to this specific sense of legalised, de jure slavery. In a broader sense, however, the word slavery may also refer to any situation in which an individual is de facto forced to work against his or her will. Scholars also use the more generic terms such as unfree labour or forced labour, to refer to such situations.[2] However, and especially under slavery in broader senses of the word, slaves may have some rights and protections according to laws or customs.

	Slavery began to exist before written history, in many cultures.[3] A person could become a slave from the time of their birth, capture, or purchase.

	While slavery was institutionally recognized by most societies, it has now been outlawed in all recognized countries,[4][5] the last being Mauritania in 2007. Nevertheless, there are still more slaves today than at any previous point in history:[6] an estimated 45 million people remain enslaved worldwide.[7] The most common form of the slave trade is now commonly referred to as human trafficking. Chattel slavery is also still practiced by the Islamic State of Iraq and the Levant. In other areas, slavery (or unfree labour) continues through practices such as debt bondage, serfdom, domestic servants kept in captivity, certain adoptions in which children are forced to work as slaves, child soldiers, and forced marriage.[8]

	Contents  [hide] 
	1	Terminology
	2	Types
	2.1	Chattel slavery
	2.2	Bonded labour
	2.3	Forced labour
	2.4	Forced marriage
	2.5	Dependents
	3	Contemporary slavery
	3.1	Distribution
	3.2	Economics
	3.3	Trafficking
	3.4	Examples
	4	History
	4.1	Early History
	4.2	Classical antiquity
	4.3	Middle Ages
	4.4	Modern history
	5	Abolitionism
	6	Characteristics
	6.1	Economics
	6.2	Identification
	7	Apologies
	7.1	Reparations
	8	Other uses of the term
	8.1	Wage slavery
	9	In film
	10	See also
	11	References
	12	Bibliography and further reading
	12.1	Surveys and reference
	13	External links
	13.1	Historical
	13.2	Modern
	Terminology
	The English word slave comes from Old French sclave, from the Medieval Latin sclavus, from the Byzantine Greek σκλάβος, which, in turn, comes from the ethnonym Slav, because in some early Medieval wars many Slavs were captured and enslaved.[9][10] An older interpretation connected it to the Greek verb skyleúo 'to strip a slain enemy'.[11]

	There is a dispute among historians about whether terms such as "unfree labourer" or "enslaved person", rather than "slave", should be used when describing the victims of slavery. According to those proposing a change in terminology, "slave" perpetuates the crime of slavery in language, by reducing its victims to a nonhuman noun instead of, according to Andi Cumbo-Floyd, "carry[ing] them forward as people, not the property that they were". Other historians prefer "slave" because the term is familiar and shorter, or because it accurately reflects the inhumanity of slavery, with "person" implying a degree of autonomy that slavery does not allow for.[12]

	Types

	Photograph of a slave boy in Zanzibar. 'An Arab master's punishment for a slight offense.' c. 1890.
	Chattel slavery
	Chattel slavery, also called traditional slavery, is so named because people are treated as the chattel (personal property) of the owner and are bought and sold as commodities. Although it dominated many societies in the past, this form of slavery has been formally abolished and is very rare today. Even when it can be said to survive, it is not upheld by the legal system of any internationally recognized government.[13]

	Bonded labour
	Main article: Debt bondage
	Indenture, otherwise known as bonded labour or debt bondage is a form of unfree labour under which a person pledges himself or herself against a loan.[14] The services required to repay the debt, and their duration, may be undefined.[14] Debt bondage can be passed on from generation to generation, with children required to pay off their parents' debt.[14] It is the most widespread form of slavery today.[2] Debt bondage is most prevalent in South Asia.[15]


	A Chinese Nationalist soldier, age 10, member of a Chinese division from the X Force, boarding planes in Burma bound for China, May 1944.
	Forced labour
	Main article: Unfree labour
	See also: Human trafficking, Child labour, and Military use of children
	Forced labour, or unfree labour, is sometimes used to refer to when an individual is forced to work against his or her will, under threat of violence or other punishment[2] but the generic term unfree labour is also used to describe chattel slavery, as well as any other situation in which a person is obliged to work against his or her will and a person's ability to work productively is under the complete control of another person. This may also include institutions not commonly classified as slavery, such as serfdom, conscription and penal labour. While some unfree labourers, such as serfs, have substantive, de jure legal or traditional rights, they also have no ability to terminate the arrangements under which they work, are frequently subject to forms of coercion, such as threats of violence, and experience restrictions on their activities and movement outside their place of work.

	Human trafficking primarily involves women and children forced into prostitution.[16] and is the fastest growing form of forced labour,[2] with Thailand, Cambodia, India, Brazil and Mexico having been identified as leading hotspots of commercial sexual exploitation of children.[17]

	In 2007, Human Rights Watch estimated that 200,000 to 300,000 children served as soldiers in current conflicts.[18]

	Forced marriage
	Main article: Forced marriage
	See also: Marriage by abduction and Child marriage
	A forced marriage may be regarded as a form of slavery by one or more of the parties involved in the marriage, as well as by people observing the marriage. People forced into marriage can be required to engage in sexual activity or to perform domestic duties or other work without any personal control. The customs of bride price and dowry that exist in many parts of the world can lead to buying and selling people into marriage.[19][20] Forced marriage continues to be practiced in parts of the world including some parts of Asia and Africa. Forced marriages may also occur in immigrant communities in Europe, the United States, Canada and Australia.[21][22][23][24] Marriage by abduction occurs in many places in the world today, with a national average of 69% of marriages in Ethiopia being through abduction.[25]

	The International Labour Organization defines child and forced marriage as forms of modern-day slavery.[26]

	Dependents
	The word "slave" has also been used to refer to a legal state of dependency to somebody else.[27][28] In many cases, such as in ancient Persia, the situation and lives of such slaves could be better than those of other common citizens.[29]

	Contemporary slavery
	See also: Slavery in Mauritania, Contemporary slavery, Child slavery, Trafficking of children, and Illegal immigration § Slavery

	Modern incidence of slavery, as a percentage of the population, by country. Estimates from the Walk Free Foundation. Estimates by other sources may be higher.

	Child brickyard labourers in Nepal: Thousands of children work as bonded labourers in Asia, particularly in the Indian subcontinent.[30]
	Even though slavery is now outlawed in every country,[31] the number of slaves today is estimated as between 12 million[32] and 29.8 million.[33] Several estimates of the number of slaves in the world have been provided.[34] According to a broad definition of slavery used by Kevin Bales of Free the Slaves (FTS), an advocacy group linked with Anti-Slavery International, there were 27 million people in slavery in 1999, spread all over the world.[35] In 2005, the International Labour Organization provided an estimate of 12.3 million forced labourers.[36] Siddharth Kara has also provided an estimate of 28.4 million slaves at the end of 2006 divided into three categories: bonded labour/debt bondage (18.1 million), forced labour (7.6 million), and trafficked slaves (2.7 million).[37] Kara provides a dynamic model to calculate the number of slaves in the world each year, with an estimated 29.2 million at the end of 2009. According to a 2003 report by Human Rights Watch, an estimated 15 million children in debt bondage in India work in slavery-like conditions to pay off their family's debts.[38][39]

	Distribution
	A report by the Walk Free Foundation in 2013,[40] found India had the highest number of slaves, nearly 14 million, followed by China (2.9 million), Pakistan (2.1 million), Nigeria, Ethiopia, Russia, Thailand, Democratic Republic of Congo, Myanmar and Bangladesh; while the countries with the highest of proportion of slaves were Mauritania, Haiti, Pakistan, India and Nepal.[41]

	In June 2013, U.S. State Department released a report on slavery, it placed Russia, China, Uzbekistan in the worst offenders category, Cuba, Iran, North Korea, Sudan, Syria, and Zimbabwe were also at the lowest level. The list also included Algeria, Libya, Saudi Arabia and Kuwait among a total of 21 countries.[42][43]

	Economics
	While American slaves in 1809 were sold for around $40,000 (in inflation adjusted dollars), a slave nowadays can be bought for just $90, making replacement more economical than providing long term care.[44] Slavery is a multibillion-dollar industry with estimates of up to $35 billion generated annually.[45]

	Trafficking
	Main article: Human trafficking

	A world map showing countries by prevalence of female trafficking
	Trafficking in human beings (also called human trafficking) is one method of obtaining slaves.[46] Victims are typically recruited through deceit or trickery (such as a false job offer, false migration offer, or false marriage offer), sale by family members, recruitment by former slaves, or outright abduction. Victims are forced into a "debt slavery" situation by coercion, deception, fraud, intimidation, isolation, threat, physical force, debt bondage or even force-feeding with drugs of abuse to control their victims.[47] "Annually, according to U.S. government-sponsored research completed in 2006, approximately 800,000 people are trafficked across national borders, which does not include millions trafficked within their own countries. Approximately 80 percent of transnational victims are women and girls and up to 50 percent are minors, reports the U.S. State Department in a 2008 study.[48]

	While the majority of trafficking victims are women, and sometimes children, who are forced into prostitution (in which case the practice is called sex trafficking), victims also include men, women and children who are forced into manual labour.[49] Due to the illegal nature of human trafficking, its exact extent is unknown. A U.S. government report published in 2005, estimates that 600,000 to 800,000 people worldwide are trafficked across borders each year. This figure does not include those who are trafficked internally.[49] Another research effort revealed that between 1.5 million and 1.8 million individuals are trafficked either internally or internationally each year, 500,000 to 600,000 of whom are sex trafficking victims.[37]

	Examples
	[icon]	This section needs expansion. You can help by adding to it. (March 2017)
	Examples of modern slavery are numerous. Child slavery has commonly been used in the production of cash crops and mining.

	Asia
	In 2008, the Nepalese government abolished the Haliya system, under which 20,000 people were forced to provide free farm labour.[50]

	Though slavery was officially abolished in Qing China in 1910,[51] the practice continues unofficially in some regions of the country.[52][53][54] In June and July 2007, 550 people who had been enslaved by brick manufacturers in Shanxi and Henan were freed by the Chinese government.[55] Among those rescued were 69 children.[56] In response, the Chinese government assembled a force of 35,000 police to check northern Chinese brick kilns for slaves, sent dozens of kiln supervisors to prison, punished 95 officials in Shanxi province for dereliction of duty, and sentenced one kiln foreman to death for killing an enslaved worker.[55]

	The North Korean government[57] operates six large political prison camps,[58] where political prisoners and their families (around 200,000 people)[59] in lifelong detention[60] are subjected to hard slave labour,[61] torture and inhumane treatment.[62]

	In November 2006, the International Labour Organization announced it will be seeking "to prosecute members of the ruling Myanmar junta for crimes against humanity" over the continuous unfree labour of its citizens by the military at the International Court of Justice.[63][64] According to the International Labor Organization (ILO), an estimated 800,000 people are subject to forced labour in Myanmar.[65]

	South America and Caribbean
	In 2008, in Brazil about 5,000 slaves were rescued by government authorities as part of an initiative to eradicate slavery, which was reported as ongoing in 2010.[66] Poverty has forced at least 225,000 Haitian children to work as restavecs (unpaid household servants); the United Nations considers this to be a form of slavery.[67]

	Middle East
	Some tribal sheiks in Iraq still keep blacks, called Abd, which means servant or slave in Arabic, as slaves.[68]

	According to media reports from late 2014 the Islamic State of Iraq and the Levant (ISIL) was selling Yazidi and Christian women as slaves.[69][70][71] According to Haleh Esfandiari of the Woodrow Wilson International Center for Scholars, after ISIL militants have captured an area "[t]hey usually take the older women to a makeshift slave market and try to sell them."[72] In mid-October 2014, the UN estimated that 5,000 to 7,000 Yazidi women and children were abducted by ISIL and sold into slavery.[73][74] In the digital magazine Dabiq, ISIL claimed religious justification for enslaving Yazidi women whom they consider to be from a heretical sect. ISIL claimed that the Yazidi are idol worshipers and their enslavement part of the old shariah practice of spoils of war.[75][76][77][78][79] According to The Wall Street Journal, ISIL appeals to apocalyptic beliefs and claims "justification by a Hadith that they interpret as portraying the revival of slavery as a precursor to the end of the world".[80]

	Africa
	Main article: Slavery in contemporary Africa

	Tuareg society is traditionally feudal, ranging from nobles, through vassals, to dark-skinned slaves.[81]

	Burning of a Village in Africa, and Capture of its Inhabitants (p. 12, February 1859, XVI)[82]
	In Mauritania, the last country to abolish slavery (in 1981),[83] it is estimated that up to 600,000 men, women and children, or 20% of the population, are enslaved with many used as bonded labour.[84][85][86] Slavery in Mauritania was criminalized in August 2007.[87] (although slavery as a practice was legally banned in 1981, it was not a crime to own a slave until 2007).[88] Although many slaves have escaped or have been freed since 2007, as of 2012, only one slave-owner had been sentenced to serve time in prison.[89]

	An article in the Middle East Quarterly in 1999 reported that slavery is endemic in Sudan.[90] Estimates of abductions during the Second Sudanese Civil War range from 14,000 to 200,000 people.[91]

	In Niger, slavery is also a current phenomenon. A Nigerien study has found that more than 800,000 people are enslaved, almost 8% of the population.[92][93][94] Niger installed anti slavery provision in 2003.[95][96] In a landmark ruling in 2008, the ECOWAS Community Court of Justice declared that the Republic of Niger failed to protect Hadijatou Mani Koraou from slavery, and awarded Mani CFA 10,000,000 (approximately US$20,000) in reparations.[97]

	Many pygmies in the Republic of Congo and Democratic Republic of Congo belong from birth to Bantus in a system of slavery.[98][99]

	According to the U.S. State Department, more than 109,000 children were working on cocoa farms alone in Ivory Coast in "the worst forms of child labour" in 2002.[100]

	On the night of 14–15 April 2014, a group of militants attacked the Government Girls Secondary School in Chibok, Nigeria. They broke into the school, pretending to be guards,[101] telling the girls to get out and come with them.[102] A large number of students were taken away in trucks, possibly into the Konduga area of the Sambisa Forest where Boko Haram were known to have fortified camps.[102] Houses in Chibok were also burned down in the incident.[103] According to police, approximately 276 children were taken in the attack, of whom 53 had escaped as of 2 May.[104] Other reports said that 329 girls were kidnapped, 53 had escaped and 276 were still missing.[105][106][107] The students have been forced to convert to Islam[108] and into marriage with members of Boko Haram, with a reputed "bride price" of ₦2,000 each ($12.50/£7.50).[109][110] Many of the students were taken to the neighbouring countries of Chad and Cameroon, with sightings reported of the students crossing borders with the militants, and sightings of the students by villagers living in the Sambisa Forest, which is considered a refuge for Boko Haram.[110][111]

	On May 5, 2014 a video in which Boko Haram leader Abubakar Shekau claimed responsibility for the kidnappings emerged. Shekau claimed that "Allah instructed me to sell them...I will carry out his instructions"[112] and "[s]lavery is allowed in my religion, and I shall capture people and make them slaves."[113] He said the girls should not have been in school and instead should have been married since girls as young as nine are suitable for marriage.[112][113]

	History
	Main article: History of slavery

	Slaves working in a mine, Ancient Greece

	Slaves in chains, relief found at Smyrna (present day İzmir, Turkey), 200 AD
	Early history
	Evidence of slavery predates written records, and has existed in many cultures.[3] Slavery is rare among hunter-gatherer populations because it requires economic surpluses and a high population density to be viable. This, although it has existed among unusually resource-rich hunter gatherers, such as the American Indian peoples of the salmon-rich rivers of the Pacific Northwest Coast, slavery became widespread only with the invention of agriculture during the Neolithic Revolution about 11,000 years ago.[114]

	In the earliest known records, slavery is treated as an established institution. The Code of Hammurabi (c. 1760 BC), for example, prescribed death for anyone who helped a slave escape or who sheltered a fugitive.[115] The Bible mentions slavery as an established institution.[3]

	Slavery was known in almost every ancient civilization and society including Sumer, Ancient Egypt, Ancient China, the Akkadian Empire, Assyria, Ancient India, Ancient Greece, the Roman Empire, the Hebrew kingdoms of the ancient Levant, and the pre-Columbian civilizations of the Americas.[3] Such institutions included debt-slavery, punishment for crime, the enslavement of prisoners of war, child abandonment, and the birth of slave children to slaves.[116]

	Classical antiquity
	Main articles: Slavery in ancient Greece and Slavery in ancient Rome

	The work of the Mercedarians was in ransoming Christian slaves held in Muslim hands (1637).
	Records of slavery in Ancient Greece date as far back as Mycenaean Greece. It is certain that Classical Athens had the largest slave population, with as many as 80,000 in the 6th and 5th centuries BC;[117] two to four-fifths of the population were slaves.[118] As the Roman Republic expanded outward, entire populations were enslaved, thus creating an ample supply from all over Europe and the Mediterranean. Greeks, Illyrians, Berbers, Germans, Britons, Thracians, Gauls, Jews, Arabs, and many more were slaves used not only for labour, but also for amusement (e.g. gladiators and sex slaves). This oppression by an elite minority eventually led to slave revolts (see Roman Servile Wars); the Third Servile War led by Spartacus (a Thracian) being the most famous and bitter.

	By the late Republican era, slavery had become a vital economic pillar in the wealth of Rome, as well as a very significant part of Roman society.[119] It is estimated that 25% or more of the population of Ancient Rome was enslaved, although the actual percentage is debated by scholars, and varied from region to region.[120][121] Slaves represented 15–25% of Italy's population,[122] mostly captives in war[122] especially from Gaul[123] and Epirus. Estimates of the number of slaves in the Roman Empire suggest that the majority of slaves were scattered throughout the provinces outside of Italy.[122] Generally, slaves in Italy were indigenous Italians,[124] with a minority of foreigners (including both slaves and freedmen) born outside of Italy estimated at 5% of the total in the capital at its peak, where their number was largest. Those from outside of Europe were predominantly of Greek descent, while the Jewish ones never fully assimilated into Roman society, remaining an identifiable minority. These slaves (especially the foreigners) had higher death rates and lower birth rates than natives, and were sometimes even subjected to mass expulsions.[125] The average recorded age at death for the slaves of the city of Rome was extraordinarily low: seventeen and a half years (17.2 for males; 17.9 for females).[126][page needed]

	Middle Ages
	Medieval and Early Modern Europe
	Main articles: Slavery in medieval Europe and Barbary slave trade
	See also: Serfdom

	Adalbert of Prague accuses the Jews of the Christian slave trade against Boleslaus II, Duke of Bohemia, relief of Gniezno Doors
	Large-scale trading in slaves was mainly confined to the South and East of early medieval Europe: the Byzantine Empire and the Muslim world were the destinations, while pagan Central and Eastern Europe (along with the Caucasus and Tartary) were important sources. Viking, Arab, Greek, and Radhanite Jewish merchants were all involved in the slave trade during the Early Middle Ages.[127][128][129] The trade in European slaves reached a peak in the 10th century following the Zanj rebellion which dampened the use of African slaves in the Arab world.[130][131]

	Medieval Spain and Portugal were the scene of almost constant Muslim invasion of the predominantly Christian area. Periodic raiding expeditions were sent from Al-Andalus to ravage the Iberian Christian kingdoms, bringing back booty and slaves. In raid against Lisbon, Portugal in 1189, for example, the Almohad caliph Yaqub al-Mansur took 3,000 female and child captives, while his governor of Córdoba, in a subsequent attack upon Silves, Portugal in 1191, took 3,000 Christian slaves.[132] From the 11th to the 19th century, North African Barbary Pirates engaged in Razzias, raids on European coastal towns, to capture Christian slaves to sell at slave markets in places such as Algeria and Morocco.[133][134]


	Depiction of socage on the royal demesne in feudal England, ca. 1310. Socage is an aspect of serfdom, not usually included under the term "slavery".
	In Britain, slavery continued to be practiced following the fall of Rome and sections of Hywel the Good's laws dealt with slaves in medieval Wales. The trade particularly picked up after the Viking invasions, with major markets at Chester[135] and Bristol[136] supplied by Danish, Mercian, and Welsh raiding of one another's borderlands. At the time of the Domesday Book, nearly 10% of the English population were slaves.[137] Slavery in early medieval Europe was so common that the Roman Catholic Church repeatedly prohibited it — or at least the export of Christian slaves to non-Christian lands was prohibited at e.g. the Council of Koblenz (922), the Council of London (1102) aimed mainly at the sale of English slaves to Ireland[138] and having no legal standing), and the Council of Armagh (1171). In 1452, Pope Nicholas V issued the papal bull Dum Diversas, granting the kings of Spain and Portugal the right to reduce any "Saracens (antiquated term referring to Muslims), pagans and any other unbelievers" to perpetual slavery, legitimizing the slave trade as a result of war.[139] The approval of slavery under these conditions was reaffirmed and extended in his Romanus Pontifex bull of 1455. However, Pope Paul III forbade enslavement of the Native Americans in 1537 in his papal bull Sublimus Dei.[140] Dominican friars who arrived at the Spanish settlement at Santo Domingo strongly denounced the enslavement of the local Native Americans. Along with other priests, they opposed their treatment as unjust and illegal in an audience with the Spanish king and in the subsequent royal commission.[141]


	Crimean Tatar raiders enslaved more than 1 million Eastern Europeans.[142]
	The Byzantine-Ottoman wars and the Ottoman wars in Europe brought large numbers of slaves into the Islamic world.[143] To staff its bureaucracy, the Ottoman Empire established a janissary system which seized hundreds of thousands of Christian boys through the devşirme system. They were well cared for but were legally slaves owned by the government and were not allowed to marry. They were never bought or sold. The Empire gave them significant administrative and military roles. The system began about 1365; there were 135,000 janissaries in 1826, when the system ended.[144] After the Battle of Lepanto, 12,000 Christian galley slaves were recaptured and freed from the Ottoman fleet.[145] Eastern Europe suffered a series of Tatar invasions, the goal of which was to loot and capture slaves into jasyr.[146] Seventy-five Crimean Tatar raids were recorded into Poland–Lithuania between 1474 and 1569.[147]

	Approximately 10–20% of the rural population of Carolingian Europe consisted of slaves.[148] Slavery largely disappeared from Western Europe by the later Middle Ages.[149] The slave trade became illegal in England in 1102,[150] but England went on to become very active in the lucrative Atlantic slave trade from the seventeenth to the early nineteenth century. In Scandinavia, thralldom was abolished in the mid-14th century.[151] Slavery persisted longer in Eastern Europe. Slavery in Poland was forbidden in the 15th century; in Lithuania, slavery was formally abolished in 1588; they were replaced by the second serfdom. In Kievan Rus and Muscovy, slaves were usually classified as kholops.

	China
	In the process of the Mongols invasion of China proper, many Han Chinese were enslaved by the Mongols. According to Japanese historian Sugiyama Masaaki (杉山正明) and Funada Yoshiyuki (舩田善之), there were also certain number of Mongolian slaves owned by Han Chinese during the Yuan dynasty. Moreover, there is no evidence that Han Chinese, who were considered people of the bottom of Yuan society by some research, were suffered a particularly cruel abuse. In the early Qing dynasty, many Han Chinese were enslaved by the Manchurian rulers, some of them found themselves in positions of power and influence in Manchu administrations and owned their own Han Chinese slaves.[152][153][154]

	Arab slave trade
	Main article: Arab slave trade

	13th century slave market in Yemen. Yemen officially abolished slavery in 1962.[155]
	In early Islamic states of the Western Sudan (present-day West Africa), including Ghana (750–1076), Mali (1235–1645), Segou (1712–1861), and Songhai (1275–1591), about a third of the population was enslaved.[156]

	Slaves were purchased or captured on the frontiers of the Islamic world and then imported to the major centres, where there were slave markets from which they were widely distributed.[157][158][159] In the 9th and 10th centuries, the black Zanj slaves may have constituted at least a half of the total population of lower Iraq.[156] At the same time, many slaves in the region were also imported from Central Asia and the Caucasus.[156] Many slaves were taken in the wars with the Christian nations of medieval Europe.

	Africa
	Slavery was also widespread in Africa, with both internal and external slave trade.[160]

	Modern history
	Europe
	See also: Crimean-Nogai raids into East Slavic lands

	An 1852 Wallachian poster advertising an auction of Roma slaves in Bucharest

	«The White Slave» (Eberle, 1913)
	Until the late 18th century, the Crimean Khanate (a Muslim Tatar state) maintained a massive slave trade with the Ottoman Empire and the Middle East,[146] exporting about 2 million slaves from Poland-Lithuania and Russia over the period 1500–1700.[161]

	During the Second World War (1939–1945) Nazi Germany effectively enslaved about 12 million people, both those considered undesirable and citizens of countries they conquered, with the avowed intention of treating these untermenschen as a permanent slave class of inferior beings who could be worked until they died but who possessed neither the rights nor the legal status of members of the Aryan race.[162]

	Ottoman Empire
	Main articles: Zanj, Arab slave trade, Barbary slave trade, and Devshirme
	The Ottoman Empire owned and traded slaves on a massive scale. Many slaves were the created by conquest and the suppression of rebellions, in the aftermath of which, entire populations were sometimes enslaved and sold across the Empire, reducing the risk of future rebellion. The Ottomans also purchased slaves from traders who brought slaves into the Empire from Europe and Africa.

	Africa
	Main article: Slavery in Africa

	The main routes that were used to transport slaves across medieval Africa.
	In Algiers, the capital of Algeria, captured Christians and Europeans were forced into slavery. Raids by Barbary pirates on coastal villages and ships extending from Italy to Iceland, enslaved an estimated 1 million to 1¼ million Europeans between the 16th and 19th centuries.[163] This eventually led to the bombardment of Algiers by an Anglo-Dutch fleet in 1816.[164][165]


	Slave traders in Gorée, Senegal, 18th century
	Half the population of the Sokoto caliphate of the 19th century (based in the future northern Nigeria) were slaves.[156] The Swahili-Arab slave trade reached its height about 160 years ago, when, for example, approximately 20,000 slaves were considered to be carried yearly from Nkhotakota on Lake Malawi to Kilwa.[166] Roughly half the population of Madagascar was enslaved.[156][167]

	According to the Encyclopedia of African History, "It is estimated that by the 1890s the largest slave population of the world, about 2 million people, was concentrated in the territories of the Sokoto Caliphate. The use of slave labour was extensive, especially in agriculture."[168][169] The Anti-Slavery Society estimated there were 2 million slaves in Ethiopia in the early 1930s out of an estimated population of 8 to 16 million.[170]


	Arab slave traders and their captives along the Ruvuma river (in today's Tanzania and Mozambique).
	Hugh Clapperton in 1824 believed that half the population of Kano were enslaved people.[171] W. A. Veenhoven wrote: "The German doctor, Gustav Nachtigal, an eye-witness, believed that for every slave who arrived at a market three or four died on the way ... Keltie (The Partition of Africa, London, 1920) believes that for every slave the Arabs brought to the coast at least six died on the way or during the slavers' raid. Livingstone puts the figure as high as ten to one."[172]

	One of the most famous slave traders on the eastern Zanj (Bantu) coast was Tippu Tip, himself the grandson of a slave. The prazeros were slave-traders along the Zambezi. North of the Zambezi, the waYao and Makua people played a similar role as professional slave-raiders and -traders. Still further north were the Nyamwezi slave-traders.[173]

	Asia
	See also: History of slavery in Asia

	A contract from the Tang dynasty that records the purchase of a 15-year-old slave for six bolts of plain silk and five Chinese coins.
	In Constantinople, about one-fifth of the population consisted of slaves.[156] The city was a major centre of the slave trade in the 15th and later centuries. By 1475 most of the slaves were provided by Tatar raids on Slavic villages.[174] It has been estimated that some 200,000 slaves—mainly Circassians—were imported into the Ottoman Empire between 1800 and 1909.[175] As late as 1908, women slaves were still sold in the Ottoman Empire.[176] A slave market for captured Russian and Persian slaves was centred in the Central Asian khanate of Khiva.[177] In the early 1840s, the population of the Uzbek states of Bukhara and Khiva included about 900,000 slaves.[175] Darrel P. Kaiser wrote, "Kazakh-Kirghiz tribesmen kidnapped 1573 settlers from colonies [German settlements in Russia] in 1774 alone and only half were successfully ransomed. The rest were killed or enslaved."[178]

	According to Sir Henry Bartle Frere (who sat on the Viceroy's Council), there were an estimated 8 or 9 million slaves in India in 1841. About 15% of the population of Malabar were slaves. Slavery was abolished in British India by the Indian Slavery Act V. of 1843.[3]

	In East Asia, the Imperial government formally abolished slavery in China in 1906, and the law became effective in 1910.[179] The Nangzan in Tibetan history were, according to Chinese sources, hereditary household slaves.[180]

	In the Joseon period of Korea, members of the slave class were known as nobi. The nobi were socially indistinct from freemen other than the ruling yangban class, and some possessed property rights, legal entities and civil rights. Hence, some scholars argue that it's inappropriate to call them "slaves",[181] while some scholars describe them as serfs.[182][183] The nobi population could fluctuate up to about one-third of the population, but on average the nobi made up about 10% of the total population.[184] In 1801, the vast majority of government nobi were emancipated,[185] and by 1858 the nobi population stood at about 1.5 percent of the total population of Korea.[186] The hereditary nobi system was officially abolished around 1886–87 and the rest of the nobi system was abolished with the Gabo Reform of 1894,[186] but traces remained until 1930.

	In late 16th century Japan, slavery as such was officially banned, but forms of contract and indentured labour persisted alongside the period penal codes' forced labour.[187]

	The hill tribe people in Indochina were "hunted incessantly and carried off as slaves by the Siamese (Thai), the Anamites (Vietnamese), and the Cambodians".[188] A Siamese military campaign in Laos in 1876 was described by a British observer as having been "transformed into slave-hunting raids on a large scale".[189] The census, taken in 1879, showed that 6% of the population in the Malay sultanate of Perak were slaves.[175] Enslaved people made up about two-thirds of the population in part of North Borneo in the 1880s.[175]

	Throughout the 1930s and 1940s the Yi people (also known as Nuosu) of China terrorized Sichuan to rob and enslave non-Nuosu including Han people. The descendants of the Han Chinese slaves are the White Yi (白彝) and they outnumber the Black Yi (黑彝) aristocracy by ten to one.[190] As much as tens of thousands of Han slaves were incorporated into Nuosu society every year. The Han slaves and their offspring were used for manual labor.[191] There is a saying goes like: "the worst insult to a Nuosu is to call him a "Han" (with the implication being that "your ancestors were slaves")".[192]

	Americas
	Further information: Atlantic slave trade, Encomienda, Mita (Inca), Slavery in Brazil, and Slavery in the United States

	The Brazilian slave-hunter, 1823, by Johann Moritz Rugendas
	Slavery in the Americas had a contentious history, and played a major role in the history and evolution of some countries, triggering at least one revolution and one civil war, as well as numerous rebellions. The Aztecs had slaves.[193] Other Amerindians, such as the Inca of the Andes, the Tupinambá of Brazil, the Creek of Georgia, and the Comanche of Texas, also owned slaves.[3]

	The maritime town of Lagos was the first slave market created in Portugal (one of the earliest colonizers of the Americas) for the sale of imported African slaves—the Mercado de Escravos, opened in 1444.[194][195] In 1441, the first slaves were brought to Portugal from northern Mauritania.[195]

	In 1519, Mexico's first Afro-Mexican slave was brought by Hernán Cortés.

	By 1552, black African slaves made up 10% of the population of Lisbon.[196][197] In the second half of the 16th century, the Crown gave up the monopoly on slave trade and the focus of European trade in African slaves shifted from import to Europe to slave transports directly to tropical colonies in the Americas—in the case of Portugal, especially Brazil.[195] In the 15th century one-third of the slaves were resold to the African market in exchange of gold.[198]

	In order to establish itself as an American empire, Spain had to fight against the relatively powerful civilizations of the New World. The Spanish conquest of the indigenous peoples in the Americas included using the Natives as forced labour. The Spanish colonies were the first Europeans to use African slaves in the New World on islands such as Cuba and Hispaniola, see Atlantic slave trade.[199]


	The public flogging of a slave in Rio de Janeiro, Brazil. From Jean Baptiste Debret, Voyage Pittoresque et Historique au Brésil (1834–1839).
	Bartolomé de Las Casas a 16th-century Dominican friar and Spanish historian participated in campaigns in Cuba (at Bayamo and Camagüey) and was present at the massacre of Hatuey; his observation of that massacre led him to fight for a social movement away from the use of natives as slaves and towards the importation of African Blacks as slaves. Also, the alarming decline in the native population had spurred the first royal laws protecting the native population (Laws of Burgos, 1512–1513).

	The first African slaves arrived in Hispaniola in 1501.[200] In 1518, Charles I of Spain agreed to ship slaves directly from Africa. England played a prominent role in the Atlantic slave trade. The "slave triangle" was pioneered by Francis Drake and his associates. In 1640 a Virginia court sentenced John Punch to slavery, forcing him to serve his master, Hugh Gwyn, for the remainder of his life. This was the first legal sanctioning of slavery in the English colonies.[201][202] In 1655, A black man, Anthony Johnson of Virginia, was granted ownership of John Casor as the result of a civil case.[203]

	The Henrietta Marie was probably built in France sometime in the 17th century and carried a crew of about eighteen men. The ship came into English possession late in the 17th century, possibly as a war prize during the War of the Grand Alliance. It was put to use in the Atlantic slave trade, making at least two voyages carrying Africans to slavery in the West Indies. On its first voyage, in 1697–1698, the ship carried more than 200 people from Africa that were sold as slaves in Barbados. In 1699 the Henrietta Marie sailed from England on the first leg of the triangular trade route with a load of trade goods, including iron and copper bars, pewter utensils, glass beads, cloth and brandy. The ship sailed under license from the Royal African Company (which held a monopoly on English trade with Africa), in exchange for ten percent of the profits of the voyage. It is known to have traded for African captives at New Calabar on the Guinea Coast. The ship then sailed on the second leg of its voyage, from Africa to the West Indies, and in May 1701 landed 191 Africans for sale in Port Royal, Jamaica. The Henrietta Marie then loaded a cargo of sugar, cotton, dyewoods (indigo) and ginger to take back to England on the third leg of the triangular route. After leaving Port Royal on 18 May 1701, the ship headed for the Yucatán Channel to pass around the western end of Cuba (thus avoiding the pirates infesting the passage between Cuba and Hispaniola) and catch the Gulf Stream, the preferred route for all ships leaving the Caribbean to return to Europe. A month later, the Henrietta Marie wrecked on New Ground Reef near the Marquesas Keys, approximately 35 miles (56 kilometres) west of Key West. All aboard were lost.[204]


	Planting the sugar cane, British colony of Antigua, 1823
	Pirates often targeted slavers. For example, the 300 ton English frigate Concord launched in 1710 but was captured by the French one year later. She was modified to hold more cargo, including slaves, and renamed La Concorde de Nantes. Sailing as a slave ship, she was captured by the pirate Captain Benjamin Hornigold on November 28, 1717, near the island of Martinique. Hornigold turned her over to one of his men, Edward Teach (later known as Blackbeard), and made him her captain. Teach then renamed her the Queen Anne's Revenge.[205] By 1750, slavery was a legal institution in all of the 13 American colonies,[206][207] and the profits of the slave trade and of West Indian plantations amounted to 5% of the British economy at the time of the Industrial Revolution.[208]

	The trans-Atlantic slave trade peaked in the late 18th century, when the largest number of slaves were captured on raiding expeditions into the interior of West Africa. These expeditions were typically carried out by African kingdoms, such as the Oyo empire (Yoruba), the Ashanti Empire,[209] the kingdom of Dahomey,[210] and the Aro Confederacy.[211] Europeans rarely entered the interior of Africa, due to fierce African resistance. The slaves were brought to coastal outposts where they were traded for goods. A significant portion of African Americans in North America are descended from Mandinka people.[212] Through a series of conflicts, primarily with the Fulani Jihad States, about half of the Senegambian Mandinka were converted to Islam while as many as a third were sold into slavery to the Americas through capture in conflict.[212]


	Slaves on a Virginia plantation (The Old Plantation, c. 1790)

	Mid-19th century portrait of an older New Orleans woman with her child slave servant
	An estimated 12 million Africans arrived in the Americas from the 16th to the 19th centuries.[213] Of these, an estimated 645,000 were brought to what is now the United States. The usual estimate is that about 15% of slaves died during the voyage, with mortality rates considerably higher in Africa itself in the process of capturing and transporting indigenous peoples to the ships.[214]

	Many Europeans who arrived in North America during the 17th and 18th centuries came under contract as indentured servants.[215] The transformation from indentured servitude to slavery was a gradual process in Virginia. The earliest legal documentation of such a shift was in 1640 where a negro, John Punch, was sentenced to lifetime slavery for attempting to run away. This case also marked the disparate treatment of Africans as held by the Virginia County Court, as two white runaways received far lesser sentences.[216] After 1640, planters started to ignore the expiration of indentured contracts and kept their servants as slaves for life. This was demonstrated by the case Johnson v. Parker, where the court ruled that John Casor, an indentured servant, be returned to Johnson who claimed that Casor belonged to him for his life.[217][218] According to the 1860 U. S. census, 393,975 individuals, representing 8% of all US families, owned 3,950,528 slaves.[219] One-third of Southern families owned slaves.[220]


	Funeral at slave plantation, Suriname. Colored lithograph printed circa 1840–1850, digitally restored.
	The largest number of slaves were shipped to Brazil.[221] In the Spanish viceroyalty of New Granada, corresponding mainly to modern Panama, Colombia, and Venezuela, the free black population in 1789 was 420,000, whereas African slaves numbered only 20,000. Free blacks also outnumbered slaves in Brazil. By contrast, in Cuba, free blacks made up only 15% in 1827; and in the French colony of Saint-Domingue (present-day Haiti) it was a mere 5% in 1789.[222]

	Author Charles Rappleye argued that:

	In the West Indies in particular, but also in North and South America, slavery was the engine that drove the mercantile empires of Europe. It appeared, in the eighteenth century, as universal and immutable as human nature.[223]


	Lady in litter being carried by her slaves, province of São Paulo in Brazil, ca.1860.
	Although the trans-Atlantic slave trade ended shortly after the American Revolution, slavery remained a central economic institution in the Southern states of the United States, from where slavery expanded with the westward movement of population.[224] Historian Peter Kolchin wrote, "By breaking up existing families and forcing slaves to relocate far from everyone and everything they knew" this migration "replicated (if on a reduced level) many of [the] horrors" of the Atlantic slave trade.[225]

	Historian Ira Berlin called this forced migration the Second Middle Passage. Characterizing it as the "central event" in the life of a slave between the American Revolution and the Civil War, Berlin wrote that whether they were uprooted themselves or simply lived in fear that they or their families would be involuntarily moved, "the massive deportation traumatized black people, both slave and free.."[226]

	By 1860, 500,000 slaves had grown to 4 million. As long as slavery expanded, it remained profitable and powerful and was unlikely to disappear. Although complete statistics are lacking, it is estimated that 1,000,000 slaves moved west from the Old South between 1790 and 1860.[227]

	Most of the slaves were moved from Maryland, Virginia, and the Carolinas. Michael Tadman, in a 1989 book Speculators and Slaves: Masters, Traders, and Slaves in the Old South, indicates that 60–70% of interregional migrations were the result of the sale of slaves. In 1820, a child in the Upper South had a 30% chance to be sold south by 1860.[227]

	In Puerto Rico, African slavery was finally abolished on March 22, 1873.


	Page Boy with slave collar, Dutch 17th-century painting
	Middle East
	Main article: Arab slave trade
	See also: Slavery (Ottoman Empire), Islamic views on slavery, and Slavery on the Barbary Coast

	Ottoman wars in Europe resulted in many captive Christians being carried deep into Muslim territory.
	According to Robert Davis, between 1 million and 1.25 million Europeans were captured by Barbary pirates and sold as slaves in North Africa and Ottoman Empire between the 16th and 19th centuries.[228][229] There was also an extensive trade in Christian slaves in the Black Sea region for several centuries until the Crimean Khanate was destroyed by the Russian Empire in 1783.[230] In the 1570s close to 20,000 slaves a year were being sold in the Crimean port of Kaffa.[231] The slaves were captured in southern Russia, Poland-Lithuania, Moldavia, Wallachia, and Circassia by Tatar horsemen.[232] Some researchers estimate that altogether more than 3 million people were captured and enslaved during the time of the Crimean Khanate.[233][234]


	Persian slave in the Khanate of Khiva, 19th century

	British captain witnessing the miseries of the Christian slaves in Algiers, 1815

	The Arab enslavement of the Dinka people.
	The Arab slave trade lasted more than a millennium.[235] As recently as the early 1960s, Saudi Arabia's slave population was estimated at 300,000.[236] Along with Yemen, the Saudis abolished slavery only in 1962.[237] Historically, slaves in the Arab World came from many different regions, including Sub-Saharan Africa (mainly Zanj),[238] the Caucasus (mainly Circassians),[239] Central Asia (mainly Tartars), and Central and Eastern Europe (mainly Saqaliba).[240]

	Under Omani Arabs Zanzibar became East Africa's main slave port, with as many as 50,000 enslaved Africans passing through every year during the 19th century.[241][242] Some historians estimate that between 11 and 18 million African slaves crossed the Red Sea, Indian Ocean, and Sahara Desert from 650 to 1900 AD.[3][243] Eduard Rüppell described the losses of Sudanese slaves being transported on foot to Egypt: "after the Daftardar bey's 1822 campaign in the southern Nuba mountains, nearly 40,000 slaves were captured. However, through bad treatment, disease and desert travel barely 5000 made it to Egypt.."[244]

	The Moors, starting in the 8th century, also raided coastal areas around the Mediterranean and Atlantic Ocean, and became known as the Barbary pirates.[245] It is estimated that they captured 1.25 million white slaves from Western Europe and North America between the 16th and 19th centuries.[246][247] The mortality rate was very high. For instance, plague killed a third to two-thirds of the 30,000 occupants of the slave pens in Algiers in 1662.[228]

	Abolitionism
	Main article: Abolitionism
	See also: Abolition of slavery timeline
	[show] v t e
	Slave Trade suppression
	 
	The painting of the 1840 Anti-Slavery Society Convention at Exeter Hall. Move your cursor to identify delegates or click the icon to enlarge.[248]
	Slavery has existed, in one form or another, through recorded human history—as have, in various periods, movements to free large or distinct groups of slaves.

	Ashoka, who ruled the Maurya Empire from 269–232 BCE, abolished the slave trade but not slavery.[249] The Qin dynasty, which ruled China from 221 to 206 BC, abolished slavery and discouraged serfdom. However, many of its laws were overturned when the dynasty was overthrown.[250] Slavery was again abolished, by Wang Mang, in China in 17 C.E but was reinstituted after his assassination.[251]

	The Spanish colonization of the Americas sparked a discussion about the right to enslave Native Americans. A prominent critic of slavery in the Spanish New World colonies was Bartolomé de las Casas, who opposed the enslavement of Native Americans, and later also of Africans in America.

	One of the first protests against slavery came from German and Dutch Quakers in Pennsylvania in 1688.[252] One of the most significant milestones in the campaign to abolish slavery throughout the world occurred in England in 1772, with British judge Lord Mansfield, whose opinion in Somersett's Case was widely taken to have held that slavery was illegal in England. This judgement also laid down the principle that slavery contracted in other jurisdictions could not be enforced in England.[253] In 1777, Vermont, at the time an independent nation, became the first portion of what would become the United States to abolish slavery.[252] France abolished slavery in 1794.[252]


	Joseph Jenkins Roberts, born in Virginia, was the first president of Liberia, which was founded in 1822 for freed American slaves.
	British Member of Parliament William Wilberforce led the anti-slavery movement in the United Kingdom, although the groundwork was an anti-slavery essay by Thomas Clarkson. Wilberforce was also urged by his close friend, Prime Minister William Pitt the Younger, to make the issue his own, and was also given support by reformed Evangelical John Newton. The Slave Trade Act was passed by the British Parliament on March 25, 1807, making the slave trade illegal throughout the British Empire,[254] Wilberforce also campaigned for abolition of slavery in the British Empire, which he lived to see in the Slavery Abolition Act 1833. After the 1807 act abolishing the slave trade was passed, these campaigners switched to encouraging other countries to follow suit, notably France and the British colonies. Between 1808 and 1860, the British West Africa Squadron seized approximately 1,600 slave ships and freed 150,000 Africans who were aboard.[255] Action was also taken against African leaders who refused to agree to British treaties to outlaw the trade, for example against "the usurping King of Lagos", deposed in 1851. Anti-slavery treaties were signed with over 50 African rulers.[256]

	In 1839, the world's oldest international human rights organization, Anti-Slavery International, was formed in Britain by Joseph Sturge, which campaigned to outlaw slavery in other countries.[257] There were celebrations in 2007 to commemorate the 200th anniversary of the abolition of the slave trade in the United Kingdom through the work of the British Anti-Slavery Society.

	In the United States, abolitionist pressure produced a series of small steps towards emancipation. After January 1, 1808, the importation of slaves into the United States was prohibited,[258] but not the internal slave trade, nor involvement in the international slave trade externally. Legal slavery persisted; and those slaves already in the U.S. were legally emancipated only in 1863. Many American abolitionists took an active role in opposing slavery by supporting the Underground Railroad. Violent clashes between anti-slavery and pro-slavery Americans included Bleeding Kansas, a series of political and armed disputes in 1854–1861 as to whether Kansas would join the United States as a slave or free state. By 1860, the total number of slaves reached almost four million, and the American Civil War, beginning in 1861, led to the end of slavery in the United States.[259] In 1863, Lincoln issued the Emancipation Proclamation, which freed slaves held in the Confederate States; the 13th Amendment to the U. S. Constitution prohibited most forms of slavery throughout the country.


	Photographed in 1863 – Gordon aka Peter, a man who was enslaved in Louisiana.[260] This famous photo was distributed by abolitionists as evidence of the cruelty of slavery.[261]
	In the case of freed slaves of the United States, many became sharecroppers and indentured servants. In this manner, some became tied to the very parcel of land into which they had been born a slave having little freedom or economic opportunity due to Jim Crow laws which perpetuated discrimination, limited education, promoted persecution without due process and resulted in continued poverty. Fear of reprisals such as unjust incarcerations and lynchings deterred upward mobility further.

	In the 1860s, David Livingstone's reports of atrocities within the Arab slave trade in Africa stirred up the interest of the British public, reviving the flagging abolitionist movement. The Royal Navy throughout the 1870s attempted to suppress "this abominable Eastern trade", at Zanzibar in particular. In 1905, the French abolished indigenous slavery in most of French West Africa.[262]

	On December 10, 1948, the United Nations General Assembly adopted the Universal Declaration of Human Rights, which declared freedom from slavery is an internationally recognized human right. Article 4 of the Universal Declaration of Human Rights states:

	No one shall be held in slavery or servitude; slavery and the slave trade shall be prohibited in all their forms.[263]

	In 2014, for the first time in history, major leaders of many religions, Buddhist, Anglican, Catholic, and Orthodox Christian, Hindu, Jewish, and Muslim, met to sign a shared commitment against modern-day slavery; the declaration they signed calls for the elimination of slavery and human trafficking by the year 2020.[264] The signatories were: Pope Francis, Mātā Amṛtānandamayī, Bhikkhuni Thich Nu Chân Không (representing Zen Master Thích Nhất Hạnh), Datuk K Sri Dhammaratana, Chief High Priest of Malaysia, Rabbi Abraham Skorka, Rabbi David Rosen, Abbas Abdalla Abbas Soliman, Undersecretary of State of Al Azhar Alsharif (representing Mohamed Ahmed El-Tayeb, Grand Imam of Al-Azhar), Grand Ayatollah Mohammad Taqi al-Modarresi, Sheikh Naziyah Razzaq Jaafar, Special advisor of Grand Ayatollah (representing Grand Ayatollah Sheikh Basheer Hussain al Najafi), Sheikh Omar Abboud, Justin Welby, Archbishop of Canterbury, and Metropolitan Emmanuel of France (representing Ecumenical Patriarch Bartholomew.)[264]

	Groups such as the American Anti-Slavery Group, Anti-Slavery International, Free the Slaves, the Anti-Slavery Society, and the Norwegian Anti-Slavery Society continue to campaign to eliminate slavery.

	Characteristics
	Economics

	Gustave Boulanger's painting The Slave Market
	Economists have attempted to model the circumstances under which slavery (and variants such as serfdom) appear and disappear. One observation is that slavery becomes more desirable for landowners where land is abundant but labour is scarce, such that rent is depressed and paid workers can demand high wages. If the opposite holds true, then it becomes more costly for landowners to have guards for the slaves than to employ paid workers who can only demand low wages due to the amount of competition.[265] Thus, first slavery and then serfdom gradually decreased in Europe as the population grew, but were reintroduced in the Americas and in Russia as large areas of new land with few people became available.[266] In his books, Time on the Cross and Without Consent or Contract: the Rise and Fall of American Slavery, Robert Fogel maintains that slavery was in fact a profitable method of production, especially on bigger plantations growing cotton that fetched high prices in the world market. It gave whites in the South higher average incomes than those in the North, but most of the money was spent on buying slaves and plantations.


	Slave being whipped in Brazil, during the heyday of gold exploration in Minas Gerais (1770).
	Slavery is more common when the labour done is relatively simple and thus easy to supervise, such as large-scale growing of a single crop. It is much more difficult and costly to check that slaves are doing their best and with good quality when they are doing complex tasks. Therefore, slavery was seen as the most efficient method of production for large-scale crops like sugar and cotton, whose output was based on economies of scale. This enabled a gang system of labour to be prominent on large plantations where field hands were monitored and worked with factory-like precision. Each work gang was based on an internal division of labour that not only assigned every member of the gang to a precise task but simultaneously made his or her performance dependent on the actions of the others. The hoe hands chopped out the weeds that surrounded the cotton plants as well as excessive sprouts. The plow gangs followed behind, stirring the soil near the rows of cotton plants and tossing it back around the plants. Thus, the gang system worked like an early version of the assembly line later to be found in factories.[267]

	Critics since the 18th century have argued that slavery tends to retard technological advancement, since the focus is on increasing the number of slaves doing simple tasks rather than upgrading the efficiency of labour. Because of this, theoretical knowledge and learning in Greece—and later in Rome—was not applied to ease physical labour or improve manufacturing.[268]

	Adam Smith made the argument that free labour was economically better than slave labour, and argued further that slavery in Europe ended during the Middle Ages, and then only after both the church and state were separate, independent and strong institutions,[269] that it is nearly impossible to end slavery in a free, democratic and republican forms of governments since many of its legislators or political figures were slave owners, and would not punish themselves, and that slaves would be better able to gain their freedom when there was centralized government, or a central authority like a king or the church.[270] Similar arguments appear later in the works of Auguste Comte, especially when it comes to Adam Smith's belief in the separation of powers or what Comte called the "separation of the spiritual and the temporal" during the Middle Ages and the end of slavery, and Smith's criticism of masters, past and present. As Smith stated in the Lectures on Jurisprudence, "The great power of the clergy thus concurring with that of the king set the slaves at liberty. But it was absolutely necessary both that the authority of the king and of the clergy should be great. Where ever any one of these was wanting, slavery still continues.."


	The inspection and sale of a slave
	Slaves can be an attractive investment because the slave-owner only needs to pay for sustenance and enforcement. This is sometimes lower than the wage-cost of free labourers, because free workers earn more than sustenance, in these cases slaves have positive price. When the cost of sustenance and enforcement exceeds the wage rate, slave-owning would no longer be profitable, and owners would simply release their slaves. Slaves are thus a more attractive investment in high-wage environments, and environments where enforcement is cheap, and less attractive in environments where the wage-rate is low and enforcement is expensive.[271]

	Free workers also earn compensating differentials, whereby they are paid more for doing unpleasant work. Neither sustenance nor enforcement costs rise with the unpleasantness of the work, however, so slaves' costs do not rise by the same amount. As such, slaves are more attractive for unpleasant work, and less for pleasant work. Because the unpleasantness of the work is not internalised, being born by the slave rather than the owner, it is a negative externality and leads to over-use of slaves in these situations.[271]

	The weighted average global sales price of a slave is calculated to be approximately $340, with a high of $1,895 for the average trafficked sex slave, and a low of $40 to $50 for debt bondage slaves in part of Asia and Africa.[37] Worldwide slavery is a criminal offense but slave owners can get very high returns for their risk. According to researcher Siddharth Kara, the profits generated worldwide by all forms of slavery in 2007 were $91.2 billion. That is second only to drug trafficking in terms of global criminal enterprises. The weighted average annual profits generated by a slave in 2007 was $3,175, with a low of an average $950 for bonded labour and $29,210 for a trafficked sex slave.[37] Approximately 40% of slave profits each year are generated by trafficked sex slaves, representing slightly more than 4% of the world's 29 million slaves.[37]

	Robert E. Wright has developed a model that helps to predict when firms (individuals, companies) will be more likely to use slaves rather than wage workers, indentured servants, family members, or other types of labourers.[272]

	Identification
	Throughout history, slaves were clothed in a distinctive fashion, particularly with respect to footwear or rather the lack thereof. This was both due to economic reasons as well as a distinguishing feature, especially in South Africa and South America. For example, the Cape Town slave code stated that "Slaves must go barefoot and must carry passes."[273] This was the case in the majority of states that abolished slavery later in history, as most images from the respective historical period suggest that slaves were barefoot.[274] To quote Brother Riemer (1779): "[the slaves] are, even in their most beautiful suit, obliged to go barefoot. Slaves were forbidden to wear shoes. This was a prime mark of distinction between the free and the bonded and no exceptions were permitted."[275]

	As shoes have been considered badges of freedom since biblical times "But the father said to his servants, Bring forth the best robe, and put [it] on him; and put a ring on his hand, and shoes on [his] feet (Luke 15:22)" this aspect has been an informal law wherever slavery existed. A barefoot person could therefore be clearly identified as a slave upon first sight. In certain societies this rule is valid to this day, as with the Tuareg slavery which is still unofficially practiced, and their slaves have to go barefoot.[276]

	Apologies
	On May 21, 2001, the National Assembly of France passed the Taubira law, recognizing slavery as a crime against humanity. Apologies on behalf of African nations, for their role in trading their countrymen into slavery, remain an open issue since slavery was practiced in Africa even before the first Europeans arrived and the Atlantic slave trade was performed with a high degree of involvement of several African societies. The black slave market was supplied by well-established slave trade networks controlled by local African societies and individuals.[277] Indeed, as already mentioned in this article, slavery persists in several areas of West Africa until the present day.

	There is adequate evidence citing case after case of African control of segments of the trade. Several African nations such as the Calabar and other southern parts of Nigeria had economies depended solely on the trade. African peoples such as the Imbangala of Angola and the Nyamwezi of Tanzania would serve as middlemen or roving bands warring with other African nations to capture Africans for Europeans.[278]

	Several historians have made important contributions to the global understanding of the African side of the Atlantic slave trade. By arguing that African merchants determined the assemblage of trade goods accepted in exchange for slaves, many historians argue for African agency and ultimately a shared responsibility for the slave trade.[279]

	In 1999, President Mathieu Kerekou of Benin (formerly the Kingdom of Dahomey) issued a national apology for the central role Africans played in the Atlantic slave trade.[280] Luc Gnacadja, minister of environment and housing for Benin, later said: "The slave trade is a shame, and we do repent for it."[281] Researchers estimate that 3 million slaves were exported out of the Slave Coast bordering the Bight of Benin.[281] President Jerry Rawlings of Ghana also apologized for his country's involvement in the slave trade.[280]

	The issue of an apology is linked to reparations for slavery and is still being pursued by a number of entities across the world. For example, the Jamaican Reparations Movement approved its declaration and action Plan.

	In September 2006, it was reported that the UK government might issue a "statement of regret" over slavery.[282] This was followed by a "public statement of sorrow" from Tony Blair on November 27, 2006,[283] and a formal apology on March 14, 2007.[284]

	On February 25, 2007, the Commonwealth of Virginia resolved to 'profoundly regret' and apologize for its role in the institution of slavery. Unique and the first of its kind in the U. S., the apology was unanimously passed in both Houses as Virginia approached the 400th anniversary of the founding of Jamestown, where the first slaves were imported into North America in 1619.[285]

	Liverpool, which was a large slave trading port, apologized in 1999. On August 24, 2007, Mayor Ken Livingstone of London, United Kingdom, apologized publicly for Britain's role in colonial slave trade. "You can look across there to see the institutions that still have the benefit of the wealth they created from slavery," he said, pointing towards the financial district. He claimed that London was still tainted by the horrors of slavery. Specifically, London outfitted, financed, and insured many of the ships, which helped fund the building of London's docks. Jesse Jackson praised Livingstone, and added that reparations should be made, one of his common arguments.[286]

	On July 30, 2008, the United States House of Representatives passed a resolution apologizing for American slavery and subsequent discriminatory laws.[287] In June 2009, the US Senate passed a resolution apologizing to African-Americans for the "fundamental injustice, cruelty, brutality, and inhumanity of slavery".[288] The news was welcomed by President Barack Obama, the nation's first President of African descent.[289] Some of President Obama's ancestors were slave owners.[290]

	In 2010, Libyan leader Muammar Gaddafi apologized for Arab involvement in the slave trade, saying: "I regret the behavior of the Arabs… They brought African children to North Africa, they made them slaves, they sold them like animals, and they took them as slaves and traded them in a shameful way."[291]

	Reparations
	Main article: Reparations for slavery
	refer to caption
	Monument to slaves in Zanzibar
	There have been movements to achieve reparations for those formerly held as slaves, or sometimes their descendants. Claims for reparations for being held in slavery are handled as a civil law matter in almost every country. This is often decried as a serious problem, since former slaves' relative lack of money means they often have limited access to a potentially expensive and futile legal process. Mandatory systems of fines and reparations paid to an as yet undetermined group of claimants from fines, paid by unspecified parties, and collected by authorities have been proposed by advocates to alleviate this "civil court problem.."Since in almost all cases there are no living ex-slaves or living ex-slave owners these movements have gained little traction. In nearly all cases the judicial system has ruled that the statute of limitations on these possible claims has long since expired.

	Other uses of the term
	The word slavery is often used as a pejorative to describe any activity in which one is coerced into performing.

	Proponents of animal rights apply the term slavery to the condition of some or all human-owned animals, arguing that their status is comparable to that of human slaves.[292]

	Some argue that military drafts and other forms of coerced government labour constitute state-operated slavery.[293][294] Some libertarians and anarcho-capitalists view government taxation as a form of slavery.[295]

	Some Antipsychiatry proponents apply the term slavery to the involuntary psychiatric patient. There are no unbiased physical tests for mental illness, and the psychiatric patient must follow the orders of his/her psychiatrist. Drapetomania was a psychiatric diagnosis for a slave who did not want to be a slave. Thomas Szasz wrote a book titled "Psychiatric Slavery",[296] published in 1998 and a book titled " Liberation by Oppression: A Comparative Study of Slavery and Psychiatry",[297] published in 2003.

	Wage slavery
	Main articles: Labour economics § Wage slavery, and Wage labour
	Some socialists, view total and immediate wage dependence as a form of slavery.[298] The labour market, as institutionalised under today's market economic systems, has been criticised,[299] especially by both mainstream socialists and anarcho-syndicalists,[300][301][302] who utilise the term wage slavery[303][304] as a pejorative for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.[305]

	For Marxists, labour-as-commodity, which is how they regard wage labour,[306] provides an absolutely fundamental point of attack against capitalism.[307] "It can be persuasively argued," noted one concerned philosopher[who?], "that the conception of the worker's labour as a commodity confirms Marx's stigmatization of the wage system of private capitalism as 'wage-slavery;' that is, as an instrument of the capitalist's for reducing the worker's condition to that of a slave, if not below it."[308][citation needed]

	In film
	Main article: List of films featuring slavery
	Film has been the most influential medium in the presentation of the history of slavery to the general public around the world.[309] The American film industry has had a complex relationship with slavery and until recent decades often avoided the topic. Films such as Birth of a Nation (1915)[310] and Gone with the Wind (1939) became controversial because they gave a favourable depiction. The last favourable treatment was Song of the South from Disney in 1946. In 1940 The Santa Fe Trail gave a liberal but ambiguous interpretation of John Brown's attacks on slavery—the film does not know what to do with slavery.[311] The Civil Rights Movement in the 1950s made defiant slaves into heroes.[312] The question of slavery in American memory necessarily involves its depictions in feature films.[313]


	Poster for the film Spartacus
	Most Hollywood films used American settings, although Spartacus (1960), dealt with an actual revolt in the Roman Empire known as the Third Servile War. It failed and all the rebels were executed, but their spirit lived on according to the film.[314] The Last Supper (La última cena in Spanish) was a 1976 film directed by Cuban Tomás Gutiérrez Alea about the teaching of Christianity to slaves in Cuba, and emphasizes the role of ritual and revolt. Burn! takes place on the imaginary Portuguese island of Queimada (where the locals speak Spanish) and it merges historical events that took place in Brazil, Cuba, Santo Domingo, Jamaica, and elsewhere. Spartacus stays surprisingly close to the historical record.[315]

	Historians agree that films have largely shaped historical memories, but they debate issues of accuracy, plausibility, moralism, sensationalism, how facts are stretched in search of broader truths, and suitability for the classroom.[316][317] Berlin argues that critics complain if the treatment emphasizes historical brutality, or if it glosses over the harshness to highlight the emotional impact of slavery.`
},{
	title: "Theocracy",
	eYear: 1765,
	wYear: 2017,
	eSource: "",
	wSource: "",
	eConn: [],
	wConn: [],
	eArt: `Bleh`,
	wArt:`Blah`
},{
	title: "Theology",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 16 (1765), pp. 249–251",
	wSource: "",
	eConn: ["theological","conclusions","revelation","motive","theological","motive","theology","god","first","principles","revelation","theological","god","revelation","conclusions","revelation","god","reason","conclusions","principles","theology","reason","theological","revelation"],
	wConn: ["religious","tradition","theology","religious","theological","seminary","learning","century","theology","academic","century","university","academic","discipline","religious","resources","instance","university","university","theology","truly","religious","theology","study"],
	eArt: `THEOLOGY, Theologia, from the Greek θεὸς, God , and λόγος , discourse , taken in general, is the science of God and divine things, as one may know them by natural lights. It is in this sense that Aristotle ( Metaphysics , 1, vi) calls theology that part of philosophy that is concerned with God and some of his attributes. It is in this same sense that the Pagans gave their poets the name of theologians, because they regarded them as more enlightened than the common man on the nature of divinity & on the mysteries of religion.
	<p> The ancients had three sorts of theology : 1. Mythology or the fabulous that flourished among Poets, and that principally ruled over theogony, or the generation of the gods. See Fable, Mythology , and Theogony. 2. Political Theology embraced principally by princes, magistrates, priests, and the body of the people, as the most useful and most necessary science for the security, tranquility and prosperity of the state. 3. Physical or natural Theology , cultivated by the Philosophes , is the science most suited to nature and to reason, accepting only a sole supreme God, and demons or genies as mediators between God and men. See Demon, Genie.</p>
	<p> The Hebrews, who had favored revelation, also have their Theologians, for that name can be given to the Prophets raised by God to instruct them, to pontiffs charged by the state with explaining the law, & scribes or doctors who professed to interpret it. Since their dispersal, modern Jews have not lacked theological writers or books; the writings of their rabbis are spread throughout the world. See Rabbis and Talmud.</p>
	<p> Among Christians the word Theology is taken in various ways. The ancient fathers, and particularly Greeks like S. Basil and St. Gregory of Nazianzus, gave this name especially to that part of the Christian doctrine that deals with divinity; hence they call St. John the Evangelist the theologian par excellence, because he dealt with the divinity of the Word in a manner more profound and extended than the other apostles. They also call St. Gregory of Nazianzus “the theologian ” because he defended with zeal the divinity of the Word against the Arians, and in this sense the Greeks distinguished theology from what they called economy, that is to say, the part of the Christian doctrine that deals with the mystery of the Incarnation.</p>
	<p> But in a broader sense, Theology is defined as a science that teaches us what we ought to believe about God and the way He wants us to serve Him; it is divided into two kinds: Natural Theology and Supernatural Theology.</p>
	<p> Natural theology is the knowledge we have of God and his attributes, by the sole light of reason and nature, and in consideration of the works that could only come from his hands. Supernatural theology (or theology properly speaking) is a science founded on revealed principles that draws conclusions about both God, his nature, attributes, etc, and about all the other things that can relate to God; hence it follows that theology joins in its way of proceeding the use of reason with the certitude of revelation that it is founded in part on the light of revelation and in part on that of reason.</p>
	<p> All the truths that Theology proposes the search for and study of, are either speculative or practical, in this respect dividing the subject into speculative theology and practical or moral theology. Speculative theology has the sole aim of clarifying, fixing and defending the dogmas of religion insofar as they should be believed. Practical or moral theology is concerned with fixing religious duties, by treating virtues and vices, prescribing rules, and deciding what is just or unjust, licit or illicit, in the order of religion.</p>
	<p> As for the manner of treating Theology, people distinguish between positive and scholastic. Positive Theology has the goal of expounding and proving the truths of religion by scriptural tesxs, in line with the tradition of the Church Fathers and the decisions of councils, without being attached to the scholastic methods but treating them in a rhetorical style, as did the Church Fathers.</p>
	<p> Scholastic Theology employs dialectics, arguments, and the forms commonly used in the schools to deal with religious matters.</p>
	<p> Some authors think that the difference found between positive and scholastic Theology does not come from a difference of style and elocution, in a word, from a scholastic form proper to the latter that is not found in the former. They say that scholastic Theologians have enclosed in a single body and placed in a certain order all questions regarding doctrine, instead of which the ancients did not deal with religious dogma, except separately and on occasion. But this does not pertain to style, for the moderns could have treated the whole religious plane in rhetorical style, and the ancients could have dealt only with some questions in scholastic style. The true difference between positive and scholastic therefore depends on the stylistic form, since the subject matter is the same.</p>
	<p> Luther called s cholastic Theology a “two-faced discipline , composed of a mixture of Holy Scripture and philosophical reasons. Mixtione quadam ex divinis eloquiis & philosphicis rationibus tanquam ex centayrorum genere biformis disciplina conflata est. ” But as we will see later, he had only a false idea of it and he was judging it by its abuses.</p>
	<p> Abbot Fleury in his fifth discourse on ecclesiastical history does not appear any more favorable to scholasticism, for after its being objected that if it is not true that the scholastics had found a more commodious and more exact method for teaching Theology, although their style is no more solid or more precise than the ancients’, to which he responded:</p>
	<p> “I have often heard it said (but I cannot agree and I will never be persuaded of it) that until the twelfth century method was lacking in Christian schools. It is true that the ancients did not make an entire course of Theology, as did Hugo of St. Victor, Robert Pullus, Hildebert de Tours, and so many others. But they did not neglect to give us in their works the entire plan of religion, like St. Augustine, who in his Enchiridion shows all that one should believe (& the way of teaching it) in his book on Christian doctrine. One even finds an abbreviated morality in several other treatises, such as St. Clement of Alexandria’s pedagogy.</p>
	<p> So what is lacking among the ancients? Is it each giving his entire course of Theology , always starting with the division and definition of the same subjects? I admit that the moderns have done this, but I do not agree that religion has been better taught for it. The most palpable effect of this method is to have filled with world with an infinity of volumes (partly printed, partly still in manuscript) that remain dormant in the great libraries because they do not attract readers either by their utility or agreement – for who today reads Alexander of Hales or Albert the Great?”</p>
	<p> And he had previously remarked that he saw nothing great in the latter —other than the thickness and number of the volumes.</p>
	<p> He then observes that the scholastics claimed to follow the method of geometricians, but this was not so, for they often took Scripture in figurative and altered senses, posed as principles the axioms of a bad philosophy, or one based on the authority of some profane author. Then he adds:</p>
	<p> “While the scholastics imitated the method of geometricians, they copied their dry and uniform style even better. They indulged in another fault by making a particular language distinct from all vulgar tongues and from true Latin, although nominally its origin. This was not at all necessary, since each person can philosophize by speaking his own tongue well. Aristotle’s writings are in good Greek, the philosophical works of Cicero in good Latin, and in the last century Descartes explained his doctrine in good French...</p>
	<p> Another error is to believe that a dry, constrained, and uniform style is more clear and more concise than ordinary and natural discourse, where one gives oneself the freedom to vary sentences and to use some images. But this restrained and pre-molded style, so to speak, is prolix as well as being very annoying. On each page they repeat the same formulas: for example, on the subject six questions are posed; on the first, one proceeds thus, then three objections, then I answer what should be said, etc., and then come the answers to the objections. You will say that the author is obliged by inevitable necessity to express himself always the same. On each line they repeat the terms of the art: proposition, assertion, major, minor, proof, conclusions, etc – and these repetitions lengthen the discourse very much...</p>
	<p> In form, the arguments again lengthen the discourse noticeably, and make the person who sees the conclusion right away impatient. He is comforted by an enthymeme or by a simple proposition that underlies all the rest. It would be better to reserve entire syllogisms for rare occasions when one must develop a specious sophism or make an abstract truth perceptible.</p>
	<p> However, those who are accustomed to the scholastic style do not recognize reasonings unless they are presented in a syllogistic form. The Church Fathers appear to them rhetoricians, or even windbags, because they explain things naturally, as is done in conversation, because they sometimes use questions, exclamations, and other ordinary figures of speech. The scholastics do not see that figures and ingenious turns of phrase save many words, or that often by a well placed work one prevents or overcomes an objection that would occupy them for a long time.”</p>
	<p> These accusations are serious and one can scarcely say worse of scholasticism; but they pertain only to ancient scholasticism, disfigured by frivolous questions and a barbarous style. For it must be agreed that since the renewal of studies in the sixteenth centaury, scholasticism has changed form in these two respects. In effect, to consider it from its veritable standpoint, it is merely the knowledge of divine Scripture interpreted following the meaning the Church approves, by joining together the explanations and censures of the fathers, without neglecting the help that can be drawn from the secular sciences to clarify and sustain the truth. Scholastica theologia est divinarum scriptuarum peritia, recepto quem ecclesia approbat sensu, non spretis orthodoxorum doctorum interpretationibus & censuris, interdum aliarum disiplinarum non contempto suffragio. It is thus that the theology faculty of Paris has known it, who cultivate it on these principles, and whose goal in exercising its students is to accustom them to right reasoning by the use of dialectics.</p>
	<p> In effect, subtract from scholasticism a great number of futile questions that overtaxed the ancients, remove the abuses of their method, & reduce it to dealing in order with the interesting truths of dogma and morality, and you will find that it as ancient as the church. So many polemic and dogmatic works by the fathers of all centuries, in which they establish the various dogmas of religion attacked by the heretics are an incontestable proof of this. For if they were not content to simply expound the faith of the Church by bringing passages from Scripture and the Fathers on which it is founded, but they also employed dialectics and reasoning to establish the veritable meaning of passages they cited in order to explain those that are put forward by their adversaries, to refute the difficulties they raise, to clarify and develop the consequences of the principles they find established in Holy Scripture and in tradition, to convict of error the false consequences drawn by the heretics; and finally they would neglect noting of that may serve to make the truth known, clarified, and sustained, to persuade those who are not convinced of it, and to remove from error those who are engaged in it; to succeed, they employ the principles of natural reason, the science of languages, the subtleties of dialectic, the traits of eloquence, and the authority of philosophers and of historians. One finds in their writing propositions, proofs, objections, responses, arguments, consequences, etc.; thus the whole difference comes from the method of the moderns being less hidden, and they are not (or do not affect to be) so eloquent. But at bottom, are they less solid when they stick to essential points and treat them according to the great principles as modern scholastics do, especially in the theology faculty of Paris? The defects of a nascent method do not always prove that it is bad, and often elevate those who have perfected it.</p>
	<p> Theologians have the habit of treating several questions relating to the dignity, utility, and necessity of the science they are professing, and on all these topics we will refer the reader to their writings. We content ourselves with touching what concerns the certitude of Theology, or theological conclusions. By theological conclusions we mean those that are evidently and certainly deduced from one or two premises, either when both are revealed, or when one is revealed and the other simply known by natural lights; one wonders 1) if these conclusions are of an equal certitude as propositions that go without saying; 2) if they are more or less certain that the conclusions of other sciences; 3) if they equal in certitude the first principles or axioms of geometry, philosophy etc.</p>
	<p> Deciding all these questions depends on knowing the foundation of the certitude of theological conclusions, that is to say, what motive determines to mind to acquiesce. It is generally agreed that the immediate revelation of God proposed by the Church is the motive that leads to acquiescing in the truths of faith; virtual or mediate revelation, that is to say, the connection that is found between a theological conclusion and revelation, a connection manifested by natural lights, is the motive that brings acquiescence to theological conclusions.</p>
	<p> Form there it is easy to infer: 1) That purely theological conclusions do not have the same degree of certitude as the verities of faith, the latter being founded on a) the immediate revelation of God; and b) the decision of the Church that attest the truth of this revelation, instead of which theological conclusions have only the motive of their connection with revelation, but the connection is perceived only by the lights of reason; the motive of acquiescence and the means of knowing these motive lie , as we see, in the theological conclusions of an inferior order to the motive that determines the mind to subject itself to the verities of faith and to the means that uncover this motive. 2) That theological conclusions are more certain than the conclusions of the natural sciences taken in general, because one knows that the latter often rest only on conjectures and that their connection with first principles is not so evident as that of theological conclusions with immediate revelation.</p>
	<p> But opinion is divided on the third question, whether theological conclusions are more or less certain than first principles of geometry and philosophy, and on this point there are two opinions.</p>
	<p> The first is that of ancient theologians who maintain that theological conclusions are more certain than first principles because, they say, they rely on God’s revelation and so cannot and will not deceive men, instead of which the certainty of first principles is founded only on reason or natural light, which is subject to error.</p>
	<p> On the contrary, most moderns think that first principles are as certain as theological conclusions because: 1) Such is the certitude of these axioms - “the whole is grater than the sum of its parts,” “two things equal to a third are equal to each other,” etc. – that it is impossible to assign them any greater certainty, and one feels by experience that there are no truths with which the mind agrees more readily. 2) Because God is no less the author of reason than revelation, from which it follows that if one cannot suspect revelation of falsity, from fear of making the reproach fall on God Himself, one cannot suspect reason of error concerning first principles, since God gave us these two equal means, one of knowing natural truths, the other for adhering to the verities of faith. 3) Because faith itself is in some way supported by reason: for, (they say) why do we believe in revelation? Because we know that God is in essence the truth that cannot either deceive or be deceived. And who is it that shows us this truth? Reason, no doubt – it is also that which by various motives of credibility persuades us that Jesus Christ is the messiah, and that his religion is the only veritable one. If then reason leads us by the hand to faith and if it is in some way the foundation of it, why would one want theological conclusions (that one admits to be less certain than the verities of faith) to be more so than the axioms and first principles of Reason (Holden, de Resolut. Fidei , I, I, ch 3 & Element. Theolog . Ch. 1, pg 12).</p>`,
	wArt:`Theology is the critical study of the nature of the divine. It is taught as an academic discipline, typically in universities, seminaries and schools of divinity.[1]
	<p> Definition[edit]</p>
	<p> Augustine of Hippo defined the Latin equivalent, theologia, as "reasoning or discussion concerning the Deity";[2] Richard Hooker defined "theology" in English as "the science of things divine".[3] The term can, however, be used for a variety of different disciplines or fields of study.[4] Theologians use various forms of analysis and argument (philosophical, ethnographic, historical, spiritual and others) to help understand, explain, test, critique, defend or promote any of myriad religious topics. Specifically, the study of theology may help a theologian more deeply understand their own religious tradition, [5] another religious tradition, [6] or it may enable them to explore the nature of divinity without reference to any specific tradition. Theology may be used to propagate, [7] reform, [8] or justify a religious tradition or it may be used to compare, [9] challenge (e.g. biblical criticism), or oppose (e.g. irreligion) a religious tradition or world-view. Theology might also help a theologian to address some present situation or need through a religious tradition, [10] or to explore possible ways of interpreting the world. [11]</p>
	<p> Etymology[edit]</p>
	<p> Main article: History of theology</p>
	<p> Theology translates into English from the Greek theologia (θεολογία) which derived from Τheos (Θεός), meaning "God," and -logia (-λογία),[12] meaning "utterances, sayings, or oracles" (a word related to logos [λόγος], meaning "word, discourse, account, or reasoning") which had passed into Latin as theologia and into French as théologie. The English equivalent "theology" (Theologie, Teologye) had evolved by 1362.[13] The sense the word has in English depends in large part on the sense the Latin and Greek equivalents had acquired in Patristic and medieval Christian usage, though the English term has now spread beyond Christian contexts.</p>
	<p> Greek theologia (θεολογία) was used with the meaning "discourse on god" in the fourth century BC by Plato in The Republic, Book ii, Ch. 18.[14] Aristotle divided theoretical philosophy into mathematike, physike and theologike, with the latter corresponding roughly to metaphysics, which, for Aristotle, included discourse on the nature of the divine.[15]</p>
	<p> Drawing on Greek Stoic sources, the Latin writer Varro distinguished three forms of such discourse: mythical (concerning the myths of the Greek gods), rational (philosophical analysis of the gods and of cosmology) and civil (concerning the rites and duties of public religious observance).[16]</p>
	<p> Theologos, closely related to theologia, appears once in some biblical manuscripts, in the heading to the book of Revelation: apokalypsis ioannoy toy theologoy, "the revelation of John the theologos." There, however, the word refers not to John the "theologian" in the modern English sense of the word but—using a slightly different sense of the root logos, meaning not "rational discourse" but "word" or "message"—one who speaks the words of God, logoi toy theoy.[17]</p>
	<p> Some Latin Christian authors, such as Tertullian and Augustine, followed Varro's threefold usage,[18] though Augustine also used the term more simply to mean 'reasoning or discussion concerning the deity'[2]</p>
	<p> In Patristic Greek Christian sources, theologia could refer narrowly to devout and inspired knowledge of, and teaching about, the essential nature of God.[19]</p>
	<p> The Latin author Boethius, writing in the early 6th century, used theologia to denote a subdivision of philosophy as a subject of academic study, dealing with the motionless, incorporeal reality (as opposed to physica, which deals with corporeal, moving realities).[20] Boethius' definition influenced medieval Latin usage.[21]</p>
	<p> In scholastic Latin sources, the term came to denote the rational study of the doctrines of the Christian religion, or (more precisely) the academic discipline which investigated the coherence and implications of the language and claims of the Bible and of the theological tradition (the latter often as represented in Peter Lombard's Sentences, a book of extracts from the Church Fathers).[22]</p>
	<p> In the Renaissance, especially with Florentine Platonist apologists of Dante's poetics, the distinction between "poetic theology" (theologia poetica) and "revealed" or Biblical theology serves as steppingstone for a revival of philosophy as independent of theological authority.</p>
	<p> It is in this last sense, theology as an academic discipline involving rational study of Christian teaching, that the term passed into English in the fourteenth century,[23] though it could also be used in the narrower sense found in Boethius and the Greek patristic authors, to mean rational study of the essential nature of God – a discourse now sometimes called Theology Proper.[24]</p>
	<p> From the 17th century onwards, it also became possible to use the term 'theology' to refer to study of religious ideas and teachings that are not specifically Christian (e.g., in the term 'natural theology' which denoted theology based on reasoning from natural facts independent of specifically Christian revelation[25]), or that are specific to another religion (see below).</p>
	<p> "Theology" can also now be used in a derived sense to mean "a system of theoretical principles; an (impractical or rigid) ideology."[26]</p>
	<p> Various religions[edit]</p>
	<p> Thomas Aquinas was the greatest Western theologian of the Middle Ages.</p>
	<p> The term Theology has been deemed by some as only appropriate to the study of religions that worship a supposed deity (a theos), i.e. more widely than the Judeo-Christian tradition; and presuppose a belief in the ability to speak and reason about this deity (in logia). They suggest the term is less appropriate in religious contexts that are organized differently (religions without a single deity, or that deny that such subjects can be studied logically). ("Hierology" has been proposed as an alternative, more generic term.[27])</p>
	<p> Analogous discourses[edit]</p>
	<p> Allamah Sayyid Abul A'la Maududi was the most influential Islamic theologian of the 20th century.[28]</p>
	<p> Islamic theological discussion that parallels Christian theological discussion is named "Kalam"; the Islamic analogue of Christian theological discussion would more properly be the investigation and elaboration of Sharia or Fiqh. "Kalam ... does not hold the leading place in Muslim thought that theology does in Christianity. To find an equivalent for 'theology' in the Christian sense it is necessary to have recourse to several disciplines, and to the usul al-fiqh as much as to kalam." (L. Gardet)[29]</p>
	<p> Some academic inquiries within Buddhism, dedicated to the rational investigation of a Buddhist understanding of the world, prefer the designation Buddhist philosophy to the term Buddhist theology, since Buddhism lacks the same conception of a theos. Jose Ignacio Cabezon, who argues that the use of "theology" is appropriate, can only do so, he says, because "I take theology not to be restricted to discourse on God ... I take 'theology' not to be restricted to its etymological meaning. In that latter sense, Buddhism is of course atheological, rejecting as it does the notion of God."[30]</p>
	<p> Within Hindu philosophy, there is a solid and ancient tradition of philosophical speculation on the nature of the universe, of God (termed "Brahman", Paramatma and Bhagavan in some schools of Hindu thought) and of the Atman (soul). The Sanskrit word for the various schools of Hindu philosophy is Darshana (meaning "view" or "viewpoint"). Vaishnava theology has been a subject of study for many devotees, philosophers and scholars in India for centuries, and in recent decades also has been taken on by a number of academic institutions in Europe, such as the Oxford Centre for Hindu Studies and Bhaktivedanta College.[31] See also: Krishnology</p>
	<p> In Judaism, the historical absence of political authority has meant that most theological reflection has happened within the context of the Jewish community and synagogue, rather than within specialized academic institutions. Nevertheless, Jewish theology historically has been very active and highly significant for Christian and Islamic theology. It is sometimes claimed, however, that the Jewish analogue of Christian theological discussion would more properly be Rabbinical discussion of Jewish law and Jewish Biblical commentaries.[32]</p>
	<p> Theology as an academic discipline[edit]</p>
	<p> The history of the study of theology in institutions of higher education is as old as the history of such institutions themselves. For instance, Taxila was an early centre of Vedic learning, possible from the 6th century BC or earlier;[33] the Platonic Academy founded in Athens in the 4th century BC seems to have included theological themes in its subject matter;[34] the Chinese Taixue delivered Confucian teaching from the 2nd century BC;[35] the School of Nisibis was a centre of Christian learning from the 4th century AD;[36] Nalanda in India was a site of Buddhist higher learning from at least the 5th or 6th century AD;[37] and the Moroccan University of Al-Karaouine was a centre of Islamic learning from the 10th century,[38] as was Al-Azhar University in Cairo.[39]</p>
	<p> The earliest universities were developed under the aegis of the Latin Church by papal bull as studia generalia and perhaps from cathedral schools. It is possible, however, that the development of cathedral schools into universities was quite rare, with the University of Paris being an exception.[40] Later they were also founded by Kings (University of Naples Federico II, Charles University in Prague, Jagiellonian University in Kraków) or municipal administrations (University of Cologne, University of Erfurt). In the early medieval period, most new universities were founded from pre-existing schools, usually when these schools were deemed to have become primarily sites of higher education. Many historians state that universities and cathedral schools were a continuation of the interest in learning promoted by monasteries.[41] Christian theological learning was therefore a component in these institutions, as was the study of Church or Canon law: universities played an important role in training people for ecclesiastical offices, in helping the church pursue the clarification and defence of its teaching, and in supporting the legal rights of the church over against secular rulers.[42] At such universities, theological study was initially closely tied to the life of faith and of the church: it fed, and was fed by, practices of preaching, prayer and celebration of the Mass.[43]</p>
	<p> During the High Middle Ages, theology was therefore the ultimate subject at universities, being named "The Queen of the Sciences" and serving as the capstone to the Trivium and Quadrivium that young men were expected to study. This meant that the other subjects (including Philosophy) existed primarily to help with theological thought.[44]</p>
	<p> Christian theology’s preeminent place in the university began to be challenged during the European Enlightenment, especially in Germany.[45] Other subjects gained in independence and prestige, and questions were raised about the place in institutions that were increasingly understood to be devoted to independent reason of a discipline that seemed to involve commitment to the authority of particular religious traditions.[46]</p>
	<p> Since the early nineteenth century, various different approaches have emerged in the West to theology as an academic discipline. Much of the debate concerning theology's place in the university or within a general higher education curriculum centres on whether theology's methods are appropriately theoretical and (broadly speaking) scientific or, on the other hand, whether theology requires a pre-commitment of faith by its practitioners, and whether such a commitment conflicts with academic freedom.[47]</p>
	<p> Theology and ministerial training[edit]</p>
	<p> In some contexts, theology has been held to belong in institutions of higher education primarily as a form of professional training for Christian ministry. This was the basis on which Friedrich Schleiermacher, a liberal theologian, argued for the inclusion of theology in the new University of Berlin in 1810.[48]</p>
	<p> For instance, in Germany, theological faculties at state universities are typically tied to particular denominations, Protestant or Roman Catholic, and those faculties will offer denominationally-bound (konfessionsgebunden) degrees, and have denominationally bound public posts amongst their faculty; as well as contributing ‘to the development and growth of Christian knowledge’ they ‘provide the academic training for the future clergy and teachers of religious instruction at German schools.’[49]</p>
	<p> In the United States, several prominent colleges and universities were started in order to train Christian ministers. Harvard,[50] Georgetown,[51] Boston University,[52] Yale,[53] and Princeton[54] all had the theological training of clergy as a primary purpose at their foundation.</p>
	<p> Seminaries and bible colleges have continued this alliance between the academic study of theology and training for Christian ministry. There are, for instance, numerous prominent US examples, including Catholic Theological Union in Chicago,[55] The Graduate Theological Union in Berkeley,[56] Criswell College in Dallas,[57] The Southern Baptist Theological Seminary in Louisville,[58] Trinity Evangelical Divinity School in Deerfield, Illinois,[59] Dallas Theological Seminary,[60] North Texas Collegiate Institute in Farmers Branch, Texas [61] and The Assemblies of God Theological Seminary in Springfield, Missouri.</p>
	<p> Theology as an academic discipline in its own right[edit]</p>
	<p> In some contexts, scholars pursue theology as an academic discipline without formal affiliation to any particular church (though members of staff may well have affiliations to churches), and without focussing on ministerial training. This applies, for instance, to many university departments in the United Kingdom, including the Faculties of Divinity at the University of Cambridge and University of Oxford, the Department of Theology and Religion at the University of Exeter, and the Department of Theology and Religious Studies at the University of Leeds.[62] Traditional academic prizes, such as the University of Aberdeen's Lumsden and Sachs Fellowship, tend to acknowledge performance in theology (or divinity as it is known at Aberdeen) and in religious studies.</p>
	<p> Theology and religious studies[edit]</p>
	<p> In some contemporary contexts, a distinction is made between theology, which is seen as involving some level of commitment to the claims of the religious tradition being studied, and religious studies, which by contrast is normally seen as requiring that the question of the truth or falsehood of the religious traditions studied be kept outside its field. Religious studies involves the study of historical or contemporary practices or of those traditions' ideas using intellectual tools and frameworks that are not themselves specifically tied to any religious tradition and that are normally understood to be neutral or secular.[63] In contexts where 'religious studies' in this sense is the focus, the primary forms of study are likely to include:</p>
	<p> Anthropology of religion</p>
	<p> Comparative religion</p>
	<p> History of religions</p>
	<p> Philosophy of religion</p>
	<p> Psychology of religion</p>
	<p> Sociology of religion</p>
	<p> Sometimes, theology and religious studies are seen as being in tension,[64] and at other times, they are held to coexist without serious tension.[65] Occasionally it is denied that there is as clear a boundary between them.[66]</p>
	<p> Criticism[edit]</p>
	<p> See also: Criticism of religion</p>
	<p> There is an ancient tradition of skepticism about theology, followed by a more modern rise in secularist and atheist criticism.</p>
	<p> Criticism by philosophers[edit]</p>
	<p> Whether or not reasoned discussion about the divine is possible has long been a point of contention.</p>
	<p> Protagoras, as early as the fifth century BC, who is reputed to have been exiled from Athens because of his agnosticism about the existence of the gods, said that "Concerning the gods I cannot know either that they exist or that they do not exist, or what form they might have, for there is much to prevent one's knowing: the obscurity of the subject and the shortness of man's life."[67]</p>
	<p> Lord Bolingbroke, an English politician and political philosopher wrote in his political works his views on theology, "Theology is in fault not religion. Theology is a science that may justly be compared to the Box of Pandora. Many good things lie uppermost in it; but many evil lie under them, and scatter plagues and desolation throughout the world."[68]</p>
	<p> Thomas Paine the American revolutionary, wrote in his two part work The Age of Reason, "The study of theology, as it stands in Christian churches, is the study of nothing; it is founded on nothing; it rests on no principles; it proceeds by no authorities; it has no data; it can demonstrate nothing; and it admits of no conclusion. Not anything can be studied as a science, without our being in possession of the principles upon which it is founded; and as this is the case with Christian theology, it is therefore the study of nothing."[69]</p>
	<p> Ludwig Feuerbach, the atheist philosopher sought to dissolve theology in his work Principles of the Philosophy of the Future: "The task of the modern era was the realization and humanization of God – the transformation and dissolution of theology into anthropology."[70] This mirrored his earlier work The Essence of Christianity (pub. 1841), for which he was banned from teaching in Germany, in which he had said that theology was a "web of contradictions and delusions".[71]</p>
	<p> A.J. Ayer the former logical-positivist, sought to show in his essay "Critique of Ethics and Theology" that all statements about the divine are nonsensical and any divine-attribute is unprovable. He wrote: "It is now generally admitted, at any rate by philosophers, that the existence of a being having the attributes which define the god of any non-animistic religion cannot be demonstratively proved... [A]ll utterances about the nature of God are nonsensical."[72]</p>
	<p> Walter Kaufmann the philosopher, in his essay "Against Theology", sought to differentiate theology from religion in general. "Theology, of course, is not religion; and a great deal of religion is emphatically anti-theological... An attack on theology, therefore, should not be taken as necessarily involving an attack on religion. Religion can be, and often has been, untheological or even anti-theological." However, Kaufmann found that "Christianity is inescapably a theological religion".[73]</p>
	<p> Critics of theology as an academic discipline[edit]</p>
	<p> Critics dating back to the 18th century have questioned the suitability of theology as an academic discipline and in the 21st century criticism continues.[74]</p>
	<p> General criticism[edit]</p>
	<p> Charles Bradlaugh believed theology prevented human beings achieving liberty.[75] Bradlaugh noted theologians of his time stated that modern scientific research contradicted sacred scriptures therefore the scriptures must be wrong.[76]</p>
	<p> Robert G. Ingersoll stated that when theologians had power the majority of people lived in hovels while a privileged few had palaces and cathedrals. In Ingersoll's opinion science rather than theology improved people's lives. Ingersoll maintained further that trained theologians reason no better than a person who assumes the devil must exist because pictures resemble the devil so exactly.[77]</p>
	<p> Mark Twain stated that several mutually incompatible religions claimed to be the true religion and that people cut the throats of others for following a different theology.[78]</p>`
},{
	title: "Woman",
	eYear: 1756,
	wYear: 2017,
	eSource: "https://lololo.com",
	wSource: "https://en.wikipedia.org/wiki/Woman",
	eConn: ["married","women","women","widows","women","men","women","merchants","merchants","widows","communities","privilege","communities","merchants","communities","masters","women","communities","women","cannot","trade","widows","masters","widows","communities","trade","communities","business","business","widows","women","trade","women","public","women","privilege","women","masters","women","business","women","admitted","sex","women","privilege","widows","merchants","privilege","merchants","masters","merchants","have","men","than","men","men","married","married","early","sex","early","naturally","early","activities"],

	wConn: ["women","men","women","music", "women","issues", "women","education","violence","against","women","social","classical","music","violence","women","during","war","composers","music","war","rape","women","female","information","women","female","human","during","rape","century","women"],

	eArt: "Woman, we include under this rubric all persons of the feminine sex, whether girls, married women or widows; but in certain respects married women are distinguished from unmarried and widowed women from married.\n\n<p> All wives and unmarried women are at times included under the term men.\n</p>\n<p> The condition of women in general is nevertheless different in several ways from that of men.\n</p>\n<p> Women are earlier nubile than men, the age of puberty is fixed for them at 12 years; their personality is commonly formed sooner than that of men, they also cease to be of childbearing capability earlier than men. citi\xF9s pubescunt, citi\xF9s senescunt. (Early puberty, early old age.)\n</p>\n<p> Men, according to the prerogatives of their sex and the force of their temperament, are naturally capable of all sorts of employment and activities; whereas women, due to the fragility of their sex and their naturally delicacy, are excluded from many functions and incapable of certain activities.\n</p>\n<p> First of all, in regard to the religious world, women can be canonesses, nuns, abbesses of an abbey of young girls; but they cannot hold a bishopric or other livings, nor be admitted to ecclesiastical orders, either major or minor. There were nevertheless deaconesses in the archaic Church, but this practice is no longer sustained.\n</p>\n<p> In certain monarchical states, as in France, women, whether single, married or widowed, cannot succeed to the throne.\n</p>\n<p> Women are neither admitted to military employment nor to the chivalric orders.\n</p>\n<p> According to Roman law, which is in this regard followed throughout the kingdom, women are not admitted to public hearings; thus they cannot hold the office of judge, nor act as magistrate, nor serve as lawyer or prosecutor.\n</p>\n<p> In other times they acted as peers, and in this capacity sat in the parliament. Currently they can possess a female duchy and hold the title, but they no longer hold the office of peer. See Peer and Peerage.\n</p>\n<p> In the past in France women could be arbiters, even passing judgment in person on their lands; but since lords are no longer allowed to render justice in person, women can no longer be either judges or arbiters.\n</p>\n<p> They can nevertheless fulfill the function of experts, in their area of knowledge, in whatever art or profession is appropriate to their sex.\n</p>\n<p> We note in the ancient ordinances that there was at one time a woman who functioned as headsman for women, such as when it was necessary to whip someone. See below Executeur de la Haute - Justice.\n</p>\n<p> One cannot name them tutors or guardians except of their own children or grandchildren; there are nevertheless examples of women being named guardians of their prodigal, violent and outcast husbands.\n</p>\n<p> Women are exempted from major levies and other duties.\n</p>\n<p> But they are not exempted from duties, nor from corv\xE9es or other charges, whether real or personal. The corv\xE9e of a woman is valued at 6 deniers according to the custom of Troyes , article 192 . and that of a man at 12 deniers.\n</p>\n<p> A few married and single women have been admitted into the literary academies; there are even a few of them who have received doctorates in the universities. Hel\xE9ne-Lucrece Piscopia Cornara demanded the doctorate in Theology at the university of Padua; Cardinal Barbarigo, bishop of Padua, opposed it: she was forced to accept a doctorate in Philosophy, which was conferred upon her to universal acclaim, 25 June 1678. Bayle, oeuvres, tome I. p. 361. Young miss Patin received as well the same rank; and on the 10th May 1732, Laure Bassi, bourgeoise from Bologna, received a doctorate in Medicine at the preference of the senate, of the cardinal of Polignac, two bishops, the principle nobility, and the doctors of the university. Finally in 1750, signora Maria-Gaetana Agnese was named publicly to the post of professor of Mathematics at Bologna in Italy.\n</p>\n<p> One cannot call women as witnesses to wills nor in acts before notaries; but they can give testimony in depositions, both in civil and criminal matters. \n</p>\n<p> It is commonly said that two women are necessary to act as witness: nevertheless it is not that women's depositions count for half that of men, this is rather founded on the belief that women's testimony is in general light and subject to variation; this is why it is taken less seriously than that of men: it depends on the prudence of the judge to add more or less faith to the depositions of women, according to the quality of those who are deposing and other circumstances.\n</p>\n<p> There are religious houses, communities and hospitals for women married and single, whose government is entrusted to married women.\n</p>\n<p> No women are received into the male corporations and communities, such as communities of merchants and artisans, because women who take part in the business and trade of their husbands, are not considered reputable public merchants: but in several of these communities, the daughters of masters have the privilege of transferring the mastership to the one they marry; and widows of masters have the right to continue the business and trade of their husband, as long as they remain widows; or if it is an art that a woman cannot exercise, they can rent their privilege, as do the widows of surgeons.\n</p>\n<p> There are certain businesses and trades reserved for wives and single women, who form among themselves bodies and communities which are their own, like the matrons or midwives, the linen merchants, fishwives, grain merchants, dressmakers, flower sellers, etc.\n</p>\n<p> Women are not detainable bodily for civil debts, unless they are public merchants, or for stellionate deriving from their actions. See Detained by body.\n</p>\n<p> At different times laws have been made to restrict luxury goods for women, of which the oldest is the Oppia law.\n</p>\n<p> There are also several specific regulations for the burial of women; in the abbey of S. Bertin they cannot ever be buried. \n</p>\n",

	wArt: "A woman is a female human. The term woman is usually reserved for an adult, with the term girl being the usual term for a female child or adolescent. The term woman is also sometimes used to identify a female human, regardless of age, as in phrases such as \"women's rights\". \"Woman\" may also refer to a person's gender identity. Women with typical genetic development are usually capable of giving birth from puberty until menopause.\n\n<h2>Etymology</h2>\n<p>  The spelling of \"woman\" in English has progressed over the past millennium from w\u012Bfmann to w\u012Bmmann to wumman, and finally, the modern spelling woman. In Old English, w\u012Bfmann meant \"female human\", whereas w\u0113r meant \"male human\". Mann or monn had a gender-neutral meaning of \"human\", corresponding to Modern English \"person\" or \"someone\"; however, subsequent to the Norman Conquest, man began to be used more in reference to \"male human\", and by the late 13th century had begun to eclipse usage of the older term w\u0113r. The medial labial consonants f and m in w\u012Bfmann coalesced into the modern form \"woman\", while the initial element, which meant \"female\", underwent semantic narrowing to the sense of a married woman (\"wife\").\n</p>\n<p>  It is a popular misconception that the term \"woman\" is etymologically connected to \"womb\". \"Womb\" is actually from the Old English word wambe meaning \"stomach\" (modern German retains the colloquial term \"Wampe\" from Middle High German for \"potbelly\").\n</p>\n<h3>Biological symbol</h3>\n<p>  The symbol for the planet Venus is the sign also used in biology for the female sex. It is a stylized representation of the goddess Venus's hand-mirror or an abstract symbol for the goddess: a circle with a small equilateral cross underneath. The Venus symbol also represented femininity, and in ancient alchemy stood for copper. Alchemists constructed the symbol from a circle (representing spirit) above an equilateral cross (representing matter).\n</p>\n<h2>Terminology</h2>\n<p>  Further information: girl, virgin, mother, wife, goodwife, lady, maid, maiden, and widow\n</p><p>  Womanhood is the period in a female's life after she has passed through childhood and adolescence, generally around age 18.\n</p>\n<p>  The word woman can be used generally, to mean any female human or specifically, to mean an adult female human as contrasted with girl. The word girl originally meant \"young person of either sex\" in English; it was only around the beginning of the 16th century that it came to mean specifically a female child. The term girl is sometimes used colloquially to refer to a young or unmarried woman; however, during the early 1970s feminists challenged such use because the use of the word to refer to a fully grown woman may cause offence. In particular, previously common terms such as office girl are no longer widely used. Conversely, in certain cultures which link family honor with female virginity, the word girl is still used to refer to a never-married woman; in this sense it is used in a fashion roughly analogous to the obsolete English maid or maiden. Referring to an unmarried female human as a woman may, in such a culture, imply that she is sexually experienced, which would be an insult to her family.\n</p>\n<p>  There are various words used to refer to the quality of being a woman. The term \"womanhood\" merely means the state of being a woman, having passed the menarche; \"femininity\" is used to refer to a set of typical female qualities associated with a certain attitude to gender roles; \"womanliness\" is like \"femininity\", but is usually associated with a different view of gender roles; \"femaleness\" is a general term, but is often used as shorthand for \"human femaleness\"; \"distaff\" is an archaic adjective derived from women's conventional role as a spinner, now used only as a deliberate archaism; \"muliebrity\" is a neologism (derived from the Latin) meant to provide a female counterpart of \"virility\", but used very loosely, sometimes to mean merely \"womanhood\", sometimes \"femininity\" and sometimes even as a collective term for women.\n</p>\n<p>  Menarche, the onset of menstruation, occurs on average at age 12-13. Many cultures have rites of passage to symbolize a girl's coming of age, such as confirmation in some branches of Christianity, bat mitzvah in Judaism, or even just the custom of a special celebration for a certain birthday (generally between 12 and 21), like the Quincea\xF1era of Latin America.\n</p>\n<h2>History</h2>\n<p>  The earliest women whose names are known through archaeology include:\n</p>\n<p>  Neithhotep (c. 3200 BCE), the wife of Narmer and the first queen of ancient Egypt.\n</p><p>  Merneith (c. 3000 BCE), consort and regent of ancient Egypt during the first dynasty. She may have been ruler of Egypt in her own right.\n</p><p>  Merit-Ptah (c. 2700 BCE), also lived in Egypt and is the earliest known female physician and scientist.\n</p><p>  Peseshet (c. 2600 BCE), a physician in Ancient Egypt.\n</p><p>  Puabi (c. 2600 BCE), or Shubad \u2013 queen of Ur whose tomb was discovered with many expensive artifacts. Other known pre-Sargonic queens of Ur (royal wives) include Ashusikildigir, Ninbanda, and Gansamannu.\n</p><p>  Kugbau (circa 2,500 BCE), a taverness from Kish chosen by the Nippur priesthood to become hegemonic ruler of Sumer, and in later ages deified as \"Kubaba\".\n</p><p>  Tashlultum (c. 2400 BCE), Akkadian queen, wife of Sargon of Akkad and mother of Enheduanna.\n</p><p>  Baranamtarra (c. 2384 BCE), prominent and influential queen of Lugalanda of Lagash. Other known pre-Sargonic queens of the first Lagash dynasty include Menbara-abzu, Ashume'eren, Ninkhilisug, Dimtur, and Shagshag, and the names of several princesses are also known.\n</p><p>  Enheduanna (c. 2285 BCE), the high priestess of the temple of the Moon God in the Sumerian city-state of Ur and possibly the first known poet and first named author of either gender.\n</p>\n<h2>Biology and sex</h2>\n<p>  The human female reproductive system\n</p>\n<p>  Spectral karyotype of a human female\n</p><p>  Photograph of an adult female human, with an adult male for comparison.  Note that both models have partially shaved body hair.\n</p><p>  Photograph of an adult female human, with an adult male for comparison. Note that both models have partially shaved body hair.\n</p><p>  In terms of biology, the female sex organs are involved in the reproductive system, whereas the secondary sex characteristics are involved in nurturing children or, in some cultures, attracting a mate. The ovaries, in addition to their regulatory function producing hormones, produce female gametes called eggs which, when fertilized by male gametes (sperm), form new genetic individuals. The uterus is an organ with tissue to protect and nurture the developing fetus and muscle to expel it when giving birth. The vagina is used in copulation and birthing, although the term vagina is often colloquially and incorrectly used in the English language for the vulva or external female genitalia, which consists of (in addition to the vagina) the labia, the clitoris, and the female urethra. The breast evolved from the sweat gland to produce milk, a nutritious secretion that is the most distinctive characteristic of mammals, along with live birth. In mature women, the breast is generally more prominent than in most other mammals; this prominence, not necessary for milk production, is probably at least partially the result of sexual selection. (For other ways in which men commonly differ physically from women, see man.)\n</p>\n<p>  During early fetal development, embryos of both sexes appear gender-neutral. As in cases without two sexes, such as species that reproduce asexually, the gender-neutral appearance is closer to female than to male. A fetus usually develops into a male if it is exposed to a significant amount of testosterone (typically because the fetus has a Y chromosome from the father). Otherwise, the fetus usually develops into a female, typically when the fetus has an X chromosome from the father, but also when the father contributed neither an X nor Y chromosome. Later at puberty, estrogen feminizes a young woman, giving her adult sexual characteristics.\n</p>\n<p>  An imbalance of maternal hormonal levels and some chemicals (or drugs) may alter the secondary sexual characteristics of fetuses. Most women have the karyotype 46,XX, but around one in a thousand will be 47,XXX, and one in 2500 will be 45,X. This contrasts with the typical male karotype of 46,XY; thus, the X and Y chromosomes are known as female and male, respectively. Because humans inherit mitochondrial DNA only from the mother's ovum, genetic studies of the female line tend to focus on mitochondrial DNA.\n</p>\n<p>  Whether or not a child is considered female does not always determine whether or not the child later will identify themselves that way (see gender identity). For instance, intersex individuals, who have mixed physical and/or genetic features, may use other criteria in making a clear determination. At birth, babies may be assigned a gender based on their genitalia. In some cases, even if a child had XX chromosomes, if they were born with a penis, they were raised as a male. There are also transgender and transsexual women, who were assigned as male at birth, but identify as women; there are varying social, legal, and individual definitions with regard to these issues (see trans woman).\n</p>\n\n<p>  \"The Life & Age of Woman - Stages of Woman's Life from the Cradle to the Grave\",1849\n</p><p>  Although fewer females than males are born (the ratio is around 1:1.05), because of a longer life expectancy there are only 81 men aged 60 or over for every 100 women of the same age. Women typically have a longer life expectancy than men. This is due to a combination of factors: genetics (redundant and varied genes present on sex chromosomes in women); sociology (such as the fact that women are not expected in most modern nations to perform military service); health-impacting choices (such as suicide or the use of cigarettes, and alcohol); the presence of the female hormone estrogen, which has a cardioprotective effect in premenopausal women; and the effect of high levels of androgens in men. Out of the total human population in 2015, there were 101.8 men for every 100 women.\n</p>\n\n<p>  Woman nursing her infant\n</p><p>  Girls' bodies undergo gradual changes during puberty, analogous to but distinct from those experienced by boys. Puberty is the process of physical changes by which a child's body matures into an adult body capable of sexual reproduction to enable fertilisation. It is initiated by hormonal signals from the brain to the gonads-either the ovaries or the testes. In response to the signals, the gonads produce hormones that stimulate libido and the growth, function, and transformation of the brain, bones, muscle, blood, skin, hair, breasts, and sexual organs. Physical growth\u2014height and weight\u2014accelerates in the first half of puberty and is completed when the child has developed an adult body. Until the maturation of their reproductive capabilities, the pre-pubertal, physical differences between boys and girls are the genitalia, the penis and the vagina. Puberty is a process that usually takes place between the ages 10\u201316, but these ages differ from girl to girl. The major landmark of girls' puberty is menarche, the onset of menstruation, which occurs on average between ages 12\u201313.\n</p>\n<p>  Most girls go through menarche and are then able to become pregnant and bear children. This generally requires internal fertilization of her eggs with the sperm of a man through sexual intercourse, though artificial insemination or the surgical implantation of an existing embryo is also possible (see reproductive technology). The study of female reproduction and reproductive organs is called gynaecology.\n</p>\n<h2>Health</h2>\n<p>  Further information: Women's health and Maternal death\n</p>\n<p>  Pregnant woman\n</p><p>  Women's health refers to health issues specific to human female anatomy. There are some diseases that primarily affect women, such as lupus. Also, there are some gender-related illnesses that are found more frequently or exclusively in women, e.g., breast cancer, cervical cancer, or ovarian cancer. Women and men may have different symptoms of an illness and may also respond to medical treatment differently. This area of medical research is studied by gender-based medicine.\n</p>\n<p>  The issue of women's health has been taken up by many feminists, especially where reproductive health is concerned. Women's health is positioned within a wider body of knowledge cited by, amongst others, the World Health Organisation, which places importance on gender as a social determinant of health.\n</p>\n<p>  Maternal mortality or maternal death is defined by WHO as \"the death of a woman while pregnant or within 42 days of termination of pregnancy, irrespective of the duration and site of the pregnancy, from any cause related to or aggravated by the pregnancy or its management but not from accidental or incidental causes.\" About 99% of maternal deaths occur in developing countries. More than half of them occur in sub-Saharan Africa and almost one third in South Asia. The main causes of maternal mortality are severe bleeding (mostly bleeding after childbirth), infections (usually after childbirth), pre-eclampsia and eclampsia, unsafe abortion, and pregnancy complications from malaria and HIV/AIDS. Most European countries, Australia, as well as Japan and Singapore are very safe in regard to childbirth, while Sub-Saharan countries are the most dangerous.\n</p>\n<h2>Reproductive rights and freedom</h2>\n\n<p>  A poster from a 1921 eugenics conference displays the U.S. states that had implemented sterilization legislation\n</p><p>  Reproductive rights are legal rights and freedoms relating to reproduction and reproductive health. The International Federation of Gynecology and Obstetrics has stated that:\n</p>\n<p>  (...) the human rights of women include their right to have control over and decide freely and responsibly on matters related to their sexuality, including sexual and reproductive health, free of coercion, discrimination and violence. Equal relationships between women and men in matters of sexual relations and reproduction, including full respect for the integrity of the person, require mutual respect, consent and shared responsibility for sexual behavior and its consequences.\n</p><p>  Violations of reproductive rights include forced pregnancy, forced sterilization and forced abortion.\n</p>\n<p>  Forced sterilization was practiced during the first half of the 20th century by many Western countries. Forced sterilization and forced abortion are reported to be currently practiced in countries such as Uzbekistan and China.\n</p>\n<p>  The lack of adequate laws on sexual violence combined with the lack of access to contraception and/or abortion are a cause of enforced pregnancy (see pregnancy from rape).\n</p>\n<h2>Culture and gender roles</h2>\n<p>  Main article: Gender role\n</p>\n<p>  A woman weaving. Textile work is traditionally and historically a female occupation in many cultures.\n</p><p>  In many prehistoric cultures, women assumed a particular cultural role. In hunter-gatherer societies, women were generally the gatherers of plant foods, small animal foods and fish, while men hunted meat from large animals.\n</p>\n<p>  In more recent history, gender roles have changed greatly. Originally, starting at a young age, aspirations occupationally are typically veered towards specific directions according to gender. Traditionally, middle class women were involved in domestic tasks emphasizing child care. For poorer women, especially working class women, although this often remained an ideal, economic necessity compelled them to seek employment outside the home. Many of the occupations that were available to them were lower in pay than those available to men.\n</p>\n<p>  As changes in the labor market for women came about, availability of employment changed from only \"dirty\", long hour factory jobs to \"cleaner\", more respectable office jobs where more education was demanded, women's participation in the U.S. labor force rose from 6% in 1900 to 23% in 1923. These shifts in the labor force led to changes in the attitudes of women at work, allowing for the revolution which resulted in women becoming career and education oriented.\n</p>\n\n<p>  During World War II, some women performed roles which would otherwise have been considered male jobs by the culture of the time\n</p><p>  In the 1970s, many female academics, including scientists, avoided having children. However, throughout the 1980s, institutions tried to equalize conditions for men and women in the workplace. However, the inequalities at home stumped women's opportunities to succeed as far as men. Professional women are still responsible for domestic labor and child care. As people would say, they have a \"double burden\" which does not allow them the time and energy to succeed in their careers. Furthermore, though there has been an increase in the endorsement of egalitarian gender roles in the home by both women and men, a recent research study showed that women focused on issues of morality, fairness, and well-being, while men focused on social conventions. Until the early 20th century, U.S. women's colleges required their women faculty members to remain single, on the grounds that a woman could not carry on two full-time professions at once. According to Schiebinger, \"Being a scientist and a wife and a mother is a burden in society that expects women more often than men to put family ahead of career.\" (pg. 93).\n</p>\n<p>  Movements advocate equality of opportunity for both sexes and equal rights irrespective of gender. Through a combination of economic changes and the efforts of the feminist movement, in recent decades women in many societies now have access to careers beyond the traditional homemaker.\n</p>\n<p>  Although a greater number of women are seeking higher education, salaries are often less than those of men. CBS News claimed in 2005 that in the United States women who are ages 30 to 44 and hold a university degree make 62 percent of what similarly qualified men do, a lower rate than in all but three of the 19 countries for which numbers are available. Some Western nations with greater inequity in pay are Germany, New Zealand and Switzerland.\n</p>\n<h3>Violence against women</h3>\n<p>  Main article: Violence against women\n</p>\n<p>  A campaign against female genital mutilation \u2013 a road sign near Kapchorwa, Uganda\n</p>\n<p>  Burning witches, with others held in Stocks\n</p>\n<p>  A young ethnic Chinese woman from one of the Imperial Japanese Army's \"comfort battalions\" is interviewed by an Allied officer.\n</p><p>  The UN Declaration on the Elimination of Violence against Women defines \"violence against women\" as:\n</p>\n<p>  any act of gender-based violence that results in, or is likely to result in, physical, sexual or mental harm or suffering to women, including threats of such acts, coercion or arbitrary deprivation of liberty, whether occurring in public or in private life.\n</p>\n<p>  and identifies three forms of such violence: that which occurs in the family, that which occurs within the general community, and that which is perpetrated or condoned by the State. It also states that \"violence against women is a manifestation of historically unequal power relations between men and women\".\n</p>\n<p>  Violence against women remains a widespread problem, fueled, especially outside the West, by patriarchal social values, lack of adequate laws, and lack of enforcement of existing laws. Social norms that exist in many parts of the world hinder progress towards protecting women from violence. For example, according to surveys by UNICEF, the percentage of women aged 15\u201349 who think that a husband is justified in hitting or beating his wife under certain circumstances is as high as 90% in Afghanistan and Jordan, 87% in Mali, 86% in Guinea and Timor-Leste, 81% in Laos, and 80% in the Central African Republic. A 2010 survey conducted by the Pew Research Center found that stoning as a punishment for adultery was supported by 82% of respondents in Egypt and Pakistan, 70% in Jordan, 56% Nigeria, and 42% in Indonesia.\n</p>\n<p>  Specific forms of violence that affect women include female genital mutilation, sex trafficking, forced prostitution, forced marriage, rape, sexual harassment, honor killings, acid throwing, and dowry related violence. Governments can be complicit in violence against women, for instance through practices such as stoning (as punishment for adultery).\n</p>\n<p>  There have also been many forms of violence against women which have been prevalent historically, notably the burning of witches, the sacrifice of widows (such as sati) and foot binding. The prosecution of women accused of witchcraft has a long tradition, for example witch trials in the early modern period (between the 15th and 18th centuries) were common in Europe and in the European colonies in North America. Today, there remain regions of the world (such as parts of Sub-Saharan Africa, rural North India, and Papua New Guinea) where belief in witchcraft is held by many people, and women accused of being witches are subjected to serious violence. In addition, there are also countries which have criminal legislation against the practice of witchcraft. In Saudi Arabia, witchcraft remains a crime punishable by death, and in 2011 the country beheaded a woman for 'witchcraft and sorcery'.\n</p>\n<p>  It is also the case that certain forms of violence against women have been recognized as criminal offenses only during recent decades, and are not universally prohibited, in that many countries continue to allow them. This is especially the case with marital rape. In the Western World, there has been a trend towards ensuring gender equality within marriage and prosecuting domestic violence, but in many parts of the world women still lose significant legal rights when entering a marriage.\n</p>\n<p>  Sexual violence against women greatly increases during times of war and armed conflict, during military occupation, or ethnic conflicts; most often in the form of war rape and sexual slavery. Contemporary examples of sexual violence during war include rape during the Bangladesh Liberation War, rape in the Bosnian War, rape during the Rwandan Genocide, and rape during Second Congo War. In Colombia, the armed conflict has also resulted in increased sexual violence against women.\n</p>\n<p>  Laws and policies on violence against women vary by jurisdiction. In the European Union, sexual harassment and human trafficking are subject to directives.\n</p>\n<h2>Clothing, fashion and dress codes</h2>\n<p>  Further information: Fashion, Modesty, and Hijab by country\n</p>\n<p>  Afghan women wearing burqas. Some Muslim women wear hijabs and other types of clothing as a symbol of modesty and privacy.\n</p><p>  Women in different parts of the world dress in different ways, with their choices of clothing being influenced by local culture, religious tenets traditions, social norms, and fashion trends, amongst other factors. Different societies have different ideas about modesty. However, in many jurisdictions, women's choices in regard to dress are not always free, with laws limiting what they may or may not wear. This is especially the case in regard to Islamic dress. While certain jurisdictions legally mandate such clothing (the wearing of the headscarf), other countries forbid or restrict the wearing of certain hijab attire (such as burqa/covering the face) in public places (one such country is France - see French ban on face covering). These laws are highly controversial.\n</p>\n<h2>Fertility and family life</h2>\n<p>  Further information: Mother\n</p>\n<p>  A world map showing countries by total fertility rate (TFR), according to the CIA World Factbook's 2015 data.\n  </p><p>    7\u20138 Children\n  </p><p>    6\u20137 Children\n  </p><p>    5\u20136 Children\n  </p><p>    4\u20135 Children\n  </p><p>    3\u20134 Children\n  </p><p>    2\u20133 Children\n  </p><p>    1\u20132 Children\n  </p><p>    0\u20131 Children\n  </p><p>  Percentage of births to unmarried women, selected countries, 1980 and 2007.\n  </p>\n\n<p>  Mother and child, in Bhutan\n</p><p>  The total fertility rate (TFR) - the average number of children born to a woman over her lifetime - differs significantly between different regions of the world. In 2016, the highest estimated TFR was in Niger (6.62 children born per woman) and the lowest in Singapore (0.82 children/woman). While most Sub-Saharan African countries have a high TFR, which creates problems due to lack of resources and contributes to overpopulation, most Western countries currently experience a sub replacement fertility rate which may lead to population ageing and population decline.\n</p>\n<p>  In many parts of the world, there has been a change in family structure over the past few decades. For instance, in the West, there has been a trend of moving away from living arrangements that include the extended family to those which only consist of the nuclear family. There has also been a trend to move from marital fertility to non-marital fertility. Children born outside marriage may be born to cohabiting couples or to single women. While births outside marriage are common and fully accepted in some parts of the world, in other places they are highly stigmatized, with unmarried mothers facing ostracism, including violence from family members, and in extreme cases even honor killings. In addition, sex outside marriage remains illegal in many countries (such as Saudi Arabia, Pakistan, Afghanistan, Iran, Kuwait, Maldives, Morocco, Oman, Mauritania, United Arab Emirates, Sudan, and Yemen).\n</p>\n<p>  The social role of the mother differs between cultures. In many parts of the world, women with dependent children are expected to stay at home and dedicate all their energy to child raising, while in other places mothers most often return to paid work (see working mother and stay-at-home mother).\n</p>\n<h2>Religion</h2>\n<p>  Further information: Women in Christianity, Women in Judaism, Women in Islam, Women in Mormonism, Women in Hinduism, Women in Sikhism, and Women in Buddhism\n</p><p>  Particular religious doctrines have specific stipulations relating to gender roles, social and private interaction between the sexes, appropriate dressing attire for women, and various other issues affecting women and their position in society. In many countries, these religious teachings influence the criminal law, or the family law of those jurisdictions (see Sharia law, for example). The relation between religion, law and gender equality has been discussed by international organizations.\n</p>\n<h2>Education</h2>\n<p>  Main article: Female education\n</p><p>  Female education includes areas of gender equality and access to education, and its connection to the alleviation of poverty. Also involved are the issues of single-sex education and religious education in that the division of education along gender lines as well as religious teachings on education have been traditionally dominant and are still highly relevant in contemporary discussions of educating females as a global consideration.\n</p>\n<p>  While the feminist movement has certainly promoted the importance of the issues attached to female education the discussion is wide-ranging and by no means narrowly defined. It may include, for example, HIV/AIDS education. Universal education, meaning state-provided primary and secondary education independent of gender is not yet a global norm, even if it is assumed in most developed countries. In some Western countries, women have surpassed men at many levels of education. For example, in the United States in 2005/2006, women earned 62% of associate degrees, 58% of bachelor's degrees, 60% of master's degrees, and 50% of doctorates.\n</p>\n\n<p>  Women attending an adult literacy class in the El Alto section of La Paz, Bolivia\n</p>\n<p>  A female biologist weighs a desert tortoise before release\n</p><h3>Literacy</h3>\n<p>  Main article: Literacy\n</p><p>  World literacy is lower for females than for males. The CIA World Factbook presents an estimate from 2010 which shows that 80% of women are literate, compared to 88.6% of men (aged 15 and over). Literacy rates are lowest in South and West Asia, and in parts of Sub-Saharan Africa.\n</p>\n<h3>OECD countries</h3>\n<h4>Education</h4>\n<p>  The educational gender gap in Organisation for Economic Co-operation and Development (OECD) countries has been reduced over the last 30 years. Younger women today are far more likely to have completed a tertiary qualification: in 19 of the 30 OECD countries, more than twice as many women aged 25 to 34 have completed tertiary education than have women aged 55 to 64. In 21 of 27 OECD countries with comparable data, the number of women graduating from university-level programmes is equal to or exceeds that of men. 15-year-old girls tend to show much higher expectations for their careers than boys of the same age. While women account for more than half of university graduates in several OECD countries, they receive only 30% of tertiary degrees granted in science and engineering fields, and women account for only 25% to 35% of researchers in most OECD countries.\n</p>\n<p>  There is a common misconception that women have still not advanced in achieving academic degrees. According to Margaret Rossiter, a historian of science, women now earn 54 percent of all bachelor's degrees in the United States. However, although there are more women holding bachelor's degrees than men, as the level of education increases, the more men tend to fit the statistics instead of women. At the graduate level, women fill 40 percent of the doctorate degrees (31 percent of them being in engineering).\n</p>\n<p>  While to this day women are studying at prestigious universities at the same rate as men, they are not being given the same chance to join faculty. Sociologist Harriet Zuckerman has observed that the more prestigious an institute is, the more difficult and time-consuming it will be for women to obtain a faculty position there. In 1989, Harvard University tenured its first woman in chemistry, Cynthia Friend, and in 1992 its first woman in physics, Melissa Franklin. She also observed that women were more likely to hold their first professional positions as instructors and lecturers while men are more likely to work first in tenure positions. According to Smith and Tang, as of 1989, 65 percent of men and only 40 percent of women held tenured positions and only 29 percent of all scientists and engineers employed as assistant professors in four-year colleges and universities were women.\n</p>\n<h4>Jobs</h4>\n<p>  In 1992, women earned 9 percent of the PhDs awarded in engineering, but only one percent of those women became professors. In 1995, 11 percent of professors in science and engineering were women. In relation, only 311 deans of engineering schools were women, which is less than 1 percent of the total. Even in psychology, a degree in which women earn the majority of PhDs, they hold a significant amount of fewer tenured positions, roughly 19 percent in 1994.\n</p>\n<h2>Women in politics</h2>\n<p>  A world map showing female governmental participation by country, 2010.\n</p><p>  A world map showing female governmental participation by country, 2010\n</p>\n<p>  Angela Merkel has earned the top spot on the FORBES list of Most Powerful Women In The World for eight of the past 10 years\n</p><p>  Women are underrepresented in government in most countries. In October 2013, the global average of women in national assemblies was 22%. Suffrage is the civil right to vote. Women's suffrage in the United States was achieved gradually, first at state and local levels, starting in the late 19th century and early 20th century, and in 1920 women in the US received universal suffrage, with the passage of the Nineteenth Amendment to the United States Constitution. Some Western countries were slow to allow women to vote; notably Switzerland, where women gained the right to vote in federal elections in 1971, and in the canton of Appenzell Innerrhoden women were granted the right to vote on local issues only in 1991, when the canton was forced to do so by the Federal Supreme Court of Switzerland; and Liechtenstein, in 1984, through a women's suffrage referendum.\n</p>\n<h2>Science, literature and art</h2>\n\n<p>  German composer Clara Schumann in 1878\n</p><p>  Women have, throughout history, made contributions to science, literature and art. One area where women have been permitted most access historically was that of obstetrics and gynecology (prior to the 18th century, caring for pregnant women in Europe was undertaken by women; from the mid 18th century onwards medical monitoring of pregnant women started to require rigorous formal education, to which women did not generally have access, therefore the practice was largely transferred to men).\n</p>\n<p>  Writing was generally also considered acceptable for upper class women, although achieving success as a female writer in a male dominated world could be very difficult; as a result several women writers adopted a male pen name (e.g. George Sand, George Eliot).\n</p>\n<p>  Women have been composers, songwriters, instrumental performers, singers, conductors, music scholars, music educators, music critics/music journalists and other musical professions. There are music movements, events and genres related to women, women's issues and feminism. In the 2010s, while women comprise a significant proportion of popular music and classical music singers, and a significant proportion of songwriters (many of them being singer-songwriters), there are few women record producers, rock critics and rock instrumentalists. Although there have been a huge number of women composers in classical music, from the Medieval period to the present day, women composers are significantly underrepresented in the commonly performed classical music repertoire, music history textbooks and music encyclopedias; for example, in the Concise Oxford History of Music, Clara Schumann is one of the only female composers who is mentioned.\n</p>\n<p>  Women comprise a significant proportion of instrumental soloists in classical music and the percentage of women in orchestras is increasing. A 2015 article on concerto soloists in major Canadian orchestras, however, indicated that 84% of the soloists with the Orchestre Symphonique de Montreal were men. In 2012, women still made up just 6% of the top-ranked Vienna Philharmonic orchestra. Women are less common as instrumental players in popular music genres such as rock and heavy metal, although there have been a number of notable female instrumentalists and all-female bands. Women are particularly underrepresented in extreme metal genres. Women are also underrepresented in orchestral conducting, music criticism/music journalism, music producing, and sound engineering. While women were discouraged from composing in the 19th century, and there are few women musicologists, women became involved in music education \"... to such a degree that women dominated  during the later half of the 19th century and well into the 20th century.\"\n</p>\n<p>  According to Jessica Duchen, a music writer for London's The Independent, women musicians in classical music are \"... too often judged for their appearances, rather than their talent\" and they face pressure \"... to look sexy onstage and in photos.\" Duchen states that while \"there are women musicians who refuse to play on their looks, ... the ones who do tend to be more materially successful.\"\n</p>\n<p>  According to the UK's Radio 3 editor, Edwina Wolstencroft, the classical music industry has long been open to having women in performance or entertainment roles, but women are much less likely to have positions of authority, such as being the leader of an orchestra. In popular music, while there are many women singers recording songs, there are very few women behind the audio console acting as music producers, the individuals who direct and manage the recording process.\n</p>\n"
},{
	title: "World",
	eYear: 1765,
	wYear: 2017,
	eSource: "Vol. 10 (1765), pp. 640–641",
	wSource: "https://en.wikipedia.org/wiki/World",
	eConn: ["world","earth","used","earth","planets","inhabited","other","planets","earth","inhabited","comets","times","planets","earth","opinion","men","world","different","times","warmth","teaches","men","similar","earth"],
	wConn: ["world","history","religion","world","world","sum","world","war","world","scope","world","participation","world","international","world","intercontinental","world","entire","christianity","world","world","human","population","world"],
	eArt: `World, we give this name to the collection and the system of different parts that make up this universe. See Cosmogony, Cosmography, Cosmology, and System. World is used more specifically for the earth, including its different parts and people that live there, and in that sense, we ask whether planets are each a world like our earth, that is to say, if they are inhabited. Concerning which, see the following article : Plurality of Worlds.
	<p> In a work entitled the same as this article, Mr. de Fontenelle was the first to claim that each planet from the moon to Saturn is an inhabited world like our earth. The general reason he used is that planets are similar bodies to our earth, our earth is a planet, and so consequently since it is inhabited, so too must other planets. The author refutes theologians' objections by assuring that he doesn't place humans on other planets but inhabitants that aren’t men at all. Mr. Huyghens in his Cosmotheoros printed in 1690, a short time after Mr. Fontenelle’s work, supports the same opinion with this difference; he claims that planets’ inhabitants must have the same arts and knowledge as we, which is not so different from making men of them. After all, why would this opinion contradict faith? Scripture teaches us, undoubtedly, that all men come from Adam, but it means only men who inhabit our earth. Other men can live on other planets and come from elsewhere than from Adam.
	</p>
	<p> Though the belief in inhabitants' existence on planets may seem true, it is not without difficulties, either. First it is doubtful if several planets, among them the moon, have an atmosphere, and on the assumption that they do not, we cannot see how living beings would breathe and survive there. Second, we notice in some planets like Jupiter considerable changing figures on their surface, see Bands, and it seems that an inhabited planet should be more tranquil. Lastly comets are certainly planets, see Comet, yet it is difficult to believe that comets are inhabited because of extreme differences in the sun's heat that its inhabitants would have to endure, from at times being burnt to at other times hardly or not at all feeling the sun’s warmth. The comet in 1680, for example, almost passed in front of the sun and from there distanced itself so far that it will only return in 575 years. What living bodies would be able to withstand that extraordinary heat on one hand and extreme cold on the other? The same applies in varying degrees to other comets. How must we respond, therefore, to those who inquire if planets are inhabited? That we don’t know.</p>`,
	wArt:`<p> The world is the planet Earth and all life upon it, including human civilization.[1] In a philosophical context, the world is the whole of the physical Universe, or an ontological world. In a theological context, the world is the material or the profane sphere, as opposed to the celestial, spiritual, transcendent or sacred. The "end of the world" refers to scenarios of the final end of human history, often in religious contexts.</p>
	<p> History of the world is commonly understood as spanning the major geopolitical developments of about five millennia, from the first civilizations to the present. In terms such as world religion, world language, world government, and world war, world suggests international or intercontinental scope without necessarily implying participation of the entire world.</p>
	<p> World population is the sum of all human populations at any time; similarly, world economy is the sum of the economies of all societies or countries, especially in the context of globalization. Terms like world championship, gross world product, world flags imply the sum or combination of all current-day sovereign states.</p>
	<p> The English word world comes from the Old English weorold (-uld), weorld, worold (-uld, -eld), a compound of wer "man" and eld "age," which thus means roughly "Age of Man."[2] The Old English is a reflex of the Common Germanic *wira-alđiz, also reflected in Old Saxon werold, Old Dutch werilt, Old High German weralt, Old Frisian warld and Old Norse verǫld (whence the Icelandic veröld).[3]</p>
	<p> The corresponding word in Latin is mundus, literally "clean, elegant", itself a loan translation of Greek cosmos "orderly arrangement." While the Germanic word thus reflects a mythological notion of a "domain of Man" (compare Midgard), presumably as opposed to the divine sphere on the one hand and the chthonic sphere of the underworld on the other, the Greco-Latin term expresses a notion of creation as an act of establishing order out of chaos.</p>
	<p> 'World' distinguishes the entire planet or population from any particular country or region: world affairs pertain not just to one place but to the whole world, and world history is a field of history that examines events from a global (rather than a national or a regional) perspective. Earth, on the other hand, refers to the planet as a physical entity, and distinguishes it from other planets and physical objects.</p>
	<p> 'World' was also classically used to mean the material universe, or the cosmos: "The worlde is an apte frame of heauen and earthe, and all other naturall thinges contained in them." [4] The earth was often described as 'the center of the world'.[5]</p>
	<p> 'World' can also be used attributively, to mean 'global', 'relating to the whole world', forming usages such as world community or world canonical texts.[6]</p>
	<p> By extension, a 'world' may refer to any planet or heavenly body, especially when it is thought of as inhabited, especially in the context of science fiction or futurology.</p>
	<p> 'World', in its original sense, when qualified, can also refer to a particular domain of human experience.</p>
	<p> The world of work describes paid work and the pursuit of a career, in all its social aspects, to distinguish it from home life and academic study.</p>
	<p> The fashion world describes the environment of the designers, fashion houses and consumers that make up the fashion industry.</p>
	<p> historically, the New World vs. the Old World, referring to the parts of the world colonized in the wake of the age of discovery. Now mostly used in zoology and botany, as in New World monkey.</p>
	<p> Philosophy</p>
	<p> The Garden of Earthly Delights triptych by Hieronymus Bosch (c. 1503) shows the "garden" of mundane pleasures flanked by Paradise and Hell. The exterior panel shows the world before the appearance of humanity, depicted as a disc enclosed in a sphere.</p>
	<p> In philosophy, the term world has several possible meanings. In some contexts, it refers to everything that makes up reality or the physical universe. In others, it can mean have a specific ontological sense (see world disclosure). While clarifying the concept of world has arguably always been among the basic tasks of Western philosophy, this theme appears to have been raised explicitly only at the start of the twentieth century[7] and has been the subject of continuous debate. The question of what the world is has by no means been settled.</p>
	<p> Parmenides</p>
	<p> The traditional interpretation of Parmenides' work is that he argued that the everyday perception of reality of the physical world (as described in doxa) is mistaken, and that the reality of the world is 'One Being' (as described in aletheia): an unchanging, ungenerated, indestructible whole.</p>
	<p> Plato</p>
	<p> In his Allegory of the Cave, Plato distinguishes between forms and ideas and imagines two distinct worlds: the sensible world and the intelligible world.</p>
	<p> Hegel</p>
	<p> In Georg Wilhelm Friedrich Hegel's philosophy of history, the expression Weltgeschichte ist Weltgericht (World History is a tribunal that judges the World) is used to assert the view that History is what judges men, their actions and their opinions. Science is born from the desire to transform the World in relation to Man; its final end is technical application.</p>
	<p> Schopenhauer</p>
	<p> The World as Will and Representation is the central work of Arthur Schopenhauer. Schopenhauer saw the human will as our one window to the world behind the representation; the Kantian thing-in-itself. He believed, therefore, that we could gain knowledge about the thing-in-itself, something Kant said was impossible, since the rest of the relationship between representation and thing-in-itself could be understood by analogy to the relationship between human will and human body.</p>
	<p> Wittgenstein</p>
	<p> Two definitions that were both put forward in the 1920s, however, suggest the range of available opinion. "The world is everything that is the case," wrote Ludwig Wittgenstein in his influential Tractatus Logico-Philosophicus, first published in 1922. This definition would serve as the basis of logical positivism, with its assumption that there is exactly one world, consisting of the totality of facts, regardless of the interpretations that individual people may make of them.</p>
	<p> Heidegger</p>
	<p> Martin Heidegger, meanwhile, argued that "the surrounding world is different for each of us, and notwithstanding that we move about in a common world".[8] The world, for Heidegger, was that into which we are always already "thrown" and with which we, as beings-in-the-world, must come to terms. His conception of "world disclosure" was most notably elaborated in his 1927 work Being and Time.</p>
	<p> Freud</p>
	<p> In response, Sigmund Freud proposed that we do not move about in a common world, but a common thought process. He believed that all the actions of a person are motivated by one thing: lust. This led to numerous theories about reactionary consciousness.</p>
	<p> Other</p>
	<p> Some philosophers, often inspired by David Lewis, argue that metaphysical concepts such as possibility, probability, and necessity are best analyzed by comparing the world to a range of possible worlds; a view commonly known as modal realism.</p>
	<p> Religion and mythology</p>
	<p> Yggdrasil, a modern attempt to reconstruct the Norse world tree which connects the heavens, the world, and the underworld.</p>
	<p> Mythological cosmologies often depict the world as centered on an axis mundi and delimited by a boundary such as a world ocean, a world serpent or similar. In some religions, worldliness (also called carnality[citation needed]) is that which relates to this world as opposed to other worlds or realms.</p>
	<p> Buddhism</p>
	<p> In Buddhism, the world means society, as distinct from the monastery. It refers to the material world, and to worldly gain such as wealth, reputation, jobs, and war. The spiritual world would be the path to enlightenment, and changes would be sought in what we could call the psychological realm.</p>
	<p> Christianity</p>
	<p> In Christianity, the term often connotes the concept of the fallen and corrupt world order of human society, in contrast to the World to Come. The world is frequently cited alongside the flesh and the Devil as a source of temptation that Christians should flee. Monks speak of striving to be "in this world, but not of this world"—as Jesus said—and the term "worldhood" has been distinguished from "monkhood", the former being the status of merchants, princes, and others who deal with "worldly" things.</p>
	<p> This view is clearly expressed by king Alfred the Great of England (d. 899) in his famous Preface to the Cura Pastoralis:</p>
	<p> "Therefore I command you to do as I believe you are willing to do, that you free yourself from worldly affairs (Old English: woruldðinga) as often as you can, so that wherever you can establish that wisdom that God gave you, you establish it. Consider what punishments befell us in this world when we neither loved wisdom at all ourselves, nor transmitted it to other men; we had the name alone that we were Christians, and very few had the practices."</p>
	<p> Although Hebrew and Greek words meaning "world" are used in Scripture with the normal variety of senses, many examples of its use in this particular sense can be found in the teachings of Jesus according to the Gospel of John, e.g. 7:7, 8:23, 12:25, 14:17, 15:18-19, 17:6-25, 18:36. For contrast, a relatively newer concept is Catholic imagination.</p>
	<p> Contemptus mundi is the name given to the recognition that the world, in all its vanity, is nothing more than a futile attempt to hide from God by stifling our desire for the good and the holy.[9] This view has been criticized as a "pastoral of fear" by modern historian Jean Delumeau.[10]</p>
	<p> During the Second Vatican Council, there was a novel attempt to develop a positive theological view of the World, which is illustrated by the pastoral optimism of the constitutions Gaudium et spes, Lumen gentium, Unitatis redintegratio and Dignitatis humanae.</p>
	<p> Eastern Christianity</p>
	<p> In Eastern Christian monasticism or asceticism the world of mankind is driven by passions. Therefore, the passions of the World are simply called "the world". Each of these passions are a link to the world of mankind or order of human society. Each of these passions must be overcome in order for a person to receive salvation (theosis). The process of theosis is a personal relationship with God. This understanding is taught within the works of ascetics like Evagrius Ponticus, and the most seminal ascetic works read most widely by Eastern Christians, the Philokalia and the Ladder of Divine Ascent (the works of Evagrius and John Climacus are also contained within the Philokalia). At the highest level of world transcendence is hesychasm which culminates into the Vision of God.</p>
	<p> Orbis Catholicus</p>
	<p> Orbis Catholicus is a Latin phrase meaning Catholic world, per the expression Urbi et Orbi, and refers to that area of Christendom under papal supremacy. It is somewhat similar to the phrases secular world, Jewish world and Islamic world.</p>`
}
];


